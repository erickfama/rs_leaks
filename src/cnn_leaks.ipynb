{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "id": "euV33F4mb5i6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1266e700-24d5-410f-b8a3-2b9dece03921"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Jul  6 18:40:29 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P0    44W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "id": "tIpeUm2Yb7mn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "239c9d0e-325d-4845-bf50-c99145c6e924"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 89.6 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Lqa2rdfmhNP1"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "from skimage.io import imread\n",
        "import numpy as np\n",
        "import albumentations as A\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Conv2D, Activation, MaxPool2D, Dropout, BatchNormalization, Dense, Flatten, LayerNormalization\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vypWYBIhQqY"
      },
      "outputs": [],
      "source": [
        "def norm_bands(tif):\n",
        "    return (tif - tif.min())/(tif.max() - tif.min())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount Gdrive"
      ],
      "metadata": {
        "id": "VzB2V37YzvX0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkdqB9jimX6i",
        "outputId": "963f0bda-864c-42ad-a5ca-c147a39bb806"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbr8suj3lyhC"
      },
      "source": [
        "## Load X and Y sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "G5VpSgroxDbA"
      },
      "outputs": [],
      "source": [
        "# Read from google drive\n",
        "X = np.load(\"/content/drive/MyDrive/training/X_full.npy\")\n",
        "Y = np.load(\"/content/drive/MyDrive/training/Y_full.npy\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run if shuffled datasets are wanted\n",
        "shuffler = np.random.permutation(len(X))\n",
        "X = X[shuffler]\n",
        "Y = Y[shuffler]"
      ],
      "metadata": {
        "id": "0HLxvSRaOEsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run if you want to get get only S2 bands\n",
        "X = X[:, :, :, :13]\n",
        "#X = np.expand_dims(X, axis = -1)\n",
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1e4BGnwNg-J",
        "outputId": "1fb029e0-d72e-490a-93fa-dcf3fdbad1b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3910, 20, 20, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsU_vFT4lyhF",
        "outputId": "43a46b63-4ac6-469e-ddd7-efed0724b0a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (3909, 20, 20, 14)\n",
            "Y shape: (3909, 1)\n"
          ]
        }
      ],
      "source": [
        "print(\"X shape:\", X.shape)\n",
        "print(\"Y shape:\", Y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhZpCHwflyhG"
      },
      "source": [
        "## Define training, validation and test sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "zQiGg5LQlyhG"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size = 0.2, random_state = 13)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.2, random_state = 13)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeGf_6XplyhG",
        "outputId": "314a9358-b784-41b7-9139-3341d6b8100a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train:  (2501, 20, 20, 14)\n",
            "X_val:  (782, 20, 20, 14)\n",
            "X_test:  (626, 20, 20, 14)\n",
            "y_train:  (2501, 1)\n",
            "y_val:  (782, 1)\n",
            "y_test:  (626, 1)\n"
          ]
        }
      ],
      "source": [
        "# Shapes of sets\n",
        "print(\"X_train: \", X_train.shape)\n",
        "print(\"X_val: \", X_val.shape)\n",
        "print(\"X_test: \", X_test.shape)\n",
        "print(\"y_train: \", y_train.shape)\n",
        "print(\"y_val: \", y_val.shape)\n",
        "print(\"y_test: \", y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Js9_qq2glyhG"
      },
      "outputs": [],
      "source": [
        "def see_balance_in_set(set):\n",
        "    print(np.unique(set.ravel(), return_counts = True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvGXLke5lyhG",
        "outputId": "409339cd-0115-4d89-c684-5b4871259585"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([0, 1], dtype=int32), array([1266, 1235]))\n",
            "(array([0, 1], dtype=int32), array([366, 416]))\n",
            "(array([0, 1], dtype=int32), array([323, 303]))\n"
          ]
        }
      ],
      "source": [
        "# Check if classes are balanced\n",
        "see_balance_in_set(y_train)\n",
        "see_balance_in_set(y_val)\n",
        "see_balance_in_set(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVsZulq5lyhH"
      },
      "source": [
        "## Own architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_z1XuH5hYoT",
        "outputId": "67423cf4-75c5-4c1f-fe96-d1eae61eaa60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 20, 20, 32)        4064      \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 20, 20, 32)       128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " activation (Activation)     (None, 20, 20, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 18, 18, 32)        9248      \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 18, 18, 32)        0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 18, 18, 32)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 18, 18, 64)        18496     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 18, 18, 64)        0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 18, 18, 64)        0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 17, 17, 64)        16448     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 17, 17, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 17, 17, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 8, 8, 64)         0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 4096)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               2097664   \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,146,817\n",
            "Trainable params: 2,146,625\n",
            "Non-trainable params: 192\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "\n",
        "# 1st Conv layer\n",
        "model.add(Conv2D(32, (3, 3), padding = \"same\", input_shape = (20, 20, 14)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(\"relu\"))\n",
        "\n",
        "# 2nd Conv layer\n",
        "model.add(Conv2D(32, (3, 3), padding = \"valid\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# 3rd conv layer\n",
        "model.add(Conv2D(64, (3, 3), padding = \"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# 4th conv layer\n",
        "model.add(Conv2D(64, (2, 2), padding = \"valid\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPool2D(2, 2))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Dense layer\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation = \"relu\"))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(1, activation = \"sigmoid\"))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ff4NE23d5bIw"
      },
      "outputs": [],
      "source": [
        "# scheduler that got 77% acc\n",
        "def scheduler(epoch, lr):\n",
        "   l = 0.0001\n",
        "   if epoch > 150:\n",
        "       l = 0.00001\n",
        "\n",
        "   return l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpCpqyiU5jxX"
      },
      "outputs": [],
      "source": [
        "callback = LearningRateScheduler(scheduler, verbose = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9AeNtAU9lyhI"
      },
      "outputs": [],
      "source": [
        "optim = optimizers.Adam()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTf-izn2lyhI"
      },
      "outputs": [],
      "source": [
        "model.compile(loss = \"binary_crossentropy\",\n",
        "              optimizer = optim,\n",
        "              metrics = [\"acc\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vu23tUf5lyhI",
        "outputId": "77da5cb4-a8f8-4204-9c67-25a860f92081"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 1/1000\n",
            "20/20 [==============================] - 14s 40ms/step - loss: 1.1998 - acc: 0.4942 - val_loss: 0.7382 - val_acc: 0.5128 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 2/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.9738 - acc: 0.5166 - val_loss: 0.7012 - val_acc: 0.5080 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 3/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.8923 - acc: 0.4934 - val_loss: 0.7326 - val_acc: 0.5128 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 4/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.7984 - acc: 0.5202 - val_loss: 0.7049 - val_acc: 0.5128 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 5/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.7524 - acc: 0.5170 - val_loss: 0.6994 - val_acc: 0.5128 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 6/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.7363 - acc: 0.5306 - val_loss: 0.6896 - val_acc: 0.5128 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 7/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.7256 - acc: 0.5338 - val_loss: 0.6867 - val_acc: 0.5128 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 8/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.7310 - acc: 0.5102 - val_loss: 0.6840 - val_acc: 0.5032 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 9/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.7062 - acc: 0.5378 - val_loss: 0.6821 - val_acc: 0.5591 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 10/1000\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.7041 - acc: 0.5222 - val_loss: 0.6798 - val_acc: 0.5911 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 11/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.7048 - acc: 0.5458 - val_loss: 0.6786 - val_acc: 0.6054 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 12/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.6900 - acc: 0.5554 - val_loss: 0.6784 - val_acc: 0.5831 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 13/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.6992 - acc: 0.5370 - val_loss: 0.6769 - val_acc: 0.5751 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 14/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.6890 - acc: 0.5526 - val_loss: 0.6746 - val_acc: 0.6134 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 15/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.6840 - acc: 0.5558 - val_loss: 0.6745 - val_acc: 0.6246 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 16: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 16/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.6886 - acc: 0.5646 - val_loss: 0.6735 - val_acc: 0.6038 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 17: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 17/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.6800 - acc: 0.5678 - val_loss: 0.6715 - val_acc: 0.6134 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 18: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 18/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.6904 - acc: 0.5570 - val_loss: 0.6709 - val_acc: 0.6022 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 19: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 19/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.6759 - acc: 0.5638 - val_loss: 0.6702 - val_acc: 0.5958 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 20: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 20/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.6740 - acc: 0.5754 - val_loss: 0.6691 - val_acc: 0.6230 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 21: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 21/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.6687 - acc: 0.5910 - val_loss: 0.6666 - val_acc: 0.6182 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 22: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 22/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.6711 - acc: 0.5750 - val_loss: 0.6651 - val_acc: 0.6645 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 23: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 23/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.6638 - acc: 0.5938 - val_loss: 0.6661 - val_acc: 0.6134 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 24: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 24/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.6656 - acc: 0.5798 - val_loss: 0.6651 - val_acc: 0.5687 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 25: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 25/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.6573 - acc: 0.5922 - val_loss: 0.6603 - val_acc: 0.6262 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 26: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 26/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.6543 - acc: 0.6118 - val_loss: 0.6562 - val_acc: 0.6422 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 27: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 27/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.6554 - acc: 0.6002 - val_loss: 0.6583 - val_acc: 0.6134 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 28: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 28/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.6447 - acc: 0.6058 - val_loss: 0.6508 - val_acc: 0.6374 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 29: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 29/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.6430 - acc: 0.6170 - val_loss: 0.6467 - val_acc: 0.6166 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 30: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 30/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.6486 - acc: 0.6242 - val_loss: 0.6507 - val_acc: 0.6134 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 31: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 31/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.6390 - acc: 0.6234 - val_loss: 0.6606 - val_acc: 0.5911 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 32: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 32/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.6338 - acc: 0.6345 - val_loss: 0.6596 - val_acc: 0.6006 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 33: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 33/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.6228 - acc: 0.6465 - val_loss: 0.6483 - val_acc: 0.6006 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 34: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 34/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.6161 - acc: 0.6421 - val_loss: 0.6462 - val_acc: 0.6102 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 35: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 35/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.6068 - acc: 0.6473 - val_loss: 0.6650 - val_acc: 0.5751 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 36: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 36/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.6001 - acc: 0.6701 - val_loss: 0.6520 - val_acc: 0.5974 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 37: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 37/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.6024 - acc: 0.6681 - val_loss: 0.6518 - val_acc: 0.6006 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 38: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 38/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.5914 - acc: 0.6729 - val_loss: 0.6430 - val_acc: 0.6102 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 39: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 39/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.5941 - acc: 0.6557 - val_loss: 0.6474 - val_acc: 0.5831 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 40: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 40/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.5865 - acc: 0.6685 - val_loss: 0.6194 - val_acc: 0.6166 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 41: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 41/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.5743 - acc: 0.6921 - val_loss: 0.6554 - val_acc: 0.5783 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 42: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 42/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.5737 - acc: 0.6937 - val_loss: 0.6698 - val_acc: 0.5559 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 43: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 43/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.5691 - acc: 0.6949 - val_loss: 0.6626 - val_acc: 0.5623 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 44: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 44/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.5639 - acc: 0.6873 - val_loss: 0.6279 - val_acc: 0.6022 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 45: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 45/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.5565 - acc: 0.7049 - val_loss: 0.6868 - val_acc: 0.5639 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 46: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 46/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.5621 - acc: 0.7041 - val_loss: 0.6066 - val_acc: 0.6486 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 47: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 47/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.5570 - acc: 0.6917 - val_loss: 0.6090 - val_acc: 0.6789 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 48: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 48/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.5425 - acc: 0.7261 - val_loss: 0.7086 - val_acc: 0.5703 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 49: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 49/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.5426 - acc: 0.7217 - val_loss: 0.6469 - val_acc: 0.6374 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 50: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 50/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.5278 - acc: 0.7405 - val_loss: 0.6369 - val_acc: 0.6470 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 51: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 51/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.5253 - acc: 0.7397 - val_loss: 0.6923 - val_acc: 0.6022 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 52: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 52/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.5342 - acc: 0.7261 - val_loss: 0.6462 - val_acc: 0.6070 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 53: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 53/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.5217 - acc: 0.7377 - val_loss: 0.6690 - val_acc: 0.6198 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 54: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 54/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.5119 - acc: 0.7553 - val_loss: 0.7089 - val_acc: 0.5990 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 55: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 55/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.5150 - acc: 0.7489 - val_loss: 0.7120 - val_acc: 0.5815 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 56: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 56/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.5022 - acc: 0.7629 - val_loss: 0.6808 - val_acc: 0.5479 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 57: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 57/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.4995 - acc: 0.7501 - val_loss: 0.6763 - val_acc: 0.5895 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 58: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 58/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.4911 - acc: 0.7629 - val_loss: 0.6641 - val_acc: 0.6326 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 59: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 59/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.4930 - acc: 0.7633 - val_loss: 0.6190 - val_acc: 0.6709 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 60: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 60/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.4963 - acc: 0.7589 - val_loss: 0.6991 - val_acc: 0.6038 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 61: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 61/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.4896 - acc: 0.7525 - val_loss: 0.6621 - val_acc: 0.6342 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 62: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 62/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.4840 - acc: 0.7709 - val_loss: 0.6172 - val_acc: 0.6565 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 63: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 63/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.4785 - acc: 0.7697 - val_loss: 0.6878 - val_acc: 0.5990 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 64: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 64/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.4839 - acc: 0.7713 - val_loss: 0.6196 - val_acc: 0.6406 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 65: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 65/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.4715 - acc: 0.7813 - val_loss: 0.7969 - val_acc: 0.5847 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 66: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 66/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.4686 - acc: 0.7749 - val_loss: 0.8059 - val_acc: 0.5863 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 67: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 67/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.4722 - acc: 0.7837 - val_loss: 0.6652 - val_acc: 0.6438 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 68: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 68/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.4690 - acc: 0.7709 - val_loss: 0.6415 - val_acc: 0.6438 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 69: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 69/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.4687 - acc: 0.7801 - val_loss: 0.5700 - val_acc: 0.6773 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 70: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 70/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.4636 - acc: 0.7717 - val_loss: 0.6290 - val_acc: 0.6422 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 71: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 71/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.4583 - acc: 0.7769 - val_loss: 0.6733 - val_acc: 0.6182 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 72: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 72/1000\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.4594 - acc: 0.7809 - val_loss: 0.5552 - val_acc: 0.6917 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 73: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 73/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.4511 - acc: 0.7821 - val_loss: 0.7141 - val_acc: 0.5990 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 74: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 74/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.4526 - acc: 0.7833 - val_loss: 0.6174 - val_acc: 0.6406 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 75: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 75/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.4549 - acc: 0.7797 - val_loss: 0.5718 - val_acc: 0.6789 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 76: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 76/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.4483 - acc: 0.7873 - val_loss: 0.5668 - val_acc: 0.7188 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 77: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 77/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.4401 - acc: 0.7893 - val_loss: 0.5780 - val_acc: 0.7125 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 78: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 78/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.4461 - acc: 0.7857 - val_loss: 0.6752 - val_acc: 0.6629 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 79: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 79/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.4420 - acc: 0.7841 - val_loss: 0.5719 - val_acc: 0.7236 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 80: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 80/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.4407 - acc: 0.7825 - val_loss: 0.5904 - val_acc: 0.6885 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 81: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 81/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.4398 - acc: 0.7837 - val_loss: 0.6994 - val_acc: 0.6198 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 82: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 82/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.4361 - acc: 0.7901 - val_loss: 0.5406 - val_acc: 0.7157 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 83: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 83/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.4316 - acc: 0.7937 - val_loss: 0.5756 - val_acc: 0.6933 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 84: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 84/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.4326 - acc: 0.7957 - val_loss: 0.7671 - val_acc: 0.6166 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 85: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 85/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.4332 - acc: 0.7961 - val_loss: 0.5687 - val_acc: 0.7268 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 86: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 86/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.4347 - acc: 0.7833 - val_loss: 0.6431 - val_acc: 0.6597 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 87: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 87/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.4261 - acc: 0.7901 - val_loss: 0.6564 - val_acc: 0.6789 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 88: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 88/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.4114 - acc: 0.7989 - val_loss: 0.5669 - val_acc: 0.7013 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 89: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 89/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.4149 - acc: 0.8053 - val_loss: 0.5294 - val_acc: 0.7300 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 90: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 90/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.4169 - acc: 0.7957 - val_loss: 0.6446 - val_acc: 0.6725 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 91: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 91/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.4234 - acc: 0.7945 - val_loss: 0.6576 - val_acc: 0.6965 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 92: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 92/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.4100 - acc: 0.8041 - val_loss: 0.5264 - val_acc: 0.7396 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 93: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 93/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.4173 - acc: 0.7881 - val_loss: 0.7408 - val_acc: 0.6006 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 94: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 94/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.4148 - acc: 0.7965 - val_loss: 0.5400 - val_acc: 0.7508 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 95: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 95/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.4101 - acc: 0.7957 - val_loss: 0.5241 - val_acc: 0.7444 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 96: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 96/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.4060 - acc: 0.8029 - val_loss: 0.6478 - val_acc: 0.6965 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 97: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 97/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.4050 - acc: 0.8077 - val_loss: 0.6124 - val_acc: 0.6853 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 98: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 98/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.4047 - acc: 0.8025 - val_loss: 0.6252 - val_acc: 0.7109 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 99: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 99/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3985 - acc: 0.8069 - val_loss: 0.7303 - val_acc: 0.6821 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 100: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 100/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.4075 - acc: 0.7973 - val_loss: 0.5607 - val_acc: 0.7252 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 101: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 101/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.4019 - acc: 0.8013 - val_loss: 0.9478 - val_acc: 0.6278 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 102: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 102/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3994 - acc: 0.8077 - val_loss: 0.5886 - val_acc: 0.6773 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 103: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 103/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.4002 - acc: 0.8101 - val_loss: 0.8082 - val_acc: 0.6294 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 104: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 104/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3896 - acc: 0.8009 - val_loss: 0.6187 - val_acc: 0.7125 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 105: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 105/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.4019 - acc: 0.8069 - val_loss: 0.6865 - val_acc: 0.6821 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 106: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 106/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3968 - acc: 0.7957 - val_loss: 0.6925 - val_acc: 0.6885 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 107: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 107/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3891 - acc: 0.8005 - val_loss: 0.6464 - val_acc: 0.6997 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 108: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 108/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3912 - acc: 0.8041 - val_loss: 0.5966 - val_acc: 0.7252 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 109: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 109/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3838 - acc: 0.8077 - val_loss: 0.5478 - val_acc: 0.7428 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 110: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 110/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3878 - acc: 0.7981 - val_loss: 0.8276 - val_acc: 0.6821 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 111: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 111/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3936 - acc: 0.8069 - val_loss: 0.9788 - val_acc: 0.6581 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 112: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 112/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3894 - acc: 0.7977 - val_loss: 0.5804 - val_acc: 0.7588 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 113: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 113/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3893 - acc: 0.8049 - val_loss: 0.7368 - val_acc: 0.6885 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 114: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 114/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3748 - acc: 0.8093 - val_loss: 0.6313 - val_acc: 0.7077 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 115: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 115/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3855 - acc: 0.8089 - val_loss: 0.6642 - val_acc: 0.7157 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 116: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 116/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3848 - acc: 0.8137 - val_loss: 0.6355 - val_acc: 0.6789 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 117: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 117/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3728 - acc: 0.8121 - val_loss: 0.5367 - val_acc: 0.7252 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 118: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 118/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3763 - acc: 0.8185 - val_loss: 0.5600 - val_acc: 0.7173 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 119: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 119/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3713 - acc: 0.8177 - val_loss: 0.6918 - val_acc: 0.6981 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 120: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 120/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3760 - acc: 0.8145 - val_loss: 0.7592 - val_acc: 0.7332 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 121: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 121/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3808 - acc: 0.8061 - val_loss: 0.8122 - val_acc: 0.6677 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 122: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 122/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3721 - acc: 0.8125 - val_loss: 0.6451 - val_acc: 0.7540 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 123: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 123/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3825 - acc: 0.8117 - val_loss: 0.6576 - val_acc: 0.7125 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 124: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 124/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3730 - acc: 0.8085 - val_loss: 0.5088 - val_acc: 0.7412 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 125: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 125/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3571 - acc: 0.8289 - val_loss: 0.5450 - val_acc: 0.7444 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 126: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 126/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3630 - acc: 0.8273 - val_loss: 0.6218 - val_acc: 0.7220 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 127: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 127/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3582 - acc: 0.8189 - val_loss: 0.7641 - val_acc: 0.6629 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 128: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 128/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3724 - acc: 0.8133 - val_loss: 0.5289 - val_acc: 0.7652 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 129: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 129/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3617 - acc: 0.8213 - val_loss: 0.5824 - val_acc: 0.7284 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 130: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 130/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3569 - acc: 0.8249 - val_loss: 0.6068 - val_acc: 0.7380 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 131: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 131/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3622 - acc: 0.8253 - val_loss: 0.6462 - val_acc: 0.6901 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 132: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 132/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3637 - acc: 0.8109 - val_loss: 0.5211 - val_acc: 0.7476 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 133: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 133/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3577 - acc: 0.8129 - val_loss: 0.6013 - val_acc: 0.7364 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 134: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 134/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3595 - acc: 0.8145 - val_loss: 0.5754 - val_acc: 0.7508 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 135: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 135/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3619 - acc: 0.8181 - val_loss: 0.7542 - val_acc: 0.7093 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 136: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 136/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3582 - acc: 0.8193 - val_loss: 0.5547 - val_acc: 0.7508 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 137: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 137/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3585 - acc: 0.8297 - val_loss: 0.5502 - val_acc: 0.7524 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 138: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 138/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3536 - acc: 0.8185 - val_loss: 0.5354 - val_acc: 0.7364 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 139: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 139/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3543 - acc: 0.8213 - val_loss: 0.5750 - val_acc: 0.7428 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 140: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 140/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3556 - acc: 0.8209 - val_loss: 0.6613 - val_acc: 0.7412 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 141: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 141/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3550 - acc: 0.8225 - val_loss: 0.5711 - val_acc: 0.7444 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 142: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 142/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3457 - acc: 0.8301 - val_loss: 0.6664 - val_acc: 0.7300 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 143: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 143/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3402 - acc: 0.8281 - val_loss: 0.5651 - val_acc: 0.7252 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 144: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 144/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3496 - acc: 0.8193 - val_loss: 0.5368 - val_acc: 0.7556 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 145: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 145/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3360 - acc: 0.8309 - val_loss: 0.6472 - val_acc: 0.7173 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 146: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 146/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3440 - acc: 0.8273 - val_loss: 0.5518 - val_acc: 0.7492 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 147: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 147/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3287 - acc: 0.8393 - val_loss: 0.5796 - val_acc: 0.7125 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 148: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 148/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3393 - acc: 0.8265 - val_loss: 0.6327 - val_acc: 0.6821 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 149: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 149/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3389 - acc: 0.8285 - val_loss: 0.6561 - val_acc: 0.7125 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 150: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 150/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3433 - acc: 0.8265 - val_loss: 0.6140 - val_acc: 0.7029 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 151: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 151/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3350 - acc: 0.8413 - val_loss: 0.7626 - val_acc: 0.7173 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 152: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 152/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3352 - acc: 0.8333 - val_loss: 0.5541 - val_acc: 0.7396 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 153: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 153/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3318 - acc: 0.8277 - val_loss: 0.5375 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 154: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 154/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3300 - acc: 0.8285 - val_loss: 0.5315 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 155: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 155/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3205 - acc: 0.8401 - val_loss: 0.5454 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 156: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 156/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3279 - acc: 0.8333 - val_loss: 0.5447 - val_acc: 0.7556 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 157: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 157/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3186 - acc: 0.8497 - val_loss: 0.5433 - val_acc: 0.7556 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 158: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 158/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3250 - acc: 0.8333 - val_loss: 0.5378 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 159: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 159/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3278 - acc: 0.8273 - val_loss: 0.5471 - val_acc: 0.7540 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 160: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 160/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3207 - acc: 0.8381 - val_loss: 0.5476 - val_acc: 0.7540 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 161: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 161/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3236 - acc: 0.8389 - val_loss: 0.5433 - val_acc: 0.7604 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 162: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 162/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3261 - acc: 0.8409 - val_loss: 0.5424 - val_acc: 0.7556 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 163: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 163/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3198 - acc: 0.8397 - val_loss: 0.5479 - val_acc: 0.7604 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 164: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 164/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3237 - acc: 0.8377 - val_loss: 0.5489 - val_acc: 0.7540 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 165: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 165/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3242 - acc: 0.8405 - val_loss: 0.5546 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 166: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 166/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3176 - acc: 0.8377 - val_loss: 0.5571 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 167: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 167/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3126 - acc: 0.8421 - val_loss: 0.5588 - val_acc: 0.7572 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 168: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 168/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3168 - acc: 0.8365 - val_loss: 0.5569 - val_acc: 0.7572 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 169: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 169/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3191 - acc: 0.8449 - val_loss: 0.5659 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 170: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 170/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3274 - acc: 0.8353 - val_loss: 0.5753 - val_acc: 0.7572 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 171: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 171/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3221 - acc: 0.8353 - val_loss: 0.5621 - val_acc: 0.7652 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 172: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 172/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3234 - acc: 0.8325 - val_loss: 0.5606 - val_acc: 0.7540 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 173: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 173/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3297 - acc: 0.8301 - val_loss: 0.5639 - val_acc: 0.7636 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 174: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 174/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3185 - acc: 0.8337 - val_loss: 0.5612 - val_acc: 0.7620 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 175: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 175/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3215 - acc: 0.8397 - val_loss: 0.5536 - val_acc: 0.7604 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 176: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 176/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3210 - acc: 0.8445 - val_loss: 0.5542 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 177: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 177/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3308 - acc: 0.8269 - val_loss: 0.5684 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 178: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 178/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3247 - acc: 0.8405 - val_loss: 0.5623 - val_acc: 0.7588 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 179: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 179/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3230 - acc: 0.8333 - val_loss: 0.5585 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 180: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 180/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3118 - acc: 0.8465 - val_loss: 0.5750 - val_acc: 0.7556 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 181: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 181/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3271 - acc: 0.8393 - val_loss: 0.5753 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 182: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 182/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3275 - acc: 0.8301 - val_loss: 0.5725 - val_acc: 0.7604 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 183: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 183/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3210 - acc: 0.8369 - val_loss: 0.5724 - val_acc: 0.7636 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 184: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 184/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3141 - acc: 0.8401 - val_loss: 0.5745 - val_acc: 0.7588 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 185: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 185/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3165 - acc: 0.8413 - val_loss: 0.5667 - val_acc: 0.7572 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 186: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 186/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3179 - acc: 0.8381 - val_loss: 0.5593 - val_acc: 0.7620 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 187: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 187/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3165 - acc: 0.8481 - val_loss: 0.5548 - val_acc: 0.7652 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 188: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 188/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3173 - acc: 0.8433 - val_loss: 0.5500 - val_acc: 0.7620 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 189: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 189/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3233 - acc: 0.8373 - val_loss: 0.5513 - val_acc: 0.7556 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 190: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 190/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3264 - acc: 0.8373 - val_loss: 0.5585 - val_acc: 0.7572 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 191: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 191/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3092 - acc: 0.8469 - val_loss: 0.5686 - val_acc: 0.7668 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 192: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 192/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3182 - acc: 0.8381 - val_loss: 0.5580 - val_acc: 0.7668 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 193: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 193/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3262 - acc: 0.8285 - val_loss: 0.5674 - val_acc: 0.7620 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 194: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 194/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3208 - acc: 0.8409 - val_loss: 0.5876 - val_acc: 0.7604 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 195: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 195/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3242 - acc: 0.8377 - val_loss: 0.5758 - val_acc: 0.7540 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 196: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 196/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3141 - acc: 0.8393 - val_loss: 0.5638 - val_acc: 0.7556 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 197: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 197/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3228 - acc: 0.8405 - val_loss: 0.5654 - val_acc: 0.7636 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 198: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 198/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3217 - acc: 0.8393 - val_loss: 0.5601 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 199: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 199/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3175 - acc: 0.8457 - val_loss: 0.5556 - val_acc: 0.7540 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 200: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 200/1000\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.3118 - acc: 0.8437 - val_loss: 0.5643 - val_acc: 0.7604 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 201: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 201/1000\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.3140 - acc: 0.8305 - val_loss: 0.5638 - val_acc: 0.7540 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 202: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 202/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3116 - acc: 0.8433 - val_loss: 0.5720 - val_acc: 0.7572 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 203: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 203/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3274 - acc: 0.8389 - val_loss: 0.5671 - val_acc: 0.7604 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 204: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 204/1000\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.3168 - acc: 0.8349 - val_loss: 0.5582 - val_acc: 0.7604 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 205: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 205/1000\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.3210 - acc: 0.8477 - val_loss: 0.5748 - val_acc: 0.7620 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 206: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 206/1000\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.3153 - acc: 0.8353 - val_loss: 0.5748 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 207: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 207/1000\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.3111 - acc: 0.8429 - val_loss: 0.5828 - val_acc: 0.7556 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 208: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 208/1000\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.3055 - acc: 0.8421 - val_loss: 0.5702 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 209: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 209/1000\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.3165 - acc: 0.8409 - val_loss: 0.5680 - val_acc: 0.7540 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 210: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 210/1000\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.3057 - acc: 0.8433 - val_loss: 0.5930 - val_acc: 0.7572 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 211: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 211/1000\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.3189 - acc: 0.8329 - val_loss: 0.5823 - val_acc: 0.7620 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 212: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 212/1000\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.3201 - acc: 0.8357 - val_loss: 0.5806 - val_acc: 0.7604 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 213: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 213/1000\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.3285 - acc: 0.8313 - val_loss: 0.5590 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 214: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 214/1000\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.3149 - acc: 0.8397 - val_loss: 0.5663 - val_acc: 0.7540 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 215: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 215/1000\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.3082 - acc: 0.8381 - val_loss: 0.5719 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 216: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 216/1000\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.3102 - acc: 0.8453 - val_loss: 0.5781 - val_acc: 0.7556 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 217: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 217/1000\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.3085 - acc: 0.8485 - val_loss: 0.5739 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 218: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 218/1000\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.3170 - acc: 0.8409 - val_loss: 0.5846 - val_acc: 0.7556 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 219: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 219/1000\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.3109 - acc: 0.8333 - val_loss: 0.5886 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 220: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 220/1000\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.3205 - acc: 0.8329 - val_loss: 0.5752 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 221: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 221/1000\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.3125 - acc: 0.8453 - val_loss: 0.5719 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 222: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 222/1000\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.3060 - acc: 0.8461 - val_loss: 0.5715 - val_acc: 0.7604 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 223: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 223/1000\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.3159 - acc: 0.8397 - val_loss: 0.5675 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 224: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 224/1000\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.3068 - acc: 0.8461 - val_loss: 0.5809 - val_acc: 0.7604 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 225: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 225/1000\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.3141 - acc: 0.8477 - val_loss: 0.5776 - val_acc: 0.7572 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 226: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 226/1000\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.3123 - acc: 0.8505 - val_loss: 0.5835 - val_acc: 0.7588 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 227: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 227/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3167 - acc: 0.8377 - val_loss: 0.5909 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 228: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 228/1000\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.3090 - acc: 0.8461 - val_loss: 0.5984 - val_acc: 0.7572 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 229: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 229/1000\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.3098 - acc: 0.8441 - val_loss: 0.5865 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 230: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 230/1000\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.3136 - acc: 0.8489 - val_loss: 0.5850 - val_acc: 0.7396 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 231: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 231/1000\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.3111 - acc: 0.8433 - val_loss: 0.5840 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 232: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 232/1000\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.3138 - acc: 0.8405 - val_loss: 0.5862 - val_acc: 0.7636 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 233: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 233/1000\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.3119 - acc: 0.8489 - val_loss: 0.5900 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 234: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 234/1000\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.3164 - acc: 0.8377 - val_loss: 0.5816 - val_acc: 0.7620 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 235: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 235/1000\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.3119 - acc: 0.8469 - val_loss: 0.5884 - val_acc: 0.7540 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 236: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 236/1000\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.3058 - acc: 0.8417 - val_loss: 0.5805 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 237: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 237/1000\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.3120 - acc: 0.8385 - val_loss: 0.5794 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 238: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 238/1000\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.3174 - acc: 0.8401 - val_loss: 0.5882 - val_acc: 0.7556 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 239: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 239/1000\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.3323 - acc: 0.8301 - val_loss: 0.5892 - val_acc: 0.7588 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 240: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 240/1000\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.3123 - acc: 0.8409 - val_loss: 0.5831 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 241: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 241/1000\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.3111 - acc: 0.8413 - val_loss: 0.5859 - val_acc: 0.7668 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 242: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 242/1000\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.3154 - acc: 0.8361 - val_loss: 0.5738 - val_acc: 0.7556 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 243: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 243/1000\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.3146 - acc: 0.8413 - val_loss: 0.5844 - val_acc: 0.7684 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 244: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 244/1000\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.3067 - acc: 0.8417 - val_loss: 0.5761 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 245: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 245/1000\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.3158 - acc: 0.8409 - val_loss: 0.5944 - val_acc: 0.7620 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 246: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 246/1000\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.3109 - acc: 0.8413 - val_loss: 0.5919 - val_acc: 0.7604 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 247: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 247/1000\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.3092 - acc: 0.8341 - val_loss: 0.6022 - val_acc: 0.7588 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 248: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 248/1000\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.3011 - acc: 0.8397 - val_loss: 0.6069 - val_acc: 0.7604 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 249: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 249/1000\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.3062 - acc: 0.8413 - val_loss: 0.5872 - val_acc: 0.7540 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 250: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 250/1000\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.3082 - acc: 0.8441 - val_loss: 0.6045 - val_acc: 0.7588 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 251: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 251/1000\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.3145 - acc: 0.8297 - val_loss: 0.6111 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 252: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 252/1000\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.3095 - acc: 0.8377 - val_loss: 0.5995 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 253: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 253/1000\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.3158 - acc: 0.8437 - val_loss: 0.6028 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 254: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 254/1000\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.3116 - acc: 0.8389 - val_loss: 0.5998 - val_acc: 0.7428 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 255: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 255/1000\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.3067 - acc: 0.8465 - val_loss: 0.5952 - val_acc: 0.7588 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 256: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 256/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3196 - acc: 0.8361 - val_loss: 0.5809 - val_acc: 0.7556 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 257: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 257/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3079 - acc: 0.8533 - val_loss: 0.5996 - val_acc: 0.7620 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 258: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 258/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3075 - acc: 0.8437 - val_loss: 0.6082 - val_acc: 0.7556 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 259: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 259/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3138 - acc: 0.8393 - val_loss: 0.5925 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 260: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 260/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3073 - acc: 0.8445 - val_loss: 0.5975 - val_acc: 0.7540 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 261: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 261/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3078 - acc: 0.8413 - val_loss: 0.6044 - val_acc: 0.7620 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 262: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 262/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3129 - acc: 0.8405 - val_loss: 0.5903 - val_acc: 0.7540 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 263: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 263/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3151 - acc: 0.8365 - val_loss: 0.5948 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 264: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 264/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3116 - acc: 0.8461 - val_loss: 0.5845 - val_acc: 0.7556 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 265: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 265/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3163 - acc: 0.8429 - val_loss: 0.5838 - val_acc: 0.7556 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 266: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 266/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3101 - acc: 0.8429 - val_loss: 0.5829 - val_acc: 0.7636 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 267: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 267/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3061 - acc: 0.8417 - val_loss: 0.5908 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 268: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 268/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3016 - acc: 0.8473 - val_loss: 0.5993 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 269: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 269/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3149 - acc: 0.8461 - val_loss: 0.5988 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 270: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 270/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3083 - acc: 0.8429 - val_loss: 0.6239 - val_acc: 0.7588 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 271: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 271/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3116 - acc: 0.8469 - val_loss: 0.6073 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 272: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 272/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3131 - acc: 0.8465 - val_loss: 0.5909 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 273: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 273/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3069 - acc: 0.8521 - val_loss: 0.5964 - val_acc: 0.7428 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 274: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 274/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3151 - acc: 0.8409 - val_loss: 0.6087 - val_acc: 0.7588 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 275: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 275/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3102 - acc: 0.8409 - val_loss: 0.6071 - val_acc: 0.7556 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 276: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 276/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3119 - acc: 0.8421 - val_loss: 0.5941 - val_acc: 0.7620 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 277: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 277/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3124 - acc: 0.8405 - val_loss: 0.5829 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 278: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 278/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3060 - acc: 0.8449 - val_loss: 0.6083 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 279: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 279/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3105 - acc: 0.8493 - val_loss: 0.5980 - val_acc: 0.7588 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 280: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 280/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3073 - acc: 0.8441 - val_loss: 0.5888 - val_acc: 0.7636 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 281: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 281/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3103 - acc: 0.8481 - val_loss: 0.5922 - val_acc: 0.7588 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 282: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 282/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3122 - acc: 0.8361 - val_loss: 0.5909 - val_acc: 0.7540 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 283: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 283/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3042 - acc: 0.8485 - val_loss: 0.6156 - val_acc: 0.7572 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 284: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 284/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3077 - acc: 0.8477 - val_loss: 0.6016 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 285: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 285/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3103 - acc: 0.8505 - val_loss: 0.5849 - val_acc: 0.7556 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 286: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 286/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3124 - acc: 0.8449 - val_loss: 0.5946 - val_acc: 0.7636 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 287: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 287/1000\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.3128 - acc: 0.8429 - val_loss: 0.5890 - val_acc: 0.7636 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 288: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 288/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2990 - acc: 0.8417 - val_loss: 0.5991 - val_acc: 0.7604 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 289: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 289/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3133 - acc: 0.8433 - val_loss: 0.5975 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 290: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 290/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3000 - acc: 0.8481 - val_loss: 0.6122 - val_acc: 0.7588 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 291: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 291/1000\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.3108 - acc: 0.8449 - val_loss: 0.5909 - val_acc: 0.7588 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 292: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 292/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3090 - acc: 0.8477 - val_loss: 0.6082 - val_acc: 0.7556 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 293: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 293/1000\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.3204 - acc: 0.8437 - val_loss: 0.6045 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 294: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 294/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3002 - acc: 0.8433 - val_loss: 0.6052 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 295: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 295/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3063 - acc: 0.8413 - val_loss: 0.6039 - val_acc: 0.7556 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 296: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 296/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3095 - acc: 0.8497 - val_loss: 0.6093 - val_acc: 0.7540 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 297: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 297/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3029 - acc: 0.8469 - val_loss: 0.5895 - val_acc: 0.7556 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 298: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 298/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3085 - acc: 0.8461 - val_loss: 0.6042 - val_acc: 0.7588 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 299: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 299/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3115 - acc: 0.8413 - val_loss: 0.5961 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 300: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 300/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3099 - acc: 0.8461 - val_loss: 0.5984 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 301: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 301/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3073 - acc: 0.8477 - val_loss: 0.6221 - val_acc: 0.7588 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 302: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 302/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3100 - acc: 0.8433 - val_loss: 0.5990 - val_acc: 0.7588 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 303: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 303/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3074 - acc: 0.8457 - val_loss: 0.6104 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 304: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 304/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3089 - acc: 0.8453 - val_loss: 0.5993 - val_acc: 0.7604 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 305: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 305/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3064 - acc: 0.8581 - val_loss: 0.5932 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 306: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 306/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3047 - acc: 0.8481 - val_loss: 0.6145 - val_acc: 0.7620 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 307: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 307/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3103 - acc: 0.8461 - val_loss: 0.6042 - val_acc: 0.7588 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 308: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 308/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3029 - acc: 0.8437 - val_loss: 0.6014 - val_acc: 0.7380 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 309: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 309/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3020 - acc: 0.8505 - val_loss: 0.6084 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 310: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 310/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3069 - acc: 0.8457 - val_loss: 0.5951 - val_acc: 0.7556 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 311: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 311/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3096 - acc: 0.8457 - val_loss: 0.5971 - val_acc: 0.7396 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 312: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 312/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3136 - acc: 0.8405 - val_loss: 0.6044 - val_acc: 0.7588 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 313: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 313/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3029 - acc: 0.8477 - val_loss: 0.6038 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 314: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 314/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3013 - acc: 0.8469 - val_loss: 0.6055 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 315: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 315/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3075 - acc: 0.8489 - val_loss: 0.6133 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 316: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 316/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2965 - acc: 0.8505 - val_loss: 0.6067 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 317: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 317/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3039 - acc: 0.8449 - val_loss: 0.6135 - val_acc: 0.7540 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 318: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 318/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3057 - acc: 0.8513 - val_loss: 0.6097 - val_acc: 0.7572 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 319: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 319/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2908 - acc: 0.8525 - val_loss: 0.6129 - val_acc: 0.7556 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 320: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 320/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3064 - acc: 0.8509 - val_loss: 0.6164 - val_acc: 0.7652 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 321: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 321/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3110 - acc: 0.8505 - val_loss: 0.6139 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 322: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 322/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3089 - acc: 0.8401 - val_loss: 0.6149 - val_acc: 0.7556 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 323: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 323/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3024 - acc: 0.8473 - val_loss: 0.6143 - val_acc: 0.7572 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 324: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 324/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3045 - acc: 0.8449 - val_loss: 0.6139 - val_acc: 0.7636 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 325: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 325/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3039 - acc: 0.8437 - val_loss: 0.6304 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 326: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 326/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3006 - acc: 0.8453 - val_loss: 0.5946 - val_acc: 0.7396 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 327: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 327/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3064 - acc: 0.8449 - val_loss: 0.5982 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 328: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 328/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2954 - acc: 0.8505 - val_loss: 0.6010 - val_acc: 0.7572 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 329: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 329/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3006 - acc: 0.8517 - val_loss: 0.6192 - val_acc: 0.7540 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 330: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 330/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3083 - acc: 0.8417 - val_loss: 0.6138 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 331: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 331/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3003 - acc: 0.8497 - val_loss: 0.6171 - val_acc: 0.7396 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 332: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 332/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3051 - acc: 0.8501 - val_loss: 0.6218 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 333: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 333/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2974 - acc: 0.8569 - val_loss: 0.6134 - val_acc: 0.7572 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 334: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 334/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3057 - acc: 0.8497 - val_loss: 0.6195 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 335: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 335/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3023 - acc: 0.8429 - val_loss: 0.6092 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 336: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 336/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3073 - acc: 0.8421 - val_loss: 0.6022 - val_acc: 0.7556 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 337: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 337/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2952 - acc: 0.8537 - val_loss: 0.5938 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 338: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 338/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2974 - acc: 0.8533 - val_loss: 0.6115 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 339: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 339/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3050 - acc: 0.8545 - val_loss: 0.6228 - val_acc: 0.7668 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 340: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 340/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3044 - acc: 0.8441 - val_loss: 0.6235 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 341: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 341/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3033 - acc: 0.8505 - val_loss: 0.6268 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 342: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 342/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2985 - acc: 0.8501 - val_loss: 0.6382 - val_acc: 0.7588 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 343: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 343/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2947 - acc: 0.8469 - val_loss: 0.6378 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 344: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 344/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2987 - acc: 0.8449 - val_loss: 0.6177 - val_acc: 0.7428 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 345: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 345/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2977 - acc: 0.8493 - val_loss: 0.6177 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 346: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 346/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2911 - acc: 0.8537 - val_loss: 0.6240 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 347: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 347/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2954 - acc: 0.8393 - val_loss: 0.6479 - val_acc: 0.7588 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 348: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 348/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2997 - acc: 0.8517 - val_loss: 0.6237 - val_acc: 0.7540 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 349: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 349/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2982 - acc: 0.8545 - val_loss: 0.6260 - val_acc: 0.7588 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 350: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 350/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3022 - acc: 0.8485 - val_loss: 0.6259 - val_acc: 0.7556 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 351: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 351/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3056 - acc: 0.8461 - val_loss: 0.6115 - val_acc: 0.7556 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 352: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 352/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2963 - acc: 0.8529 - val_loss: 0.6230 - val_acc: 0.7588 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 353: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 353/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2949 - acc: 0.8537 - val_loss: 0.6265 - val_acc: 0.7636 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 354: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 354/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2905 - acc: 0.8557 - val_loss: 0.6157 - val_acc: 0.7572 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 355: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 355/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2985 - acc: 0.8497 - val_loss: 0.6222 - val_acc: 0.7572 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 356: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 356/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2926 - acc: 0.8477 - val_loss: 0.6238 - val_acc: 0.7556 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 357: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 357/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3009 - acc: 0.8425 - val_loss: 0.6348 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 358: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 358/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2944 - acc: 0.8541 - val_loss: 0.6380 - val_acc: 0.7556 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 359: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 359/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2932 - acc: 0.8497 - val_loss: 0.6229 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 360: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 360/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3036 - acc: 0.8481 - val_loss: 0.6349 - val_acc: 0.7556 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 361: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 361/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2964 - acc: 0.8513 - val_loss: 0.6125 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 362: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 362/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3016 - acc: 0.8473 - val_loss: 0.6243 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 363: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 363/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3001 - acc: 0.8485 - val_loss: 0.6430 - val_acc: 0.7540 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 364: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 364/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2957 - acc: 0.8505 - val_loss: 0.6382 - val_acc: 0.7540 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 365: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 365/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2931 - acc: 0.8489 - val_loss: 0.6317 - val_acc: 0.7588 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 366: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 366/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2966 - acc: 0.8541 - val_loss: 0.6272 - val_acc: 0.7588 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 367: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 367/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2922 - acc: 0.8469 - val_loss: 0.6248 - val_acc: 0.7572 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 368: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 368/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2888 - acc: 0.8533 - val_loss: 0.6168 - val_acc: 0.7572 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 369: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 369/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3006 - acc: 0.8517 - val_loss: 0.6181 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 370: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 370/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2989 - acc: 0.8529 - val_loss: 0.6064 - val_acc: 0.7380 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 371: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 371/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3013 - acc: 0.8593 - val_loss: 0.6116 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 372: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 372/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2988 - acc: 0.8473 - val_loss: 0.6020 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 373: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 373/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2975 - acc: 0.8549 - val_loss: 0.6078 - val_acc: 0.7428 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 374: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 374/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2899 - acc: 0.8577 - val_loss: 0.6187 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 375: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 375/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2959 - acc: 0.8525 - val_loss: 0.6393 - val_acc: 0.7556 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 376: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 376/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3012 - acc: 0.8489 - val_loss: 0.6274 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 377: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 377/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3029 - acc: 0.8497 - val_loss: 0.6309 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 378: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 378/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3031 - acc: 0.8501 - val_loss: 0.6161 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 379: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 379/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3023 - acc: 0.8513 - val_loss: 0.6166 - val_acc: 0.7556 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 380: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 380/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3052 - acc: 0.8449 - val_loss: 0.6198 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 381: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 381/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2981 - acc: 0.8501 - val_loss: 0.6231 - val_acc: 0.7572 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 382: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 382/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2947 - acc: 0.8557 - val_loss: 0.6157 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 383: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 383/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2983 - acc: 0.8501 - val_loss: 0.6167 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 384: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 384/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3007 - acc: 0.8481 - val_loss: 0.6268 - val_acc: 0.7572 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 385: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 385/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2979 - acc: 0.8545 - val_loss: 0.6399 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 386: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 386/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3004 - acc: 0.8461 - val_loss: 0.6323 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 387: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 387/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2924 - acc: 0.8501 - val_loss: 0.6358 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 388: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 388/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3027 - acc: 0.8389 - val_loss: 0.6293 - val_acc: 0.7428 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 389: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 389/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2892 - acc: 0.8533 - val_loss: 0.6400 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 390: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 390/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2941 - acc: 0.8509 - val_loss: 0.6333 - val_acc: 0.7572 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 391: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 391/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3028 - acc: 0.8497 - val_loss: 0.6167 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 392: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 392/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3048 - acc: 0.8477 - val_loss: 0.6314 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 393: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 393/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2991 - acc: 0.8429 - val_loss: 0.6367 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 394: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 394/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2903 - acc: 0.8557 - val_loss: 0.6610 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 395: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 395/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3025 - acc: 0.8481 - val_loss: 0.6371 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 396: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 396/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3015 - acc: 0.8477 - val_loss: 0.6462 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 397: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 397/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3013 - acc: 0.8509 - val_loss: 0.6383 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 398: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 398/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2938 - acc: 0.8505 - val_loss: 0.6287 - val_acc: 0.7428 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 399: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 399/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2962 - acc: 0.8565 - val_loss: 0.6190 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 400: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 400/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2885 - acc: 0.8533 - val_loss: 0.6420 - val_acc: 0.7572 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 401: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 401/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2873 - acc: 0.8509 - val_loss: 0.6283 - val_acc: 0.7556 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 402: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 402/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2986 - acc: 0.8505 - val_loss: 0.6299 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 403: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 403/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2917 - acc: 0.8541 - val_loss: 0.6359 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 404: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 404/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3020 - acc: 0.8477 - val_loss: 0.6351 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 405: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 405/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2862 - acc: 0.8541 - val_loss: 0.6477 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 406: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 406/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3074 - acc: 0.8493 - val_loss: 0.6312 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 407: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 407/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2994 - acc: 0.8457 - val_loss: 0.6349 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 408: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 408/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2944 - acc: 0.8449 - val_loss: 0.6473 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 409: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 409/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2874 - acc: 0.8601 - val_loss: 0.6430 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 410: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 410/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2825 - acc: 0.8553 - val_loss: 0.6254 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 411: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 411/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2884 - acc: 0.8589 - val_loss: 0.6525 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 412: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 412/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2992 - acc: 0.8501 - val_loss: 0.6631 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 413: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 413/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2923 - acc: 0.8445 - val_loss: 0.6423 - val_acc: 0.7428 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 414: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 414/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2859 - acc: 0.8569 - val_loss: 0.6375 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 415: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 415/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2988 - acc: 0.8541 - val_loss: 0.6343 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 416: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 416/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2968 - acc: 0.8509 - val_loss: 0.6198 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 417: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 417/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2993 - acc: 0.8477 - val_loss: 0.6279 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 418: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 418/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2937 - acc: 0.8549 - val_loss: 0.6469 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 419: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 419/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2977 - acc: 0.8549 - val_loss: 0.6332 - val_acc: 0.7572 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 420: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 420/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2906 - acc: 0.8573 - val_loss: 0.6260 - val_acc: 0.7540 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 421: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 421/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2841 - acc: 0.8561 - val_loss: 0.6205 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 422: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 422/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2979 - acc: 0.8477 - val_loss: 0.6216 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 423: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 423/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2910 - acc: 0.8485 - val_loss: 0.6270 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 424: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 424/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2967 - acc: 0.8453 - val_loss: 0.6272 - val_acc: 0.7540 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 425: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 425/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3002 - acc: 0.8493 - val_loss: 0.6292 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 426: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 426/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2933 - acc: 0.8541 - val_loss: 0.6309 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 427: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 427/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2947 - acc: 0.8477 - val_loss: 0.6686 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 428: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 428/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2935 - acc: 0.8581 - val_loss: 0.6545 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 429: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 429/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2983 - acc: 0.8577 - val_loss: 0.6339 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 430: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 430/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2992 - acc: 0.8501 - val_loss: 0.6406 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 431: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 431/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2920 - acc: 0.8605 - val_loss: 0.6334 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 432: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 432/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2930 - acc: 0.8517 - val_loss: 0.6359 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 433: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 433/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2890 - acc: 0.8557 - val_loss: 0.6368 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 434: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 434/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2950 - acc: 0.8517 - val_loss: 0.6337 - val_acc: 0.7380 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 435: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 435/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2892 - acc: 0.8541 - val_loss: 0.6368 - val_acc: 0.7540 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 436: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 436/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2924 - acc: 0.8525 - val_loss: 0.6321 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 437: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 437/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3033 - acc: 0.8445 - val_loss: 0.6434 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 438: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 438/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2966 - acc: 0.8517 - val_loss: 0.6376 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 439: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 439/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2938 - acc: 0.8553 - val_loss: 0.6295 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 440: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 440/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2891 - acc: 0.8589 - val_loss: 0.6417 - val_acc: 0.7556 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 441: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 441/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2951 - acc: 0.8517 - val_loss: 0.6324 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 442: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 442/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2882 - acc: 0.8581 - val_loss: 0.6404 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 443: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 443/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2904 - acc: 0.8481 - val_loss: 0.6381 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 444: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 444/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2827 - acc: 0.8505 - val_loss: 0.6438 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 445: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 445/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2937 - acc: 0.8541 - val_loss: 0.6487 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 446: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 446/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2876 - acc: 0.8537 - val_loss: 0.6624 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 447: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 447/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2857 - acc: 0.8501 - val_loss: 0.6525 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 448: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 448/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2872 - acc: 0.8569 - val_loss: 0.6351 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 449: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 449/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2843 - acc: 0.8601 - val_loss: 0.6476 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 450: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 450/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2883 - acc: 0.8501 - val_loss: 0.6377 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 451: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 451/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2873 - acc: 0.8569 - val_loss: 0.6343 - val_acc: 0.7620 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 452: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 452/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2851 - acc: 0.8541 - val_loss: 0.6423 - val_acc: 0.7540 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 453: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 453/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2889 - acc: 0.8577 - val_loss: 0.6605 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 454: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 454/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2878 - acc: 0.8545 - val_loss: 0.6501 - val_acc: 0.7556 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 455: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 455/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2834 - acc: 0.8569 - val_loss: 0.6747 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 456: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 456/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2864 - acc: 0.8569 - val_loss: 0.6418 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 457: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 457/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2789 - acc: 0.8601 - val_loss: 0.6325 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 458: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 458/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2872 - acc: 0.8513 - val_loss: 0.6470 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 459: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 459/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3011 - acc: 0.8461 - val_loss: 0.6359 - val_acc: 0.7572 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 460: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 460/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2773 - acc: 0.8625 - val_loss: 0.6262 - val_acc: 0.7396 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 461: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 461/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2916 - acc: 0.8517 - val_loss: 0.6255 - val_acc: 0.7428 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 462: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 462/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2779 - acc: 0.8625 - val_loss: 0.6381 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 463: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 463/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2931 - acc: 0.8461 - val_loss: 0.6444 - val_acc: 0.7684 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 464: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 464/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2905 - acc: 0.8561 - val_loss: 0.6517 - val_acc: 0.7572 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 465: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 465/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2811 - acc: 0.8557 - val_loss: 0.6361 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 466: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 466/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2839 - acc: 0.8585 - val_loss: 0.6569 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 467: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 467/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2806 - acc: 0.8625 - val_loss: 0.6669 - val_acc: 0.7540 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 468: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 468/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2870 - acc: 0.8573 - val_loss: 0.6372 - val_acc: 0.7380 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 469: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 469/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2857 - acc: 0.8561 - val_loss: 0.6348 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 470: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 470/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2845 - acc: 0.8597 - val_loss: 0.6358 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 471: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 471/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2786 - acc: 0.8577 - val_loss: 0.6439 - val_acc: 0.7428 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 472: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 472/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2792 - acc: 0.8637 - val_loss: 0.6411 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 473: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 473/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2955 - acc: 0.8509 - val_loss: 0.6378 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 474: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 474/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2784 - acc: 0.8533 - val_loss: 0.6590 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 475: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 475/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2873 - acc: 0.8609 - val_loss: 0.6667 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 476: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 476/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2838 - acc: 0.8549 - val_loss: 0.6557 - val_acc: 0.7364 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 477: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 477/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2952 - acc: 0.8493 - val_loss: 0.6782 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 478: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 478/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2796 - acc: 0.8593 - val_loss: 0.6587 - val_acc: 0.7428 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 479: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 479/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2826 - acc: 0.8549 - val_loss: 0.6476 - val_acc: 0.7572 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 480: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 480/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2916 - acc: 0.8533 - val_loss: 0.6525 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 481: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 481/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2991 - acc: 0.8541 - val_loss: 0.6560 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 482: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 482/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2885 - acc: 0.8585 - val_loss: 0.6545 - val_acc: 0.7556 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 483: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 483/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2763 - acc: 0.8553 - val_loss: 0.6661 - val_acc: 0.7620 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 484: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 484/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2818 - acc: 0.8609 - val_loss: 0.6400 - val_acc: 0.7396 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 485: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 485/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2855 - acc: 0.8541 - val_loss: 0.6505 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 486: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 486/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2724 - acc: 0.8609 - val_loss: 0.6555 - val_acc: 0.7428 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 487: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 487/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2825 - acc: 0.8637 - val_loss: 0.6580 - val_acc: 0.7540 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 488: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 488/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2852 - acc: 0.8629 - val_loss: 0.6378 - val_acc: 0.7572 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 489: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 489/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2826 - acc: 0.8573 - val_loss: 0.6447 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 490: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 490/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2957 - acc: 0.8557 - val_loss: 0.6509 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 491: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 491/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2759 - acc: 0.8661 - val_loss: 0.6670 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 492: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 492/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2762 - acc: 0.8601 - val_loss: 0.6688 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 493: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 493/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2765 - acc: 0.8609 - val_loss: 0.6493 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 494: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 494/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2811 - acc: 0.8609 - val_loss: 0.6423 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 495: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 495/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2864 - acc: 0.8577 - val_loss: 0.6731 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 496: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 496/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2828 - acc: 0.8621 - val_loss: 0.6714 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 497: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 497/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2753 - acc: 0.8693 - val_loss: 0.6648 - val_acc: 0.7380 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 498: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 498/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2824 - acc: 0.8585 - val_loss: 0.6414 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 499: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 499/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2833 - acc: 0.8561 - val_loss: 0.6404 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 500: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 500/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2880 - acc: 0.8645 - val_loss: 0.6647 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 501: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 501/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2939 - acc: 0.8505 - val_loss: 0.6501 - val_acc: 0.7556 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 502: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 502/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2787 - acc: 0.8561 - val_loss: 0.6543 - val_acc: 0.7588 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 503: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 503/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2829 - acc: 0.8601 - val_loss: 0.6479 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 504: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 504/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2855 - acc: 0.8553 - val_loss: 0.6689 - val_acc: 0.7588 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 505: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 505/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2854 - acc: 0.8589 - val_loss: 0.6472 - val_acc: 0.7556 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 506: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 506/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2845 - acc: 0.8593 - val_loss: 0.6385 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 507: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 507/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2863 - acc: 0.8577 - val_loss: 0.6584 - val_acc: 0.7556 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 508: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 508/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2874 - acc: 0.8541 - val_loss: 0.6676 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 509: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 509/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2810 - acc: 0.8581 - val_loss: 0.6588 - val_acc: 0.7396 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 510: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 510/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2960 - acc: 0.8501 - val_loss: 0.6499 - val_acc: 0.7396 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 511: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 511/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2846 - acc: 0.8541 - val_loss: 0.6612 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 512: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 512/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2764 - acc: 0.8629 - val_loss: 0.6618 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 513: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 513/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2867 - acc: 0.8521 - val_loss: 0.6576 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 514: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 514/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2860 - acc: 0.8613 - val_loss: 0.6473 - val_acc: 0.7380 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 515: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 515/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2852 - acc: 0.8605 - val_loss: 0.6561 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 516: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 516/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2810 - acc: 0.8525 - val_loss: 0.6619 - val_acc: 0.7540 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 517: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 517/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2783 - acc: 0.8625 - val_loss: 0.6533 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 518: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 518/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2781 - acc: 0.8525 - val_loss: 0.6536 - val_acc: 0.7380 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 519: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 519/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2873 - acc: 0.8553 - val_loss: 0.6662 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 520: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 520/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2706 - acc: 0.8585 - val_loss: 0.6768 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 521: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 521/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2827 - acc: 0.8553 - val_loss: 0.6626 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 522: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 522/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2718 - acc: 0.8641 - val_loss: 0.6533 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 523: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 523/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2797 - acc: 0.8585 - val_loss: 0.6695 - val_acc: 0.7428 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 524: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 524/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2829 - acc: 0.8597 - val_loss: 0.6712 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 525: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 525/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2863 - acc: 0.8565 - val_loss: 0.6503 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 526: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 526/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2852 - acc: 0.8641 - val_loss: 0.6662 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 527: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 527/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2754 - acc: 0.8649 - val_loss: 0.6771 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 528: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 528/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2711 - acc: 0.8641 - val_loss: 0.6665 - val_acc: 0.7540 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 529: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 529/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2760 - acc: 0.8609 - val_loss: 0.6721 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 530: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 530/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2890 - acc: 0.8541 - val_loss: 0.6620 - val_acc: 0.7556 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 531: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 531/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2842 - acc: 0.8613 - val_loss: 0.6565 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 532: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 532/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2818 - acc: 0.8569 - val_loss: 0.6601 - val_acc: 0.7540 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 533: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 533/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2806 - acc: 0.8605 - val_loss: 0.6599 - val_acc: 0.7556 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 534: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 534/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2810 - acc: 0.8533 - val_loss: 0.6669 - val_acc: 0.7380 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 535: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 535/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2749 - acc: 0.8677 - val_loss: 0.6613 - val_acc: 0.7396 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 536: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 536/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2859 - acc: 0.8645 - val_loss: 0.6748 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 537: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 537/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2791 - acc: 0.8657 - val_loss: 0.6566 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 538: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 538/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2935 - acc: 0.8461 - val_loss: 0.6603 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 539: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 539/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2804 - acc: 0.8561 - val_loss: 0.6937 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 540: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 540/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2749 - acc: 0.8649 - val_loss: 0.6816 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 541: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 541/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2904 - acc: 0.8545 - val_loss: 0.6419 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 542: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 542/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2901 - acc: 0.8597 - val_loss: 0.6480 - val_acc: 0.7428 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 543: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 543/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2888 - acc: 0.8513 - val_loss: 0.6610 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 544: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 544/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2875 - acc: 0.8517 - val_loss: 0.6500 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 545: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 545/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2755 - acc: 0.8609 - val_loss: 0.6763 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 546: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 546/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2843 - acc: 0.8557 - val_loss: 0.6630 - val_acc: 0.7540 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 547: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 547/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2877 - acc: 0.8585 - val_loss: 0.6753 - val_acc: 0.7428 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 548: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 548/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2810 - acc: 0.8561 - val_loss: 0.6600 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 549: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 549/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2749 - acc: 0.8633 - val_loss: 0.6611 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 550: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 550/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2740 - acc: 0.8681 - val_loss: 0.6537 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 551: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 551/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2802 - acc: 0.8601 - val_loss: 0.6705 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 552: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 552/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2769 - acc: 0.8629 - val_loss: 0.6757 - val_acc: 0.7428 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 553: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 553/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2787 - acc: 0.8541 - val_loss: 0.6567 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 554: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 554/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2849 - acc: 0.8609 - val_loss: 0.6550 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 555: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 555/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2851 - acc: 0.8553 - val_loss: 0.6583 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 556: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 556/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2695 - acc: 0.8697 - val_loss: 0.6630 - val_acc: 0.7540 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 557: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 557/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2897 - acc: 0.8565 - val_loss: 0.6627 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 558: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 558/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2765 - acc: 0.8613 - val_loss: 0.6915 - val_acc: 0.7572 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 559: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 559/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2756 - acc: 0.8641 - val_loss: 0.6941 - val_acc: 0.7572 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 560: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 560/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2729 - acc: 0.8649 - val_loss: 0.6906 - val_acc: 0.7540 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 561: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 561/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2914 - acc: 0.8593 - val_loss: 0.6477 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 562: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 562/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2785 - acc: 0.8573 - val_loss: 0.6535 - val_acc: 0.7428 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 563: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 563/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2730 - acc: 0.8549 - val_loss: 0.6771 - val_acc: 0.7540 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 564: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 564/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2801 - acc: 0.8553 - val_loss: 0.6749 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 565: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 565/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2741 - acc: 0.8665 - val_loss: 0.6805 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 566: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 566/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2802 - acc: 0.8597 - val_loss: 0.7168 - val_acc: 0.7556 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 567: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 567/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2710 - acc: 0.8645 - val_loss: 0.6935 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 568: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 568/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2706 - acc: 0.8661 - val_loss: 0.6913 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 569: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 569/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2704 - acc: 0.8669 - val_loss: 0.6822 - val_acc: 0.7572 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 570: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 570/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2882 - acc: 0.8601 - val_loss: 0.6498 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 571: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 571/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2861 - acc: 0.8625 - val_loss: 0.6609 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 572: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 572/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2837 - acc: 0.8593 - val_loss: 0.6702 - val_acc: 0.7620 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 573: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 573/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2826 - acc: 0.8553 - val_loss: 0.6827 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 574: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 574/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2801 - acc: 0.8597 - val_loss: 0.7072 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 575: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 575/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2767 - acc: 0.8589 - val_loss: 0.6668 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 576: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 576/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2810 - acc: 0.8689 - val_loss: 0.6584 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 577: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 577/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2792 - acc: 0.8593 - val_loss: 0.6754 - val_acc: 0.7540 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 578: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 578/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2753 - acc: 0.8701 - val_loss: 0.6483 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 579: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 579/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2722 - acc: 0.8605 - val_loss: 0.6588 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 580: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 580/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2781 - acc: 0.8645 - val_loss: 0.6664 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 581: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 581/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2616 - acc: 0.8689 - val_loss: 0.6878 - val_acc: 0.7348 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 582: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 582/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2657 - acc: 0.8677 - val_loss: 0.6713 - val_acc: 0.7364 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 583: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 583/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2710 - acc: 0.8573 - val_loss: 0.6633 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 584: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 584/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2722 - acc: 0.8625 - val_loss: 0.6671 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 585: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 585/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2682 - acc: 0.8653 - val_loss: 0.6678 - val_acc: 0.7556 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 586: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 586/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2726 - acc: 0.8641 - val_loss: 0.6668 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 587: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 587/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2739 - acc: 0.8625 - val_loss: 0.6898 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 588: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 588/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2696 - acc: 0.8721 - val_loss: 0.6810 - val_acc: 0.7396 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 589: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 589/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2777 - acc: 0.8561 - val_loss: 0.6839 - val_acc: 0.7428 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 590: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 590/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2750 - acc: 0.8721 - val_loss: 0.6986 - val_acc: 0.7604 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 591: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 591/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2796 - acc: 0.8633 - val_loss: 0.6948 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 592: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 592/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2748 - acc: 0.8625 - val_loss: 0.6805 - val_acc: 0.7428 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 593: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 593/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2778 - acc: 0.8661 - val_loss: 0.6735 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 594: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 594/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2774 - acc: 0.8621 - val_loss: 0.6556 - val_acc: 0.7396 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 595: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 595/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2789 - acc: 0.8605 - val_loss: 0.6751 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 596: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 596/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2752 - acc: 0.8613 - val_loss: 0.6833 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 597: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 597/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2750 - acc: 0.8661 - val_loss: 0.6661 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 598: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 598/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2715 - acc: 0.8597 - val_loss: 0.6799 - val_acc: 0.7428 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 599: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 599/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2753 - acc: 0.8605 - val_loss: 0.6744 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 600: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 600/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2711 - acc: 0.8569 - val_loss: 0.6500 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 601: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 601/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2749 - acc: 0.8633 - val_loss: 0.6580 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 602: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 602/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2673 - acc: 0.8677 - val_loss: 0.6783 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 603: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 603/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2644 - acc: 0.8713 - val_loss: 0.6812 - val_acc: 0.7540 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 604: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 604/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2710 - acc: 0.8633 - val_loss: 0.6645 - val_acc: 0.7572 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 605: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 605/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2714 - acc: 0.8681 - val_loss: 0.6727 - val_acc: 0.7540 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 606: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 606/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2766 - acc: 0.8657 - val_loss: 0.6810 - val_acc: 0.7540 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 607: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 607/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2652 - acc: 0.8617 - val_loss: 0.6782 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 608: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 608/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2801 - acc: 0.8641 - val_loss: 0.6558 - val_acc: 0.7396 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 609: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 609/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2733 - acc: 0.8693 - val_loss: 0.6618 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 610: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 610/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2793 - acc: 0.8593 - val_loss: 0.6619 - val_acc: 0.7588 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 611: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 611/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2666 - acc: 0.8669 - val_loss: 0.6779 - val_acc: 0.7556 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 612: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 612/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2702 - acc: 0.8649 - val_loss: 0.6865 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 613: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 613/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2825 - acc: 0.8573 - val_loss: 0.6611 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 614: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 614/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2672 - acc: 0.8673 - val_loss: 0.6673 - val_acc: 0.7396 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 615: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 615/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2744 - acc: 0.8645 - val_loss: 0.6815 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 616: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 616/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2703 - acc: 0.8645 - val_loss: 0.6733 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 617: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 617/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2740 - acc: 0.8669 - val_loss: 0.6917 - val_acc: 0.7428 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 618: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 618/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2737 - acc: 0.8653 - val_loss: 0.6870 - val_acc: 0.7428 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 619: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 619/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2672 - acc: 0.8621 - val_loss: 0.6846 - val_acc: 0.7396 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 620: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 620/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2614 - acc: 0.8737 - val_loss: 0.6578 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 621: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 621/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2730 - acc: 0.8617 - val_loss: 0.6734 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 622: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 622/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2737 - acc: 0.8641 - val_loss: 0.7006 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 623: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 623/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2638 - acc: 0.8641 - val_loss: 0.6825 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 624: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 624/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2591 - acc: 0.8737 - val_loss: 0.6727 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 625: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 625/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2644 - acc: 0.8713 - val_loss: 0.6730 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 626: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 626/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2642 - acc: 0.8705 - val_loss: 0.6740 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 627: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 627/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2696 - acc: 0.8585 - val_loss: 0.6780 - val_acc: 0.7428 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 628: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 628/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2656 - acc: 0.8669 - val_loss: 0.6914 - val_acc: 0.7556 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 629: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 629/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2671 - acc: 0.8585 - val_loss: 0.6770 - val_acc: 0.7428 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 630: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 630/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2660 - acc: 0.8689 - val_loss: 0.6812 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 631: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 631/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2693 - acc: 0.8780 - val_loss: 0.6818 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 632: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 632/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2692 - acc: 0.8705 - val_loss: 0.6816 - val_acc: 0.7572 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 633: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 633/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2803 - acc: 0.8601 - val_loss: 0.6732 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 634: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 634/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2709 - acc: 0.8657 - val_loss: 0.6896 - val_acc: 0.7428 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 635: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 635/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2609 - acc: 0.8685 - val_loss: 0.6995 - val_acc: 0.7620 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 636: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 636/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2668 - acc: 0.8669 - val_loss: 0.6848 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 637: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 637/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2640 - acc: 0.8677 - val_loss: 0.6803 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 638: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 638/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2660 - acc: 0.8705 - val_loss: 0.6710 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 639: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 639/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2741 - acc: 0.8621 - val_loss: 0.6707 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 640: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 640/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2707 - acc: 0.8621 - val_loss: 0.6842 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 641: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 641/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2665 - acc: 0.8613 - val_loss: 0.6765 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 642: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 642/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2755 - acc: 0.8589 - val_loss: 0.6878 - val_acc: 0.7556 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 643: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 643/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2637 - acc: 0.8733 - val_loss: 0.6788 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 644: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 644/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2700 - acc: 0.8697 - val_loss: 0.6638 - val_acc: 0.7540 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 645: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 645/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2827 - acc: 0.8669 - val_loss: 0.6566 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 646: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 646/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2724 - acc: 0.8609 - val_loss: 0.6607 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 647: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 647/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2650 - acc: 0.8661 - val_loss: 0.6738 - val_acc: 0.7652 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 648: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 648/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2750 - acc: 0.8645 - val_loss: 0.6644 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 649: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 649/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2634 - acc: 0.8733 - val_loss: 0.6907 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 650: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 650/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2599 - acc: 0.8745 - val_loss: 0.6836 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 651: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 651/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2748 - acc: 0.8609 - val_loss: 0.6910 - val_acc: 0.7540 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 652: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 652/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2711 - acc: 0.8613 - val_loss: 0.6963 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 653: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 653/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2712 - acc: 0.8673 - val_loss: 0.6926 - val_acc: 0.7540 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 654: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 654/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2795 - acc: 0.8637 - val_loss: 0.6844 - val_acc: 0.7604 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 655: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 655/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2722 - acc: 0.8609 - val_loss: 0.6897 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 656: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 656/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2727 - acc: 0.8617 - val_loss: 0.6704 - val_acc: 0.7348 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 657: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 657/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2651 - acc: 0.8613 - val_loss: 0.6769 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 658: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 658/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2652 - acc: 0.8780 - val_loss: 0.6812 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 659: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 659/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2782 - acc: 0.8661 - val_loss: 0.6844 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 660: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 660/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2668 - acc: 0.8681 - val_loss: 0.7010 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 661: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 661/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2623 - acc: 0.8685 - val_loss: 0.6786 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 662: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 662/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2745 - acc: 0.8625 - val_loss: 0.6720 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 663: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 663/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2574 - acc: 0.8629 - val_loss: 0.6851 - val_acc: 0.7540 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 664: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 664/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2583 - acc: 0.8697 - val_loss: 0.6733 - val_acc: 0.7428 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 665: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 665/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2650 - acc: 0.8725 - val_loss: 0.6738 - val_acc: 0.7540 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 666: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 666/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2708 - acc: 0.8609 - val_loss: 0.6871 - val_acc: 0.7588 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 667: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 667/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2727 - acc: 0.8605 - val_loss: 0.7019 - val_acc: 0.7428 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 668: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 668/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2743 - acc: 0.8593 - val_loss: 0.6817 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 669: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 669/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2658 - acc: 0.8677 - val_loss: 0.6808 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 670: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 670/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2702 - acc: 0.8673 - val_loss: 0.6874 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 671: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 671/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2780 - acc: 0.8589 - val_loss: 0.6628 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 672: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 672/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2714 - acc: 0.8749 - val_loss: 0.6618 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 673: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 673/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2638 - acc: 0.8701 - val_loss: 0.6553 - val_acc: 0.7396 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 674: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 674/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2704 - acc: 0.8629 - val_loss: 0.6727 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 675: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 675/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2650 - acc: 0.8673 - val_loss: 0.6842 - val_acc: 0.7556 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 676: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 676/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2715 - acc: 0.8633 - val_loss: 0.6680 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 677: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 677/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2586 - acc: 0.8697 - val_loss: 0.6518 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 678: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 678/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2642 - acc: 0.8649 - val_loss: 0.6794 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 679: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 679/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2733 - acc: 0.8645 - val_loss: 0.6710 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 680: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 680/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2627 - acc: 0.8689 - val_loss: 0.6690 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 681: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 681/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2741 - acc: 0.8621 - val_loss: 0.6549 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 682: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 682/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2620 - acc: 0.8629 - val_loss: 0.6524 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 683: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 683/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2731 - acc: 0.8685 - val_loss: 0.6539 - val_acc: 0.7428 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 684: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 684/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2663 - acc: 0.8721 - val_loss: 0.6637 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 685: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 685/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2693 - acc: 0.8677 - val_loss: 0.6788 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 686: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 686/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2753 - acc: 0.8637 - val_loss: 0.6750 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 687: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 687/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2679 - acc: 0.8681 - val_loss: 0.6847 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 688: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 688/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2610 - acc: 0.8760 - val_loss: 0.6831 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 689: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 689/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2572 - acc: 0.8741 - val_loss: 0.7095 - val_acc: 0.7588 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 690: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 690/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2608 - acc: 0.8701 - val_loss: 0.6858 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 691: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 691/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2668 - acc: 0.8725 - val_loss: 0.6802 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 692: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 692/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2704 - acc: 0.8609 - val_loss: 0.6863 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 693: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 693/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2479 - acc: 0.8812 - val_loss: 0.6906 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 694: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 694/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2712 - acc: 0.8625 - val_loss: 0.7077 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 695: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 695/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2576 - acc: 0.8713 - val_loss: 0.7073 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 696: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 696/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2736 - acc: 0.8693 - val_loss: 0.6945 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 697: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 697/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2609 - acc: 0.8741 - val_loss: 0.6838 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 698: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 698/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2649 - acc: 0.8756 - val_loss: 0.6690 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 699: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 699/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2558 - acc: 0.8689 - val_loss: 0.6987 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 700: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 700/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2599 - acc: 0.8701 - val_loss: 0.6915 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 701: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 701/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2657 - acc: 0.8701 - val_loss: 0.6714 - val_acc: 0.7380 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 702: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 702/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2744 - acc: 0.8629 - val_loss: 0.6866 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 703: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 703/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2592 - acc: 0.8752 - val_loss: 0.6923 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 704: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 704/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2733 - acc: 0.8585 - val_loss: 0.6770 - val_acc: 0.7540 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 705: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 705/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2659 - acc: 0.8737 - val_loss: 0.6760 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 706: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 706/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2563 - acc: 0.8784 - val_loss: 0.6998 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 707: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 707/1000\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.2650 - acc: 0.8697 - val_loss: 0.7029 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 708: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 708/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2551 - acc: 0.8749 - val_loss: 0.6969 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 709: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 709/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2635 - acc: 0.8745 - val_loss: 0.7020 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 710: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 710/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2676 - acc: 0.8709 - val_loss: 0.7114 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 711: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 711/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2690 - acc: 0.8665 - val_loss: 0.6972 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 712: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 712/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2587 - acc: 0.8725 - val_loss: 0.6663 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 713: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 713/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2640 - acc: 0.8752 - val_loss: 0.7050 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 714: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 714/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2608 - acc: 0.8661 - val_loss: 0.7179 - val_acc: 0.7540 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 715: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 715/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2644 - acc: 0.8641 - val_loss: 0.7166 - val_acc: 0.7396 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 716: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 716/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2578 - acc: 0.8733 - val_loss: 0.7166 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 717: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 717/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2539 - acc: 0.8737 - val_loss: 0.7085 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 718: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 718/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2700 - acc: 0.8657 - val_loss: 0.7203 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 719: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 719/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2529 - acc: 0.8741 - val_loss: 0.7133 - val_acc: 0.7540 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 720: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 720/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2686 - acc: 0.8593 - val_loss: 0.7054 - val_acc: 0.7572 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 721: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 721/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2732 - acc: 0.8577 - val_loss: 0.6873 - val_acc: 0.7540 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 722: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 722/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2594 - acc: 0.8737 - val_loss: 0.6748 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 723: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 723/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2678 - acc: 0.8685 - val_loss: 0.6835 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 724: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 724/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2538 - acc: 0.8788 - val_loss: 0.7066 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 725: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 725/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2678 - acc: 0.8617 - val_loss: 0.6973 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 726: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 726/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2592 - acc: 0.8681 - val_loss: 0.7014 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 727: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 727/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2643 - acc: 0.8645 - val_loss: 0.6941 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 728: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 728/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2570 - acc: 0.8749 - val_loss: 0.7099 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 729: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 729/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2662 - acc: 0.8733 - val_loss: 0.7178 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 730: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 730/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2621 - acc: 0.8673 - val_loss: 0.7014 - val_acc: 0.7396 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 731: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 731/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2542 - acc: 0.8792 - val_loss: 0.6995 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 732: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 732/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2599 - acc: 0.8681 - val_loss: 0.7037 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 733: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 733/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2575 - acc: 0.8697 - val_loss: 0.7217 - val_acc: 0.7396 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 734: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 734/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2671 - acc: 0.8701 - val_loss: 0.6971 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 735: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 735/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2587 - acc: 0.8745 - val_loss: 0.6954 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 736: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 736/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2664 - acc: 0.8689 - val_loss: 0.7080 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 737: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 737/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2577 - acc: 0.8693 - val_loss: 0.6929 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 738: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 738/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2615 - acc: 0.8752 - val_loss: 0.6902 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 739: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 739/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2590 - acc: 0.8745 - val_loss: 0.6893 - val_acc: 0.7556 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 740: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 740/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2641 - acc: 0.8689 - val_loss: 0.7110 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 741: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 741/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2566 - acc: 0.8733 - val_loss: 0.6902 - val_acc: 0.7572 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 742: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 742/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2601 - acc: 0.8661 - val_loss: 0.6834 - val_acc: 0.7572 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 743: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 743/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2498 - acc: 0.8844 - val_loss: 0.6837 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 744: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 744/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2626 - acc: 0.8705 - val_loss: 0.6741 - val_acc: 0.7364 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 745: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 745/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2596 - acc: 0.8685 - val_loss: 0.6980 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 746: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 746/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2521 - acc: 0.8780 - val_loss: 0.7411 - val_acc: 0.7428 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 747: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 747/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2561 - acc: 0.8689 - val_loss: 0.6970 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 748: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 748/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2563 - acc: 0.8745 - val_loss: 0.6910 - val_acc: 0.7380 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 749: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 749/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2551 - acc: 0.8780 - val_loss: 0.7043 - val_acc: 0.7428 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 750: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 750/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2567 - acc: 0.8701 - val_loss: 0.6757 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 751: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 751/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2482 - acc: 0.8788 - val_loss: 0.6948 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 752: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 752/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2583 - acc: 0.8709 - val_loss: 0.6939 - val_acc: 0.7396 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 753: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 753/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2672 - acc: 0.8689 - val_loss: 0.7308 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 754: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 754/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2612 - acc: 0.8776 - val_loss: 0.7000 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 755: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 755/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2607 - acc: 0.8737 - val_loss: 0.6804 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 756: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 756/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2514 - acc: 0.8749 - val_loss: 0.6827 - val_acc: 0.7396 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 757: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 757/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2658 - acc: 0.8705 - val_loss: 0.7076 - val_acc: 0.7428 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 758: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 758/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2502 - acc: 0.8820 - val_loss: 0.7407 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 759: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 759/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2736 - acc: 0.8621 - val_loss: 0.7147 - val_acc: 0.7380 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 760: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 760/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2540 - acc: 0.8760 - val_loss: 0.7002 - val_acc: 0.7428 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 761: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 761/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2581 - acc: 0.8764 - val_loss: 0.6997 - val_acc: 0.7556 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 762: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 762/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2574 - acc: 0.8665 - val_loss: 0.7140 - val_acc: 0.7540 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 763: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 763/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2618 - acc: 0.8804 - val_loss: 0.7212 - val_acc: 0.7396 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 764: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 764/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2710 - acc: 0.8633 - val_loss: 0.7016 - val_acc: 0.7572 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 765: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 765/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2646 - acc: 0.8725 - val_loss: 0.7080 - val_acc: 0.7380 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 766: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 766/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2664 - acc: 0.8717 - val_loss: 0.7215 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 767: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 767/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2607 - acc: 0.8756 - val_loss: 0.7297 - val_acc: 0.7540 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 768: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 768/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2510 - acc: 0.8752 - val_loss: 0.7064 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 769: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 769/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2618 - acc: 0.8705 - val_loss: 0.6961 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 770: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 770/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2501 - acc: 0.8725 - val_loss: 0.6884 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 771: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 771/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2620 - acc: 0.8741 - val_loss: 0.7160 - val_acc: 0.7428 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 772: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 772/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2528 - acc: 0.8788 - val_loss: 0.6943 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 773: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 773/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2636 - acc: 0.8729 - val_loss: 0.6938 - val_acc: 0.7396 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 774: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 774/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2582 - acc: 0.8780 - val_loss: 0.7206 - val_acc: 0.7540 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 775: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 775/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2685 - acc: 0.8685 - val_loss: 0.7003 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 776: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 776/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2493 - acc: 0.8860 - val_loss: 0.6846 - val_acc: 0.7380 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 777: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 777/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2574 - acc: 0.8764 - val_loss: 0.6942 - val_acc: 0.7364 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 778: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 778/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2602 - acc: 0.8713 - val_loss: 0.6838 - val_acc: 0.7380 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 779: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 779/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2644 - acc: 0.8693 - val_loss: 0.6908 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 780: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 780/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2498 - acc: 0.8685 - val_loss: 0.6881 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 781: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 781/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2572 - acc: 0.8733 - val_loss: 0.6907 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 782: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 782/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2545 - acc: 0.8784 - val_loss: 0.7255 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 783: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 783/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2518 - acc: 0.8792 - val_loss: 0.7260 - val_acc: 0.7396 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 784: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 784/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2424 - acc: 0.8768 - val_loss: 0.7236 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 785: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 785/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2615 - acc: 0.8741 - val_loss: 0.7324 - val_acc: 0.7380 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 786: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 786/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2539 - acc: 0.8772 - val_loss: 0.7313 - val_acc: 0.7428 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 787: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 787/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2603 - acc: 0.8737 - val_loss: 0.7232 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 788: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 788/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2534 - acc: 0.8768 - val_loss: 0.7168 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 789: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 789/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2518 - acc: 0.8764 - val_loss: 0.7079 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 790: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 790/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2493 - acc: 0.8800 - val_loss: 0.7101 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 791: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 791/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2531 - acc: 0.8745 - val_loss: 0.6939 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 792: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 792/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2553 - acc: 0.8820 - val_loss: 0.7212 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 793: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 793/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2599 - acc: 0.8737 - val_loss: 0.7040 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 794: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 794/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2497 - acc: 0.8828 - val_loss: 0.7131 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 795: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 795/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2604 - acc: 0.8693 - val_loss: 0.7133 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 796: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 796/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2499 - acc: 0.8828 - val_loss: 0.7134 - val_acc: 0.7540 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 797: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 797/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2558 - acc: 0.8752 - val_loss: 0.7126 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 798: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 798/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2503 - acc: 0.8800 - val_loss: 0.7071 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 799: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 799/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2534 - acc: 0.8824 - val_loss: 0.7312 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 800: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 800/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2528 - acc: 0.8764 - val_loss: 0.7216 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 801: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 801/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2487 - acc: 0.8760 - val_loss: 0.7347 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 802: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 802/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2586 - acc: 0.8701 - val_loss: 0.7348 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 803: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 803/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2475 - acc: 0.8721 - val_loss: 0.7324 - val_acc: 0.7556 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 804: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 804/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2489 - acc: 0.8796 - val_loss: 0.7363 - val_acc: 0.7572 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 805: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 805/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2562 - acc: 0.8812 - val_loss: 0.6992 - val_acc: 0.7572 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 806: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 806/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2476 - acc: 0.8776 - val_loss: 0.6991 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 807: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 807/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2597 - acc: 0.8737 - val_loss: 0.7167 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 808: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 808/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2538 - acc: 0.8800 - val_loss: 0.6869 - val_acc: 0.7572 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 809: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 809/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2536 - acc: 0.8760 - val_loss: 0.6880 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 810: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 810/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2489 - acc: 0.8784 - val_loss: 0.7038 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 811: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 811/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2602 - acc: 0.8776 - val_loss: 0.7230 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 812: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 812/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2420 - acc: 0.8868 - val_loss: 0.7304 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 813: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 813/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2544 - acc: 0.8717 - val_loss: 0.7386 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 814: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 814/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2452 - acc: 0.8828 - val_loss: 0.7129 - val_acc: 0.7572 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 815: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 815/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2507 - acc: 0.8784 - val_loss: 0.7088 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 816: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 816/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2491 - acc: 0.8721 - val_loss: 0.7197 - val_acc: 0.7428 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 817: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 817/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2452 - acc: 0.8749 - val_loss: 0.7137 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 818: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 818/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2515 - acc: 0.8764 - val_loss: 0.7275 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 819: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 819/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2662 - acc: 0.8657 - val_loss: 0.7353 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 820: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 820/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2546 - acc: 0.8828 - val_loss: 0.7159 - val_acc: 0.7364 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 821: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 821/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2548 - acc: 0.8737 - val_loss: 0.6981 - val_acc: 0.7348 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 822: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 822/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2413 - acc: 0.8804 - val_loss: 0.6979 - val_acc: 0.7428 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 823: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 823/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2508 - acc: 0.8772 - val_loss: 0.7090 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 824: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 824/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2463 - acc: 0.8792 - val_loss: 0.7089 - val_acc: 0.7364 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 825: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 825/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2455 - acc: 0.8776 - val_loss: 0.7015 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 826: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 826/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2474 - acc: 0.8729 - val_loss: 0.6968 - val_acc: 0.7396 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 827: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 827/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2528 - acc: 0.8768 - val_loss: 0.7283 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 828: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 828/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2491 - acc: 0.8717 - val_loss: 0.7518 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 829: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 829/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2602 - acc: 0.8721 - val_loss: 0.6884 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 830: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 830/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2509 - acc: 0.8792 - val_loss: 0.7018 - val_acc: 0.7428 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 831: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 831/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2717 - acc: 0.8597 - val_loss: 0.7088 - val_acc: 0.7396 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 832: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 832/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2636 - acc: 0.8749 - val_loss: 0.6881 - val_acc: 0.7380 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 833: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 833/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2449 - acc: 0.8749 - val_loss: 0.6926 - val_acc: 0.7364 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 834: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 834/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2510 - acc: 0.8764 - val_loss: 0.7101 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 835: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 835/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2505 - acc: 0.8749 - val_loss: 0.6933 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 836: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 836/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2430 - acc: 0.8816 - val_loss: 0.6832 - val_acc: 0.7396 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 837: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 837/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2506 - acc: 0.8764 - val_loss: 0.6953 - val_acc: 0.7428 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 838: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 838/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2488 - acc: 0.8772 - val_loss: 0.7163 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 839: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 839/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2475 - acc: 0.8756 - val_loss: 0.7228 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 840: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 840/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2422 - acc: 0.8848 - val_loss: 0.7038 - val_acc: 0.7380 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 841: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 841/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2661 - acc: 0.8653 - val_loss: 0.6994 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 842: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 842/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2558 - acc: 0.8780 - val_loss: 0.6946 - val_acc: 0.7428 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 843: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 843/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2551 - acc: 0.8824 - val_loss: 0.7084 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 844: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 844/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2416 - acc: 0.8820 - val_loss: 0.7044 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 845: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 845/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2448 - acc: 0.8772 - val_loss: 0.7115 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 846: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 846/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2484 - acc: 0.8721 - val_loss: 0.7317 - val_acc: 0.7428 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 847: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 847/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2489 - acc: 0.8808 - val_loss: 0.6989 - val_acc: 0.7396 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 848: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 848/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2552 - acc: 0.8788 - val_loss: 0.6936 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 849: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 849/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2516 - acc: 0.8745 - val_loss: 0.7056 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 850: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 850/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2496 - acc: 0.8872 - val_loss: 0.6750 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 851: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 851/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2516 - acc: 0.8741 - val_loss: 0.6972 - val_acc: 0.7396 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 852: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 852/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2366 - acc: 0.8828 - val_loss: 0.7237 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 853: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 853/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2522 - acc: 0.8768 - val_loss: 0.7174 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 854: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 854/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2503 - acc: 0.8776 - val_loss: 0.7105 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 855: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 855/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2538 - acc: 0.8788 - val_loss: 0.7095 - val_acc: 0.7428 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 856: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 856/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2491 - acc: 0.8772 - val_loss: 0.7214 - val_acc: 0.7380 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 857: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 857/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2789 - acc: 0.8661 - val_loss: 0.7064 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 858: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 858/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2451 - acc: 0.8804 - val_loss: 0.7243 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 859: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 859/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2516 - acc: 0.8780 - val_loss: 0.7315 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 860: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 860/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2424 - acc: 0.8816 - val_loss: 0.7256 - val_acc: 0.7364 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 861: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 861/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2427 - acc: 0.8792 - val_loss: 0.6949 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 862: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 862/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2530 - acc: 0.8749 - val_loss: 0.6873 - val_acc: 0.7540 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 863: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 863/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2452 - acc: 0.8844 - val_loss: 0.6989 - val_acc: 0.7540 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 864: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 864/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2453 - acc: 0.8828 - val_loss: 0.7017 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 865: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 865/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2522 - acc: 0.8788 - val_loss: 0.7110 - val_acc: 0.7556 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 866: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 866/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2533 - acc: 0.8752 - val_loss: 0.7146 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 867: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 867/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2435 - acc: 0.8812 - val_loss: 0.7120 - val_acc: 0.7428 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 868: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 868/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2519 - acc: 0.8808 - val_loss: 0.7180 - val_acc: 0.7380 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 869: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 869/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2488 - acc: 0.8832 - val_loss: 0.7336 - val_acc: 0.7428 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 870: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 870/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2441 - acc: 0.8776 - val_loss: 0.7347 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 871: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 871/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2578 - acc: 0.8772 - val_loss: 0.7357 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 872: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 872/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2454 - acc: 0.8884 - val_loss: 0.7085 - val_acc: 0.7396 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 873: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 873/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2530 - acc: 0.8776 - val_loss: 0.7195 - val_acc: 0.7556 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 874: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 874/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2446 - acc: 0.8772 - val_loss: 0.7332 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 875: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 875/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2407 - acc: 0.8796 - val_loss: 0.7405 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 876: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 876/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2436 - acc: 0.8832 - val_loss: 0.7474 - val_acc: 0.7604 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 877: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 877/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2400 - acc: 0.8820 - val_loss: 0.7195 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 878: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 878/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2528 - acc: 0.8733 - val_loss: 0.7237 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 879: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 879/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2507 - acc: 0.8697 - val_loss: 0.7285 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 880: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 880/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2425 - acc: 0.8848 - val_loss: 0.7258 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 881: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 881/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2397 - acc: 0.8860 - val_loss: 0.7145 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 882: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 882/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2422 - acc: 0.8916 - val_loss: 0.7295 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 883: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 883/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2467 - acc: 0.8788 - val_loss: 0.7160 - val_acc: 0.7396 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 884: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 884/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2405 - acc: 0.8788 - val_loss: 0.7188 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 885: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 885/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2458 - acc: 0.8800 - val_loss: 0.7434 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 886: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 886/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2424 - acc: 0.8788 - val_loss: 0.7412 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 887: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 887/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2556 - acc: 0.8741 - val_loss: 0.7258 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 888: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 888/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2416 - acc: 0.8856 - val_loss: 0.7193 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 889: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 889/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2470 - acc: 0.8832 - val_loss: 0.7105 - val_acc: 0.7332 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 890: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 890/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2465 - acc: 0.8796 - val_loss: 0.7356 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 891: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 891/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2496 - acc: 0.8741 - val_loss: 0.7271 - val_acc: 0.7540 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 892: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 892/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2446 - acc: 0.8800 - val_loss: 0.7028 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 893: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 893/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2437 - acc: 0.8896 - val_loss: 0.6902 - val_acc: 0.7396 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 894: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 894/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2466 - acc: 0.8836 - val_loss: 0.7187 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 895: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 895/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2365 - acc: 0.8832 - val_loss: 0.7196 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 896: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 896/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2544 - acc: 0.8713 - val_loss: 0.7448 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 897: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 897/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2464 - acc: 0.8784 - val_loss: 0.7141 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 898: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 898/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2422 - acc: 0.8864 - val_loss: 0.7213 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 899: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 899/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2384 - acc: 0.8832 - val_loss: 0.7303 - val_acc: 0.7380 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 900: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 900/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2460 - acc: 0.8836 - val_loss: 0.7251 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 901: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 901/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2510 - acc: 0.8737 - val_loss: 0.7109 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 902: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 902/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2414 - acc: 0.8820 - val_loss: 0.7177 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 903: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 903/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2461 - acc: 0.8800 - val_loss: 0.7306 - val_acc: 0.7428 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 904: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 904/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2453 - acc: 0.8788 - val_loss: 0.7286 - val_acc: 0.7396 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 905: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 905/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2482 - acc: 0.8713 - val_loss: 0.7434 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 906: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 906/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2492 - acc: 0.8840 - val_loss: 0.7290 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 907: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 907/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2466 - acc: 0.8856 - val_loss: 0.7086 - val_acc: 0.7364 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 908: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 908/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2431 - acc: 0.8880 - val_loss: 0.7079 - val_acc: 0.7396 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 909: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 909/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2319 - acc: 0.8996 - val_loss: 0.7305 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 910: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 910/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2358 - acc: 0.8892 - val_loss: 0.7153 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 911: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 911/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2580 - acc: 0.8737 - val_loss: 0.7116 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 912: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 912/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2475 - acc: 0.8820 - val_loss: 0.6920 - val_acc: 0.7380 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 913: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 913/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2524 - acc: 0.8780 - val_loss: 0.7427 - val_acc: 0.7428 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 914: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 914/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2495 - acc: 0.8820 - val_loss: 0.7453 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 915: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 915/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2416 - acc: 0.8896 - val_loss: 0.7385 - val_acc: 0.7396 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 916: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 916/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2384 - acc: 0.8808 - val_loss: 0.7252 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 917: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 917/1000\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.2476 - acc: 0.8828 - val_loss: 0.7316 - val_acc: 0.7556 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 918: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 918/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2367 - acc: 0.8868 - val_loss: 0.7219 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 919: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 919/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2482 - acc: 0.8792 - val_loss: 0.7512 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 920: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 920/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2464 - acc: 0.8792 - val_loss: 0.7170 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 921: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 921/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2344 - acc: 0.8964 - val_loss: 0.7150 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 922: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 922/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2409 - acc: 0.8896 - val_loss: 0.7417 - val_acc: 0.7428 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 923: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 923/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2617 - acc: 0.8681 - val_loss: 0.7345 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 924: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 924/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2430 - acc: 0.8908 - val_loss: 0.7456 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 925: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 925/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2482 - acc: 0.8741 - val_loss: 0.7514 - val_acc: 0.7364 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 926: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 926/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2397 - acc: 0.8860 - val_loss: 0.7289 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 927: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 927/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2378 - acc: 0.8832 - val_loss: 0.7053 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 928: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 928/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2294 - acc: 0.8884 - val_loss: 0.7234 - val_acc: 0.7348 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 929: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 929/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2439 - acc: 0.8812 - val_loss: 0.7659 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 930: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 930/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2416 - acc: 0.8800 - val_loss: 0.7792 - val_acc: 0.7396 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 931: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 931/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2551 - acc: 0.8729 - val_loss: 0.7624 - val_acc: 0.7396 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 932: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 932/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2503 - acc: 0.8804 - val_loss: 0.7484 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 933: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 933/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2365 - acc: 0.8836 - val_loss: 0.7398 - val_acc: 0.7604 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 934: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 934/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2384 - acc: 0.8796 - val_loss: 0.7202 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 935: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 935/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2324 - acc: 0.8900 - val_loss: 0.7365 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 936: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 936/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2448 - acc: 0.8784 - val_loss: 0.7410 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 937: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 937/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2524 - acc: 0.8828 - val_loss: 0.7261 - val_acc: 0.7428 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 938: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 938/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2367 - acc: 0.8872 - val_loss: 0.7584 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 939: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 939/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2510 - acc: 0.8776 - val_loss: 0.7579 - val_acc: 0.7428 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 940: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 940/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2439 - acc: 0.8832 - val_loss: 0.7302 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 941: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 941/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2379 - acc: 0.8856 - val_loss: 0.7584 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 942: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 942/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2505 - acc: 0.8836 - val_loss: 0.7487 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 943: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 943/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2375 - acc: 0.8884 - val_loss: 0.7193 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 944: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 944/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2438 - acc: 0.8872 - val_loss: 0.7284 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 945: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 945/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2259 - acc: 0.8876 - val_loss: 0.7335 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 946: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 946/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2356 - acc: 0.8864 - val_loss: 0.7210 - val_acc: 0.7396 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 947: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 947/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2357 - acc: 0.8896 - val_loss: 0.7234 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 948: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 948/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2433 - acc: 0.8808 - val_loss: 0.7119 - val_acc: 0.7396 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 949: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 949/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2354 - acc: 0.8860 - val_loss: 0.7183 - val_acc: 0.7332 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 950: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 950/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2312 - acc: 0.8888 - val_loss: 0.7426 - val_acc: 0.7332 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 951: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 951/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2381 - acc: 0.8796 - val_loss: 0.7137 - val_acc: 0.7348 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 952: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 952/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2499 - acc: 0.8796 - val_loss: 0.7376 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 953: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 953/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2284 - acc: 0.8888 - val_loss: 0.7470 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 954: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 954/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2398 - acc: 0.8860 - val_loss: 0.7282 - val_acc: 0.7396 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 955: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 955/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2404 - acc: 0.8796 - val_loss: 0.7282 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 956: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 956/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2412 - acc: 0.8876 - val_loss: 0.7440 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 957: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 957/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2406 - acc: 0.8808 - val_loss: 0.7475 - val_acc: 0.7540 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 958: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 958/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2341 - acc: 0.8836 - val_loss: 0.7239 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 959: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 959/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2372 - acc: 0.8908 - val_loss: 0.7272 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 960: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 960/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2398 - acc: 0.8824 - val_loss: 0.7419 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 961: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 961/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2405 - acc: 0.8820 - val_loss: 0.7241 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 962: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 962/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2440 - acc: 0.8812 - val_loss: 0.7750 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 963: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 963/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2336 - acc: 0.8792 - val_loss: 0.7469 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 964: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 964/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2426 - acc: 0.8836 - val_loss: 0.7187 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 965: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 965/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2298 - acc: 0.8884 - val_loss: 0.7162 - val_acc: 0.7428 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 966: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 966/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2397 - acc: 0.8856 - val_loss: 0.7425 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 967: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 967/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2342 - acc: 0.8852 - val_loss: 0.7284 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 968: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 968/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2402 - acc: 0.8800 - val_loss: 0.7190 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 969: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 969/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2372 - acc: 0.8848 - val_loss: 0.7181 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 970: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 970/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2365 - acc: 0.8844 - val_loss: 0.7401 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 971: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 971/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2301 - acc: 0.8920 - val_loss: 0.7455 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 972: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 972/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2470 - acc: 0.8800 - val_loss: 0.7470 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 973: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 973/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2330 - acc: 0.8812 - val_loss: 0.7435 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 974: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 974/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2340 - acc: 0.8952 - val_loss: 0.7259 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 975: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 975/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2258 - acc: 0.8844 - val_loss: 0.7229 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 976: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 976/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2442 - acc: 0.8876 - val_loss: 0.7451 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 977: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 977/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2412 - acc: 0.8908 - val_loss: 0.7196 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 978: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 978/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2363 - acc: 0.8852 - val_loss: 0.6996 - val_acc: 0.7412 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 979: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 979/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2321 - acc: 0.8928 - val_loss: 0.7156 - val_acc: 0.7396 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 980: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 980/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2457 - acc: 0.8808 - val_loss: 0.7519 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 981: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 981/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2376 - acc: 0.8848 - val_loss: 0.7696 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 982: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 982/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2378 - acc: 0.8880 - val_loss: 0.7332 - val_acc: 0.7348 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 983: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 983/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2371 - acc: 0.8912 - val_loss: 0.7650 - val_acc: 0.7508 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 984: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 984/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2415 - acc: 0.8868 - val_loss: 0.7680 - val_acc: 0.7492 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 985: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 985/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2361 - acc: 0.8904 - val_loss: 0.7671 - val_acc: 0.7380 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 986: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 986/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2328 - acc: 0.8836 - val_loss: 0.7611 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 987: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 987/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2322 - acc: 0.8896 - val_loss: 0.7577 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 988: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 988/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2336 - acc: 0.8864 - val_loss: 0.7527 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 989: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 989/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2430 - acc: 0.8828 - val_loss: 0.7589 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 990: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 990/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2319 - acc: 0.8864 - val_loss: 0.7394 - val_acc: 0.7444 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 991: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 991/1000\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2312 - acc: 0.8928 - val_loss: 0.7555 - val_acc: 0.7380 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 992: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 992/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2353 - acc: 0.8908 - val_loss: 0.7339 - val_acc: 0.7460 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 993: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 993/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2415 - acc: 0.8868 - val_loss: 0.7446 - val_acc: 0.7380 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 994: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 994/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2312 - acc: 0.8932 - val_loss: 0.7650 - val_acc: 0.7428 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 995: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 995/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2347 - acc: 0.8904 - val_loss: 0.7383 - val_acc: 0.7428 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 996: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 996/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2468 - acc: 0.8725 - val_loss: 0.7295 - val_acc: 0.7428 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 997: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 997/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2358 - acc: 0.8904 - val_loss: 0.7459 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 998: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 998/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2401 - acc: 0.8820 - val_loss: 0.7614 - val_acc: 0.7524 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 999: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 999/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2299 - acc: 0.8912 - val_loss: 0.7415 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 1000: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 1000/1000\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2339 - acc: 0.8884 - val_loss: 0.7403 - val_acc: 0.7460 - lr: 1.0000e-05\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train,\n",
        "                    y_train,\n",
        "                    validation_data = (X_val, y_val),\n",
        "                    epochs = 1000,\n",
        "                    callbacks = [callback],\n",
        "                    batch_size = 128,\n",
        "                    shuffle = True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 944
        },
        "id": "r1QOJHU0VXOy",
        "outputId": "c4c54dbf-2985-443d-fe1c-130e85d0d503"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'acc', 'val_loss', 'val_acc', 'lr'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJvn_ZLRlyhI",
        "outputId": "04cd2c72-ac8c-4892-cb30-b6c58f4ca5b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25/25 [==============================] - 0s 6ms/step - loss: 0.7405 - acc: 0.7826\n",
            "test_loss, test_acc: [0.740469753742218, 0.782608687877655]\n"
          ]
        }
      ],
      "source": [
        "results = model.evaluate(X_test, y_test)\n",
        "print(\"test_loss, test_acc:\", results)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# See predictions by class\n",
        "model_pred = model.predict(X_test, batch_size = 64)\n",
        "\n",
        "print(classification_report(y_test, np.where(model_pred > 0.5, 1, 0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sesPcXxMzAcM",
        "outputId": "1c67d564-7093-489d-d629-cbcf684837bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 0s 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.84      0.80       399\n",
            "           1       0.81      0.73      0.77       383\n",
            "\n",
            "    accuracy                           0.78       782\n",
            "   macro avg       0.79      0.78      0.78       782\n",
            "weighted avg       0.79      0.78      0.78       782\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save 78% acc model\n",
        "model.save(\"/content/drive/MyDrive/models/model_78acc.keras\")"
      ],
      "metadata": {
        "id": "NDRbq0lW0Q8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Chen\n",
        "\n",
        "Based on the paper Chen et al. (2020). Augmenting a deep-learning algorithm with canal inspection knowledge for reliable water leak detection from multispectral satellite images. https://doi.org/10.1016/j.aei.2020.101161"
      ],
      "metadata": {
        "id": "V4fhnC711wwb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2IkznB9lyhI",
        "outputId": "1ca08d25-1749-44fa-f769-16233ed251d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_49 (Conv2D)          (None, 20, 20, 32)        4064      \n",
            "                                                                 \n",
            " batch_normalization_21 (Bat  (None, 20, 20, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_63 (Activation)  (None, 20, 20, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d_29 (MaxPoolin  (None, 10, 10, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_50 (Conv2D)          (None, 10, 10, 32)        9248      \n",
            "                                                                 \n",
            " activation_64 (Activation)  (None, 10, 10, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d_30 (MaxPoolin  (None, 5, 5, 32)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_39 (Dropout)        (None, 5, 5, 32)          0         \n",
            "                                                                 \n",
            " conv2d_51 (Conv2D)          (None, 5, 5, 64)          18496     \n",
            "                                                                 \n",
            " batch_normalization_22 (Bat  (None, 5, 5, 64)         256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_65 (Activation)  (None, 5, 5, 64)          0         \n",
            "                                                                 \n",
            " dropout_40 (Dropout)        (None, 5, 5, 64)          0         \n",
            "                                                                 \n",
            " max_pooling2d_31 (MaxPoolin  (None, 2, 2, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_16 (Flatten)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout_41 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_39 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 65,217\n",
            "Trainable params: 65,025\n",
            "Non-trainable params: 192\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_chen = Sequential()\n",
        "\n",
        "# 1st Conv layer\n",
        "model_chen.add(Conv2D(32, kernel_size = (3, 3), input_shape = (20, 20, 14), padding = \"same\"))\n",
        "model_chen.add(BatchNormalization())\n",
        "model_chen.add(Activation(\"relu\"))\n",
        "model_chen.add(MaxPool2D(2, 2))\n",
        "\n",
        "# 2nd Conv layer\n",
        "model_chen.add(Conv2D(32, kernel_size = (3, 3), padding = \"same\"))\n",
        "model_chen.add(Activation(\"relu\"))\n",
        "model_chen.add(MaxPool2D(2, 2))\n",
        "model_chen.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "# 3rd Conv layer\n",
        "model_chen.add(Conv2D(64, kernel_size = (3, 3), padding = \"same\"))\n",
        "model_chen.add(BatchNormalization())\n",
        "model_chen.add(Activation(\"relu\"))\n",
        "model_chen.add(Dropout(0.3))\n",
        "model_chen.add(MaxPool2D(2, 2))\n",
        "\n",
        "# Dense layer\n",
        "model_chen.add(Flatten())\n",
        "model_chen.add(Dense(128, activation = \"relu\"))\n",
        "model_chen.add(Dropout(0.5))\n",
        "model_chen.add(Dense(1, activation = \"sigmoid\"))\n",
        "\n",
        "model_chen.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZBls84wlyhJ"
      },
      "outputs": [],
      "source": [
        "optim = optimizers.Adam(learning_rate = 0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LWN9eSnlyhJ"
      },
      "outputs": [],
      "source": [
        "model_chen.compile(loss = \"binary_crossentropy\",\n",
        "                   optimizer = optim,\n",
        "                   metrics = [\"acc\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNOwaer9lyhJ",
        "outputId": "eb7b908e-c417-4b86-955b-6c5b727b22e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "5/5 [==============================] - 3s 66ms/step - loss: 1.0164 - acc: 0.4858 - val_loss: 0.8599 - val_acc: 0.4629\n",
            "Epoch 2/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.7797 - acc: 0.5138 - val_loss: 0.9208 - val_acc: 0.4680\n",
            "Epoch 3/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.7113 - acc: 0.5346 - val_loss: 1.2294 - val_acc: 0.4680\n",
            "Epoch 4/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6983 - acc: 0.5394 - val_loss: 1.5211 - val_acc: 0.4680\n",
            "Epoch 5/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6860 - acc: 0.5338 - val_loss: 1.5421 - val_acc: 0.4680\n",
            "Epoch 6/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6807 - acc: 0.5314 - val_loss: 1.5911 - val_acc: 0.4680\n",
            "Epoch 7/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6816 - acc: 0.5534 - val_loss: 1.5801 - val_acc: 0.4680\n",
            "Epoch 8/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6784 - acc: 0.5626 - val_loss: 1.4977 - val_acc: 0.4680\n",
            "Epoch 9/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6705 - acc: 0.5658 - val_loss: 1.3994 - val_acc: 0.4680\n",
            "Epoch 10/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6697 - acc: 0.5758 - val_loss: 1.4903 - val_acc: 0.4680\n",
            "Epoch 11/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6649 - acc: 0.5818 - val_loss: 1.4758 - val_acc: 0.4680\n",
            "Epoch 12/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6603 - acc: 0.5898 - val_loss: 1.4094 - val_acc: 0.4680\n",
            "Epoch 13/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6595 - acc: 0.5934 - val_loss: 1.3360 - val_acc: 0.4680\n",
            "Epoch 14/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6541 - acc: 0.5970 - val_loss: 1.2148 - val_acc: 0.4680\n",
            "Epoch 15/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6514 - acc: 0.5998 - val_loss: 1.1134 - val_acc: 0.4680\n",
            "Epoch 16/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6600 - acc: 0.5922 - val_loss: 1.0785 - val_acc: 0.4680\n",
            "Epoch 17/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6519 - acc: 0.5974 - val_loss: 0.9388 - val_acc: 0.4680\n",
            "Epoch 18/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6502 - acc: 0.6170 - val_loss: 0.7981 - val_acc: 0.4719\n",
            "Epoch 19/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6449 - acc: 0.6098 - val_loss: 0.8035 - val_acc: 0.4770\n",
            "Epoch 20/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6364 - acc: 0.6305 - val_loss: 0.7346 - val_acc: 0.4629\n",
            "Epoch 21/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6340 - acc: 0.6273 - val_loss: 0.7021 - val_acc: 0.4591\n",
            "Epoch 22/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6293 - acc: 0.6453 - val_loss: 0.7337 - val_acc: 0.4361\n",
            "Epoch 23/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6238 - acc: 0.6445 - val_loss: 0.8279 - val_acc: 0.4744\n",
            "Epoch 24/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6168 - acc: 0.6597 - val_loss: 0.6956 - val_acc: 0.5512\n",
            "Epoch 25/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6042 - acc: 0.6617 - val_loss: 0.7439 - val_acc: 0.4655\n",
            "Epoch 26/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5999 - acc: 0.6713 - val_loss: 0.7518 - val_acc: 0.4527\n",
            "Epoch 27/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5959 - acc: 0.6749 - val_loss: 0.7102 - val_acc: 0.4578\n",
            "Epoch 28/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5817 - acc: 0.6805 - val_loss: 0.7153 - val_acc: 0.5000\n",
            "Epoch 29/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5820 - acc: 0.6845 - val_loss: 0.7478 - val_acc: 0.5013\n",
            "Epoch 30/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5757 - acc: 0.6949 - val_loss: 0.6950 - val_acc: 0.5563\n",
            "Epoch 31/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5699 - acc: 0.6957 - val_loss: 0.6788 - val_acc: 0.5153\n",
            "Epoch 32/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5631 - acc: 0.6949 - val_loss: 0.7385 - val_acc: 0.4859\n",
            "Epoch 33/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5557 - acc: 0.7125 - val_loss: 0.8163 - val_acc: 0.4885\n",
            "Epoch 34/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5427 - acc: 0.7333 - val_loss: 0.7052 - val_acc: 0.4668\n",
            "Epoch 35/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5316 - acc: 0.7205 - val_loss: 0.8136 - val_acc: 0.4693\n",
            "Epoch 36/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5293 - acc: 0.7493 - val_loss: 0.8528 - val_acc: 0.4668\n",
            "Epoch 37/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5197 - acc: 0.7369 - val_loss: 0.7690 - val_acc: 0.4680\n",
            "Epoch 38/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5171 - acc: 0.7377 - val_loss: 0.7212 - val_acc: 0.4706\n",
            "Epoch 39/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5032 - acc: 0.7425 - val_loss: 0.6965 - val_acc: 0.5294\n",
            "Epoch 40/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5052 - acc: 0.7437 - val_loss: 0.7365 - val_acc: 0.4655\n",
            "Epoch 41/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5047 - acc: 0.7393 - val_loss: 0.8296 - val_acc: 0.4693\n",
            "Epoch 42/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4958 - acc: 0.7441 - val_loss: 0.6943 - val_acc: 0.5294\n",
            "Epoch 43/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4988 - acc: 0.7481 - val_loss: 0.7490 - val_acc: 0.4757\n",
            "Epoch 44/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4861 - acc: 0.7577 - val_loss: 0.6764 - val_acc: 0.5703\n",
            "Epoch 45/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.4846 - acc: 0.7573 - val_loss: 0.6819 - val_acc: 0.5358\n",
            "Epoch 46/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.4707 - acc: 0.7613 - val_loss: 0.6545 - val_acc: 0.6215\n",
            "Epoch 47/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.4769 - acc: 0.7645 - val_loss: 0.7492 - val_acc: 0.4629\n",
            "Epoch 48/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.4574 - acc: 0.7753 - val_loss: 0.6739 - val_acc: 0.5448\n",
            "Epoch 49/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.4607 - acc: 0.7669 - val_loss: 0.6908 - val_acc: 0.5550\n",
            "Epoch 50/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4533 - acc: 0.7769 - val_loss: 0.6690 - val_acc: 0.5512\n",
            "Epoch 51/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.4544 - acc: 0.7737 - val_loss: 0.6555 - val_acc: 0.5895\n",
            "Epoch 52/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.4549 - acc: 0.7645 - val_loss: 0.6566 - val_acc: 0.6240\n",
            "Epoch 53/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.4453 - acc: 0.7665 - val_loss: 0.6551 - val_acc: 0.6100\n",
            "Epoch 54/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.4456 - acc: 0.7825 - val_loss: 0.7682 - val_acc: 0.4783\n",
            "Epoch 55/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.4486 - acc: 0.7713 - val_loss: 0.6582 - val_acc: 0.5524\n",
            "Epoch 56/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.4393 - acc: 0.7821 - val_loss: 0.6716 - val_acc: 0.5371\n",
            "Epoch 57/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.4246 - acc: 0.7909 - val_loss: 0.6696 - val_acc: 0.5512\n",
            "Epoch 58/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4221 - acc: 0.7957 - val_loss: 0.6791 - val_acc: 0.5601\n",
            "Epoch 59/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.4203 - acc: 0.7865 - val_loss: 0.6997 - val_acc: 0.5882\n",
            "Epoch 60/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.4219 - acc: 0.7837 - val_loss: 0.6818 - val_acc: 0.5716\n",
            "Epoch 61/200\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.4154 - acc: 0.7961 - val_loss: 0.6350 - val_acc: 0.6164\n",
            "Epoch 62/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.4202 - acc: 0.7957 - val_loss: 0.6575 - val_acc: 0.5997\n",
            "Epoch 63/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.4093 - acc: 0.7897 - val_loss: 0.6648 - val_acc: 0.5665\n",
            "Epoch 64/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.4191 - acc: 0.7933 - val_loss: 0.6604 - val_acc: 0.5716\n",
            "Epoch 65/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.4249 - acc: 0.7857 - val_loss: 0.8532 - val_acc: 0.5435\n",
            "Epoch 66/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3982 - acc: 0.8049 - val_loss: 0.6527 - val_acc: 0.5499\n",
            "Epoch 67/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.4023 - acc: 0.7977 - val_loss: 0.6645 - val_acc: 0.5997\n",
            "Epoch 68/200\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3956 - acc: 0.7981 - val_loss: 0.8394 - val_acc: 0.6113\n",
            "Epoch 69/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3881 - acc: 0.8081 - val_loss: 0.6933 - val_acc: 0.6036\n",
            "Epoch 70/200\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3801 - acc: 0.8121 - val_loss: 0.6851 - val_acc: 0.5934\n",
            "Epoch 71/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3786 - acc: 0.8225 - val_loss: 0.7121 - val_acc: 0.5614\n",
            "Epoch 72/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3916 - acc: 0.8077 - val_loss: 0.6340 - val_acc: 0.6522\n",
            "Epoch 73/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3777 - acc: 0.8133 - val_loss: 0.6440 - val_acc: 0.5831\n",
            "Epoch 74/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3797 - acc: 0.8105 - val_loss: 0.7279 - val_acc: 0.5946\n",
            "Epoch 75/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3717 - acc: 0.8197 - val_loss: 0.6711 - val_acc: 0.5639\n",
            "Epoch 76/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3683 - acc: 0.8185 - val_loss: 0.6969 - val_acc: 0.5691\n",
            "Epoch 77/200\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3605 - acc: 0.8129 - val_loss: 0.5949 - val_acc: 0.6931\n",
            "Epoch 78/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3651 - acc: 0.8253 - val_loss: 0.6080 - val_acc: 0.6368\n",
            "Epoch 79/200\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3607 - acc: 0.8225 - val_loss: 0.7012 - val_acc: 0.6304\n",
            "Epoch 80/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3735 - acc: 0.8197 - val_loss: 0.5950 - val_acc: 0.6611\n",
            "Epoch 81/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3661 - acc: 0.8141 - val_loss: 0.6539 - val_acc: 0.6240\n",
            "Epoch 82/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3663 - acc: 0.8189 - val_loss: 0.6876 - val_acc: 0.5972\n",
            "Epoch 83/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3473 - acc: 0.8309 - val_loss: 0.7540 - val_acc: 0.5665\n",
            "Epoch 84/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3393 - acc: 0.8325 - val_loss: 0.7643 - val_acc: 0.5166\n",
            "Epoch 85/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3414 - acc: 0.8241 - val_loss: 0.6247 - val_acc: 0.6061\n",
            "Epoch 86/200\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3424 - acc: 0.8273 - val_loss: 0.6745 - val_acc: 0.5857\n",
            "Epoch 87/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3344 - acc: 0.8321 - val_loss: 0.6284 - val_acc: 0.6228\n",
            "Epoch 88/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3537 - acc: 0.8297 - val_loss: 0.6570 - val_acc: 0.5870\n",
            "Epoch 89/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3382 - acc: 0.8325 - val_loss: 0.6479 - val_acc: 0.6381\n",
            "Epoch 90/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3370 - acc: 0.8361 - val_loss: 0.7739 - val_acc: 0.5141\n",
            "Epoch 91/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3432 - acc: 0.8333 - val_loss: 0.6978 - val_acc: 0.5857\n",
            "Epoch 92/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3296 - acc: 0.8417 - val_loss: 0.6285 - val_acc: 0.6483\n",
            "Epoch 93/200\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3405 - acc: 0.8325 - val_loss: 0.8420 - val_acc: 0.5882\n",
            "Epoch 94/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3448 - acc: 0.8257 - val_loss: 0.5810 - val_acc: 0.6739\n",
            "Epoch 95/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3443 - acc: 0.8229 - val_loss: 0.6358 - val_acc: 0.5972\n",
            "Epoch 96/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3357 - acc: 0.8301 - val_loss: 0.6209 - val_acc: 0.6598\n",
            "Epoch 97/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3397 - acc: 0.8289 - val_loss: 0.6839 - val_acc: 0.6547\n",
            "Epoch 98/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3244 - acc: 0.8385 - val_loss: 0.6671 - val_acc: 0.6061\n",
            "Epoch 99/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3119 - acc: 0.8429 - val_loss: 0.7435 - val_acc: 0.5358\n",
            "Epoch 100/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3137 - acc: 0.8445 - val_loss: 0.7447 - val_acc: 0.6637\n",
            "Epoch 101/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3206 - acc: 0.8437 - val_loss: 0.6960 - val_acc: 0.6176\n",
            "Epoch 102/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3143 - acc: 0.8405 - val_loss: 0.9976 - val_acc: 0.6036\n",
            "Epoch 103/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3175 - acc: 0.8421 - val_loss: 0.8680 - val_acc: 0.6330\n",
            "Epoch 104/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3269 - acc: 0.8393 - val_loss: 0.7398 - val_acc: 0.5460\n",
            "Epoch 105/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3242 - acc: 0.8373 - val_loss: 1.0386 - val_acc: 0.5844\n",
            "Epoch 106/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3283 - acc: 0.8337 - val_loss: 0.7173 - val_acc: 0.5895\n",
            "Epoch 107/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3069 - acc: 0.8473 - val_loss: 0.8954 - val_acc: 0.6432\n",
            "Epoch 108/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3092 - acc: 0.8469 - val_loss: 0.8954 - val_acc: 0.6292\n",
            "Epoch 109/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3061 - acc: 0.8441 - val_loss: 0.7682 - val_acc: 0.5780\n",
            "Epoch 110/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3138 - acc: 0.8497 - val_loss: 0.7930 - val_acc: 0.6509\n",
            "Epoch 111/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2989 - acc: 0.8485 - val_loss: 0.7966 - val_acc: 0.6547\n",
            "Epoch 112/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3074 - acc: 0.8437 - val_loss: 0.6876 - val_acc: 0.6841\n",
            "Epoch 113/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2948 - acc: 0.8593 - val_loss: 0.6571 - val_acc: 0.7110\n",
            "Epoch 114/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2917 - acc: 0.8553 - val_loss: 0.8424 - val_acc: 0.6535\n",
            "Epoch 115/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2921 - acc: 0.8597 - val_loss: 0.6114 - val_acc: 0.7123\n",
            "Epoch 116/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2818 - acc: 0.8669 - val_loss: 0.6880 - val_acc: 0.6330\n",
            "Epoch 117/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2832 - acc: 0.8573 - val_loss: 0.9296 - val_acc: 0.5691\n",
            "Epoch 118/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2827 - acc: 0.8637 - val_loss: 1.1357 - val_acc: 0.6036\n",
            "Epoch 119/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2930 - acc: 0.8437 - val_loss: 0.7936 - val_acc: 0.6445\n",
            "Epoch 120/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2867 - acc: 0.8505 - val_loss: 0.7642 - val_acc: 0.5946\n",
            "Epoch 121/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2826 - acc: 0.8601 - val_loss: 0.7292 - val_acc: 0.6573\n",
            "Epoch 122/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2795 - acc: 0.8597 - val_loss: 0.8921 - val_acc: 0.6496\n",
            "Epoch 123/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2809 - acc: 0.8605 - val_loss: 1.2430 - val_acc: 0.6189\n",
            "Epoch 124/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2828 - acc: 0.8569 - val_loss: 1.0474 - val_acc: 0.5895\n",
            "Epoch 125/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2852 - acc: 0.8537 - val_loss: 0.7561 - val_acc: 0.6445\n",
            "Epoch 126/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2829 - acc: 0.8645 - val_loss: 0.8726 - val_acc: 0.6125\n",
            "Epoch 127/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2843 - acc: 0.8629 - val_loss: 0.7657 - val_acc: 0.6586\n",
            "Epoch 128/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2785 - acc: 0.8621 - val_loss: 0.7502 - val_acc: 0.6573\n",
            "Epoch 129/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2754 - acc: 0.8625 - val_loss: 0.7539 - val_acc: 0.6624\n",
            "Epoch 130/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2633 - acc: 0.8689 - val_loss: 0.5795 - val_acc: 0.6854\n",
            "Epoch 131/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2754 - acc: 0.8581 - val_loss: 0.6499 - val_acc: 0.6790\n",
            "Epoch 132/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2717 - acc: 0.8705 - val_loss: 0.6675 - val_acc: 0.6918\n",
            "Epoch 133/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2723 - acc: 0.8693 - val_loss: 0.9863 - val_acc: 0.6394\n",
            "Epoch 134/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2683 - acc: 0.8705 - val_loss: 0.7534 - val_acc: 0.6573\n",
            "Epoch 135/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2637 - acc: 0.8717 - val_loss: 0.9816 - val_acc: 0.6061\n",
            "Epoch 136/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2700 - acc: 0.8717 - val_loss: 0.7812 - val_acc: 0.6739\n",
            "Epoch 137/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2818 - acc: 0.8585 - val_loss: 1.4296 - val_acc: 0.6036\n",
            "Epoch 138/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2590 - acc: 0.8653 - val_loss: 0.8435 - val_acc: 0.6279\n",
            "Epoch 139/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2677 - acc: 0.8768 - val_loss: 0.6903 - val_acc: 0.6790\n",
            "Epoch 140/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2620 - acc: 0.8689 - val_loss: 0.8872 - val_acc: 0.5997\n",
            "Epoch 141/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2682 - acc: 0.8717 - val_loss: 0.9603 - val_acc: 0.6228\n",
            "Epoch 142/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2539 - acc: 0.8725 - val_loss: 0.8453 - val_acc: 0.6407\n",
            "Epoch 143/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2680 - acc: 0.8689 - val_loss: 0.8434 - val_acc: 0.6560\n",
            "Epoch 144/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2665 - acc: 0.8673 - val_loss: 0.7238 - val_acc: 0.6483\n",
            "Epoch 145/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2668 - acc: 0.8677 - val_loss: 0.7590 - val_acc: 0.6432\n",
            "Epoch 146/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2735 - acc: 0.8685 - val_loss: 0.7221 - val_acc: 0.6675\n",
            "Epoch 147/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2761 - acc: 0.8717 - val_loss: 0.6741 - val_acc: 0.7174\n",
            "Epoch 148/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2627 - acc: 0.8721 - val_loss: 0.8316 - val_acc: 0.6228\n",
            "Epoch 149/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2452 - acc: 0.8816 - val_loss: 0.8281 - val_acc: 0.6841\n",
            "Epoch 150/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2547 - acc: 0.8788 - val_loss: 0.7136 - val_acc: 0.6777\n",
            "Epoch 151/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2573 - acc: 0.8693 - val_loss: 1.0915 - val_acc: 0.6074\n",
            "Epoch 152/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2438 - acc: 0.8764 - val_loss: 1.9132 - val_acc: 0.4974\n",
            "Epoch 153/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2503 - acc: 0.8784 - val_loss: 0.8223 - val_acc: 0.6381\n",
            "Epoch 154/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2488 - acc: 0.8816 - val_loss: 0.6934 - val_acc: 0.6752\n",
            "Epoch 155/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2427 - acc: 0.8828 - val_loss: 0.7319 - val_acc: 0.6739\n",
            "Epoch 156/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2547 - acc: 0.8752 - val_loss: 0.9008 - val_acc: 0.6317\n",
            "Epoch 157/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2345 - acc: 0.8880 - val_loss: 0.7849 - val_acc: 0.6726\n",
            "Epoch 158/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2401 - acc: 0.8824 - val_loss: 0.8413 - val_acc: 0.6714\n",
            "Epoch 159/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2382 - acc: 0.8852 - val_loss: 1.8622 - val_acc: 0.5205\n",
            "Epoch 160/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2436 - acc: 0.8844 - val_loss: 1.0089 - val_acc: 0.6023\n",
            "Epoch 161/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2320 - acc: 0.8912 - val_loss: 1.1045 - val_acc: 0.5217\n",
            "Epoch 162/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2545 - acc: 0.8764 - val_loss: 1.2416 - val_acc: 0.5524\n",
            "Epoch 163/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2477 - acc: 0.8780 - val_loss: 0.8565 - val_acc: 0.6125\n",
            "Epoch 164/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2440 - acc: 0.8880 - val_loss: 0.9599 - val_acc: 0.5601\n",
            "Epoch 165/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2400 - acc: 0.8796 - val_loss: 0.8059 - val_acc: 0.6816\n",
            "Epoch 166/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2372 - acc: 0.8944 - val_loss: 0.7364 - val_acc: 0.6394\n",
            "Epoch 167/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2478 - acc: 0.8856 - val_loss: 0.8808 - val_acc: 0.6816\n",
            "Epoch 168/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2534 - acc: 0.8756 - val_loss: 1.0417 - val_acc: 0.6343\n",
            "Epoch 169/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2555 - acc: 0.8745 - val_loss: 1.7112 - val_acc: 0.5588\n",
            "Epoch 170/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2427 - acc: 0.8924 - val_loss: 6.1355 - val_acc: 0.4642\n",
            "Epoch 171/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2354 - acc: 0.8904 - val_loss: 0.9156 - val_acc: 0.5985\n",
            "Epoch 172/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2412 - acc: 0.8892 - val_loss: 0.7276 - val_acc: 0.6471\n",
            "Epoch 173/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2303 - acc: 0.8912 - val_loss: 1.1908 - val_acc: 0.6598\n",
            "Epoch 174/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2366 - acc: 0.8836 - val_loss: 0.8960 - val_acc: 0.6087\n",
            "Epoch 175/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2420 - acc: 0.8892 - val_loss: 1.2623 - val_acc: 0.5499\n",
            "Epoch 176/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2266 - acc: 0.8920 - val_loss: 0.9480 - val_acc: 0.6049\n",
            "Epoch 177/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2260 - acc: 0.8884 - val_loss: 0.9697 - val_acc: 0.5857\n",
            "Epoch 178/200\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.2195 - acc: 0.8972 - val_loss: 1.4209 - val_acc: 0.5460\n",
            "Epoch 179/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2262 - acc: 0.8936 - val_loss: 1.0392 - val_acc: 0.6061\n",
            "Epoch 180/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2171 - acc: 0.9024 - val_loss: 0.9499 - val_acc: 0.6151\n",
            "Epoch 181/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2106 - acc: 0.9016 - val_loss: 0.8478 - val_acc: 0.6138\n",
            "Epoch 182/200\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.2175 - acc: 0.9004 - val_loss: 1.3276 - val_acc: 0.6125\n",
            "Epoch 183/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2211 - acc: 0.8960 - val_loss: 1.0243 - val_acc: 0.6240\n",
            "Epoch 184/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2138 - acc: 0.9052 - val_loss: 0.8681 - val_acc: 0.5754\n",
            "Epoch 185/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2132 - acc: 0.9004 - val_loss: 1.1183 - val_acc: 0.5524\n",
            "Epoch 186/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2050 - acc: 0.8988 - val_loss: 1.1853 - val_acc: 0.5818\n",
            "Epoch 187/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2035 - acc: 0.9068 - val_loss: 1.4050 - val_acc: 0.6087\n",
            "Epoch 188/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2146 - acc: 0.9024 - val_loss: 1.0487 - val_acc: 0.6547\n",
            "Epoch 189/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2067 - acc: 0.9032 - val_loss: 1.2159 - val_acc: 0.6061\n",
            "Epoch 190/200\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.2038 - acc: 0.9084 - val_loss: 1.3400 - val_acc: 0.5486\n",
            "Epoch 191/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2044 - acc: 0.9048 - val_loss: 0.9302 - val_acc: 0.6854\n",
            "Epoch 192/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2069 - acc: 0.9036 - val_loss: 0.8586 - val_acc: 0.6854\n",
            "Epoch 193/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1998 - acc: 0.9072 - val_loss: 0.6793 - val_acc: 0.6982\n",
            "Epoch 194/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2174 - acc: 0.8960 - val_loss: 0.8954 - val_acc: 0.5754\n",
            "Epoch 195/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2219 - acc: 0.8952 - val_loss: 0.8055 - val_acc: 0.5985\n",
            "Epoch 196/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2162 - acc: 0.8944 - val_loss: 0.6795 - val_acc: 0.6535\n",
            "Epoch 197/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2206 - acc: 0.8948 - val_loss: 0.8901 - val_acc: 0.6330\n",
            "Epoch 198/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2183 - acc: 0.9024 - val_loss: 0.8055 - val_acc: 0.6688\n",
            "Epoch 199/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2074 - acc: 0.8976 - val_loss: 0.9098 - val_acc: 0.6496\n",
            "Epoch 200/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2088 - acc: 0.9004 - val_loss: 0.7197 - val_acc: 0.6573\n"
          ]
        }
      ],
      "source": [
        "history_chen = model_chen.fit(X_train,\n",
        "                         y_train,\n",
        "                         validation_data = (X_val, y_val),\n",
        "                         epochs = 200,\n",
        "                         batch_size = 512)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# list all data in history_chen\n",
        "print(history_chen.history.keys())\n",
        "# summarize history_chen for accuracy\n",
        "plt.plot(history_chen.history['acc'])\n",
        "plt.plot(history_chen.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history_chen for loss\n",
        "plt.plot(history_chen.history['loss'])\n",
        "plt.plot(history_chen.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 945
        },
        "id": "WzBTgb6NYeiM",
        "outputId": "fd4bb9d2-eb7d-4ac4-9ae6-1abb76d6c49d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvgCs8WWlyhJ",
        "outputId": "90daceb3-760e-4f0e-dd8f-7137c2b95759"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4270 - acc: 0.6422\n",
            "test_loss, test_acc: [1.426953911781311, 0.6421725153923035]\n"
          ]
        }
      ],
      "source": [
        "results_chen = model_chen.evaluate(X_test, y_test, batch_size = 64)\n",
        "print(\"test_loss, test_acc:\", results_chen)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# See predictions by class\n",
        "model_chen_pred = model_chen.predict(X_test, batch_size = 64)\n",
        "\n",
        "print(classification_report(y_test, np.where(model_chen_pred > 0.5, 1, 0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tH9R5UUFYFir",
        "outputId": "7218063d-0b96-49b5-acb4-7c0d13e67efb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 0s 3ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.77      0.73       323\n",
            "           1       0.72      0.63      0.67       303\n",
            "\n",
            "    accuracy                           0.70       626\n",
            "   macro avg       0.70      0.70      0.70       626\n",
            "weighted avg       0.70      0.70      0.70       626\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save 79% acc model\n",
        "model_chen.save(\"/content/drive/MyDrive/models/model_79acc.keras\")"
      ],
      "metadata": {
        "id": "vgnoShFFZFNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple architecture"
      ],
      "metadata": {
        "id": "SfoNtYgrpppc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgbtWvdnQV76",
        "outputId": "87b0d205-ff81-49b7-b132-886dbb92b2bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 20, 20, 32)        1824      \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 20, 20, 32)       128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " activation (Activation)     (None, 20, 20, 32)        0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 20, 20, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 20, 20, 64)        32832     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 20, 20, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 20, 20, 64)        0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 20, 20, 64)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 10, 10, 128)       32896     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 10, 10, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 10, 10, 128)       0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 10, 10, 128)       0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 5, 5, 128)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 3200)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               819456    \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 512)               131584    \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 513       \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,020,001\n",
            "Trainable params: 1,019,553\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_simple = Sequential()\n",
        "\n",
        "# 1st Conv Layer\n",
        "model_simple.add(Conv2D(32, (2, 2), padding = \"same\", strides = (1, 1), input_shape = (20, 20, 14)))\n",
        "model_simple.add(BatchNormalization())\n",
        "model_simple.add(Activation(\"relu\"))\n",
        "model_simple.add(Dropout(0.2))\n",
        "\n",
        "# 2nd Conv layer\n",
        "model_simple.add(Conv2D(64, (4, 4), padding = \"same\", strides = (1, 1)))\n",
        "model_simple.add(BatchNormalization())\n",
        "model_simple.add(Activation(\"relu\"))\n",
        "model_simple.add(Dropout(0.5))\n",
        "\n",
        "# 3rd Conv layer\n",
        "model_simple.add(Conv2D(128, (2, 2), padding = \"same\", strides = (2, 2)))\n",
        "model_simple.add(BatchNormalization())\n",
        "model_simple.add(Activation(\"relu\"))\n",
        "model_simple.add(Dropout(0.5))\n",
        "model_simple.add(MaxPool2D(2, 2))\n",
        "\n",
        "# Dense layer\n",
        "model_simple.add(Flatten())\n",
        "model_simple.add(Dense(256))\n",
        "model_simple.add(Activation(\"relu\"))\n",
        "model_simple.add(Dropout(0.6))\n",
        "model_simple.add(Dense(512))\n",
        "model_simple.add(Activation(\"relu\"))\n",
        "model_simple.add(Dropout(0.3))\n",
        "model_simple.add(Dense(1))\n",
        "model_simple.add(Activation(\"sigmoid\"))\n",
        "\n",
        "model_simple.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scheduler(epoch, lr):\n",
        "    l = 0.0001\n",
        "    if epoch > 200:\n",
        "        l = 0.00001\n",
        "    if epoch > 400:\n",
        "        l = 0.000015\n",
        "    if epoch > 600:\n",
        "        l = 0.000001\n",
        "    if epoch > 700:\n",
        "        l = 0.000025\n",
        "    if epoch > 850:\n",
        "        l = 0.00004\n",
        "\n",
        "    return l"
      ],
      "metadata": {
        "id": "vFo6kqBjRFqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callback = LearningRateScheduler(scheduler, verbose = 1)"
      ],
      "metadata": {
        "id": "cFfNYgxjRlKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iosm7qkBTTAD"
      },
      "outputs": [],
      "source": [
        "optim_simple = optimizers.Adam()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emvevA5iTX6C"
      },
      "outputs": [],
      "source": [
        "model_simple.compile(optimizer = optim_simple,\n",
        "                     loss = \"binary_crossentropy\",\n",
        "                     metrics = [\"acc\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxbrpGthTqsB",
        "outputId": "c338c6d5-0666-4e95-a27a-2947522af09b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 1/1000\n",
            "5/5 [==============================] - 15s 213ms/step - loss: 1.0125 - acc: 0.5090 - val_loss: 1.1180 - val_acc: 0.5102 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 2/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.9358 - acc: 0.5018 - val_loss: 1.1179 - val_acc: 0.5102 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 3/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.8631 - acc: 0.4942 - val_loss: 1.2627 - val_acc: 0.5102 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 4/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.7859 - acc: 0.5154 - val_loss: 1.0370 - val_acc: 0.5102 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 5/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.7681 - acc: 0.5082 - val_loss: 0.8841 - val_acc: 0.5102 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 6/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.7304 - acc: 0.5242 - val_loss: 0.8231 - val_acc: 0.5102 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 7/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.7343 - acc: 0.5010 - val_loss: 0.7997 - val_acc: 0.5102 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 8/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.7199 - acc: 0.5034 - val_loss: 0.7937 - val_acc: 0.5102 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 9/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.7055 - acc: 0.5206 - val_loss: 0.7870 - val_acc: 0.5102 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 10/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6999 - acc: 0.5254 - val_loss: 0.7781 - val_acc: 0.5102 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 11/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6968 - acc: 0.5230 - val_loss: 0.7734 - val_acc: 0.5102 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 12/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6893 - acc: 0.5306 - val_loss: 0.7748 - val_acc: 0.5102 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 13/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6937 - acc: 0.5322 - val_loss: 0.7604 - val_acc: 0.5102 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 14/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6940 - acc: 0.5198 - val_loss: 0.7552 - val_acc: 0.5102 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 15/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6929 - acc: 0.5238 - val_loss: 0.7530 - val_acc: 0.5102 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 16: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 16/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6994 - acc: 0.5066 - val_loss: 0.7481 - val_acc: 0.5102 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 17: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 17/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6950 - acc: 0.5154 - val_loss: 0.7374 - val_acc: 0.5102 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 18: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 18/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6952 - acc: 0.5114 - val_loss: 0.7318 - val_acc: 0.5102 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 19: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 19/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6888 - acc: 0.5206 - val_loss: 0.7273 - val_acc: 0.5102 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 20: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 20/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6903 - acc: 0.5082 - val_loss: 0.7253 - val_acc: 0.5102 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 21: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 21/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6930 - acc: 0.5082 - val_loss: 0.7233 - val_acc: 0.5102 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 22: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 22/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6931 - acc: 0.5154 - val_loss: 0.7197 - val_acc: 0.5102 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 23: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 23/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6873 - acc: 0.5218 - val_loss: 0.7138 - val_acc: 0.5128 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 24: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 24/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6880 - acc: 0.5250 - val_loss: 0.7102 - val_acc: 0.5128 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 25: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 25/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6876 - acc: 0.5222 - val_loss: 0.7093 - val_acc: 0.5192 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 26: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 26/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6801 - acc: 0.5246 - val_loss: 0.7096 - val_acc: 0.5256 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 27: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 27/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6889 - acc: 0.5262 - val_loss: 0.7068 - val_acc: 0.5179 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 28: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 28/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6873 - acc: 0.5258 - val_loss: 0.7030 - val_acc: 0.5141 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 29: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 29/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6841 - acc: 0.5438 - val_loss: 0.7008 - val_acc: 0.5064 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 30: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 30/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6814 - acc: 0.5430 - val_loss: 0.6984 - val_acc: 0.5102 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 31: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 31/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6824 - acc: 0.5490 - val_loss: 0.6960 - val_acc: 0.5320 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 32: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 32/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6855 - acc: 0.5158 - val_loss: 0.6949 - val_acc: 0.5064 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 33: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 33/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6804 - acc: 0.5370 - val_loss: 0.6949 - val_acc: 0.5013 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 34: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 34/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6833 - acc: 0.5406 - val_loss: 0.6951 - val_acc: 0.5077 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 35: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 35/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6754 - acc: 0.5390 - val_loss: 0.6949 - val_acc: 0.5051 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 36: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 36/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6807 - acc: 0.5382 - val_loss: 0.6939 - val_acc: 0.5077 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 37: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 37/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6776 - acc: 0.5506 - val_loss: 0.6930 - val_acc: 0.5077 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 38: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 38/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6770 - acc: 0.5490 - val_loss: 0.6921 - val_acc: 0.4706 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 39: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 39/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6765 - acc: 0.5350 - val_loss: 0.6919 - val_acc: 0.4770 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 40: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 40/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6770 - acc: 0.5498 - val_loss: 0.6915 - val_acc: 0.4808 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 41: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 41/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6778 - acc: 0.5466 - val_loss: 0.6911 - val_acc: 0.4872 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 42: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 42/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6790 - acc: 0.5514 - val_loss: 0.6902 - val_acc: 0.5026 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 43: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 43/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6720 - acc: 0.5562 - val_loss: 0.6896 - val_acc: 0.5102 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 44: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 44/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6694 - acc: 0.5538 - val_loss: 0.6886 - val_acc: 0.5141 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 45: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 45/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6725 - acc: 0.5498 - val_loss: 0.6880 - val_acc: 0.5102 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 46: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 46/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6753 - acc: 0.5630 - val_loss: 0.6875 - val_acc: 0.5141 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 47: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 47/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.6714 - acc: 0.5642 - val_loss: 0.6871 - val_acc: 0.5230 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 48: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 48/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6722 - acc: 0.5614 - val_loss: 0.6865 - val_acc: 0.5358 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 49: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 49/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6704 - acc: 0.5518 - val_loss: 0.6860 - val_acc: 0.5358 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 50: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 50/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6709 - acc: 0.5526 - val_loss: 0.6860 - val_acc: 0.5384 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 51: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 51/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6695 - acc: 0.5578 - val_loss: 0.6856 - val_acc: 0.5371 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 52: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 52/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6679 - acc: 0.5738 - val_loss: 0.6850 - val_acc: 0.5460 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 53: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 53/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6701 - acc: 0.5646 - val_loss: 0.6850 - val_acc: 0.5524 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 54: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 54/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6709 - acc: 0.5554 - val_loss: 0.6844 - val_acc: 0.5550 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 55: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 55/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6701 - acc: 0.5622 - val_loss: 0.6843 - val_acc: 0.5550 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 56: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 56/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6729 - acc: 0.5474 - val_loss: 0.6838 - val_acc: 0.5550 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 57: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 57/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6668 - acc: 0.5714 - val_loss: 0.6830 - val_acc: 0.5550 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 58: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 58/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6690 - acc: 0.5662 - val_loss: 0.6821 - val_acc: 0.5614 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 59: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 59/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6662 - acc: 0.5622 - val_loss: 0.6821 - val_acc: 0.5588 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 60: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 60/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6725 - acc: 0.5506 - val_loss: 0.6828 - val_acc: 0.5537 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 61: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 61/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6705 - acc: 0.5718 - val_loss: 0.6834 - val_acc: 0.5448 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 62: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 62/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6682 - acc: 0.5630 - val_loss: 0.6823 - val_acc: 0.5550 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 63: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 63/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6644 - acc: 0.5602 - val_loss: 0.6811 - val_acc: 0.5588 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 64: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 64/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6684 - acc: 0.5646 - val_loss: 0.6798 - val_acc: 0.5601 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 65: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 65/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6662 - acc: 0.5654 - val_loss: 0.6785 - val_acc: 0.5601 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 66: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 66/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6628 - acc: 0.5678 - val_loss: 0.6775 - val_acc: 0.5614 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 67: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 67/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6648 - acc: 0.5738 - val_loss: 0.6771 - val_acc: 0.5588 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 68: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 68/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6677 - acc: 0.5622 - val_loss: 0.6773 - val_acc: 0.5601 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 69: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 69/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6657 - acc: 0.5694 - val_loss: 0.6782 - val_acc: 0.5614 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 70: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 70/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6575 - acc: 0.5874 - val_loss: 0.6777 - val_acc: 0.5614 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 71: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 71/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6664 - acc: 0.5710 - val_loss: 0.6770 - val_acc: 0.5601 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 72: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 72/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6616 - acc: 0.5694 - val_loss: 0.6764 - val_acc: 0.5588 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 73: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 73/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6576 - acc: 0.5746 - val_loss: 0.6762 - val_acc: 0.5588 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 74: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 74/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6590 - acc: 0.5650 - val_loss: 0.6760 - val_acc: 0.5601 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 75: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 75/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6568 - acc: 0.5862 - val_loss: 0.6759 - val_acc: 0.5601 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 76: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 76/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6514 - acc: 0.5802 - val_loss: 0.6746 - val_acc: 0.5601 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 77: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 77/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6598 - acc: 0.5770 - val_loss: 0.6751 - val_acc: 0.5588 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 78: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 78/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6552 - acc: 0.5854 - val_loss: 0.6751 - val_acc: 0.5601 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 79: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 79/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6610 - acc: 0.5758 - val_loss: 0.6736 - val_acc: 0.5588 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 80: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 80/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6526 - acc: 0.5734 - val_loss: 0.6721 - val_acc: 0.5575 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 81: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 81/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6515 - acc: 0.5918 - val_loss: 0.6702 - val_acc: 0.5588 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 82: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 82/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6569 - acc: 0.5894 - val_loss: 0.6688 - val_acc: 0.5588 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 83: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 83/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6559 - acc: 0.5874 - val_loss: 0.6694 - val_acc: 0.5588 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 84: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 84/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6480 - acc: 0.5946 - val_loss: 0.6682 - val_acc: 0.5588 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 85: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 85/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6522 - acc: 0.5854 - val_loss: 0.6662 - val_acc: 0.5665 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 86: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 86/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6462 - acc: 0.5970 - val_loss: 0.6650 - val_acc: 0.5691 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 87: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 87/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6483 - acc: 0.5906 - val_loss: 0.6645 - val_acc: 0.5639 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 88: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 88/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6512 - acc: 0.5950 - val_loss: 0.6653 - val_acc: 0.5588 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 89: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 89/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6451 - acc: 0.6038 - val_loss: 0.6666 - val_acc: 0.5601 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 90: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 90/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6503 - acc: 0.6078 - val_loss: 0.6668 - val_acc: 0.5588 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 91: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 91/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6475 - acc: 0.6030 - val_loss: 0.6663 - val_acc: 0.5588 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 92: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 92/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.6400 - acc: 0.6210 - val_loss: 0.6642 - val_acc: 0.5665 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 93: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 93/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6448 - acc: 0.6094 - val_loss: 0.6631 - val_acc: 0.5780 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 94: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 94/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6388 - acc: 0.6034 - val_loss: 0.6616 - val_acc: 0.5908 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 95: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 95/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6370 - acc: 0.6206 - val_loss: 0.6598 - val_acc: 0.5946 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 96: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 96/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6361 - acc: 0.6094 - val_loss: 0.6576 - val_acc: 0.5985 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 97: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 97/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6324 - acc: 0.6222 - val_loss: 0.6585 - val_acc: 0.5959 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 98: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 98/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6319 - acc: 0.6110 - val_loss: 0.6585 - val_acc: 0.5921 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 99: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 99/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6387 - acc: 0.6158 - val_loss: 0.6583 - val_acc: 0.5895 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 100: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 100/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6356 - acc: 0.6226 - val_loss: 0.6567 - val_acc: 0.5921 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 101: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 101/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6329 - acc: 0.6297 - val_loss: 0.6543 - val_acc: 0.5972 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 102: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 102/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6326 - acc: 0.6158 - val_loss: 0.6509 - val_acc: 0.5997 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 103: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 103/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6249 - acc: 0.6230 - val_loss: 0.6495 - val_acc: 0.6010 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 104: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 104/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6226 - acc: 0.6285 - val_loss: 0.6471 - val_acc: 0.6049 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 105: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 105/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6274 - acc: 0.6357 - val_loss: 0.6478 - val_acc: 0.6036 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 106: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 106/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6280 - acc: 0.6174 - val_loss: 0.6506 - val_acc: 0.6023 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 107: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 107/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6270 - acc: 0.6317 - val_loss: 0.6497 - val_acc: 0.6036 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 108: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 108/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6232 - acc: 0.6297 - val_loss: 0.6478 - val_acc: 0.6049 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 109: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 109/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6271 - acc: 0.6253 - val_loss: 0.6486 - val_acc: 0.6074 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 110: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 110/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6220 - acc: 0.6289 - val_loss: 0.6484 - val_acc: 0.6061 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 111: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 111/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6212 - acc: 0.6285 - val_loss: 0.6475 - val_acc: 0.6087 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 112: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 112/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6214 - acc: 0.6317 - val_loss: 0.6415 - val_acc: 0.6074 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 113: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 113/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.6273 - acc: 0.6194 - val_loss: 0.6358 - val_acc: 0.6087 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 114: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 114/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6156 - acc: 0.6441 - val_loss: 0.6347 - val_acc: 0.6074 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 115: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 115/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6202 - acc: 0.6313 - val_loss: 0.6343 - val_acc: 0.6087 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 116: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 116/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6139 - acc: 0.6293 - val_loss: 0.6333 - val_acc: 0.6113 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 117: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 117/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6155 - acc: 0.6445 - val_loss: 0.6327 - val_acc: 0.6036 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 118: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 118/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6219 - acc: 0.6317 - val_loss: 0.6358 - val_acc: 0.6100 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 119: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 119/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6141 - acc: 0.6297 - val_loss: 0.6410 - val_acc: 0.6087 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 120: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 120/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6064 - acc: 0.6517 - val_loss: 0.6443 - val_acc: 0.5985 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 121: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 121/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6035 - acc: 0.6461 - val_loss: 0.6423 - val_acc: 0.5985 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 122: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 122/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6161 - acc: 0.6429 - val_loss: 0.6366 - val_acc: 0.6049 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 123: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 123/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6145 - acc: 0.6481 - val_loss: 0.6286 - val_acc: 0.6176 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 124: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 124/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6063 - acc: 0.6457 - val_loss: 0.6279 - val_acc: 0.6292 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 125: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 125/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6134 - acc: 0.6509 - val_loss: 0.6281 - val_acc: 0.6317 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 126: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 126/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6060 - acc: 0.6445 - val_loss: 0.6264 - val_acc: 0.6343 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 127: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 127/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6005 - acc: 0.6545 - val_loss: 0.6221 - val_acc: 0.6355 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 128: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 128/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6033 - acc: 0.6553 - val_loss: 0.6199 - val_acc: 0.6432 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 129: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 129/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6034 - acc: 0.6541 - val_loss: 0.6176 - val_acc: 0.6445 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 130: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 130/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6006 - acc: 0.6565 - val_loss: 0.6166 - val_acc: 0.6509 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 131: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 131/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6078 - acc: 0.6401 - val_loss: 0.6181 - val_acc: 0.6471 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 132: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 132/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6043 - acc: 0.6645 - val_loss: 0.6185 - val_acc: 0.6407 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 133: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 133/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6104 - acc: 0.6429 - val_loss: 0.6180 - val_acc: 0.6458 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 134: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 134/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6131 - acc: 0.6429 - val_loss: 0.6153 - val_acc: 0.6509 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 135: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 135/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6006 - acc: 0.6653 - val_loss: 0.6139 - val_acc: 0.6650 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 136: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 136/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.6057 - acc: 0.6573 - val_loss: 0.6159 - val_acc: 0.6471 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 137: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 137/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6020 - acc: 0.6693 - val_loss: 0.6153 - val_acc: 0.6586 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 138: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 138/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5901 - acc: 0.6657 - val_loss: 0.6172 - val_acc: 0.6471 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 139: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 139/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5946 - acc: 0.6585 - val_loss: 0.6270 - val_acc: 0.6317 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 140: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 140/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5990 - acc: 0.6641 - val_loss: 0.6494 - val_acc: 0.6215 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 141: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 141/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5938 - acc: 0.6633 - val_loss: 0.6581 - val_acc: 0.6215 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 142: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 142/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6013 - acc: 0.6533 - val_loss: 0.6532 - val_acc: 0.6215 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 143: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 143/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5928 - acc: 0.6765 - val_loss: 0.6557 - val_acc: 0.6304 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 144: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 144/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5924 - acc: 0.6677 - val_loss: 0.6680 - val_acc: 0.6343 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 145: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 145/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5921 - acc: 0.6693 - val_loss: 0.6839 - val_acc: 0.6138 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 146: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 146/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5907 - acc: 0.6769 - val_loss: 0.6686 - val_acc: 0.6176 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 147: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 147/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5883 - acc: 0.6809 - val_loss: 0.6719 - val_acc: 0.6304 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 148: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 148/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5834 - acc: 0.6769 - val_loss: 0.6752 - val_acc: 0.6266 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 149: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 149/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5878 - acc: 0.6857 - val_loss: 0.6481 - val_acc: 0.6483 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 150: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 150/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5871 - acc: 0.6809 - val_loss: 0.6875 - val_acc: 0.6176 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 151: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 151/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5834 - acc: 0.6917 - val_loss: 0.7146 - val_acc: 0.6253 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 152: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 152/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5864 - acc: 0.6857 - val_loss: 0.6564 - val_acc: 0.6292 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 153: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 153/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5817 - acc: 0.6869 - val_loss: 0.6246 - val_acc: 0.6598 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 154: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 154/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5753 - acc: 0.6945 - val_loss: 0.6410 - val_acc: 0.6471 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 155: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 155/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5729 - acc: 0.6965 - val_loss: 0.6694 - val_acc: 0.6215 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 156: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 156/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5713 - acc: 0.6969 - val_loss: 0.6702 - val_acc: 0.6151 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 157: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 157/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5786 - acc: 0.6929 - val_loss: 0.6946 - val_acc: 0.6100 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 158: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 158/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5690 - acc: 0.6889 - val_loss: 0.6850 - val_acc: 0.6113 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 159: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 159/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5697 - acc: 0.6969 - val_loss: 0.6898 - val_acc: 0.6202 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 160: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 160/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5748 - acc: 0.6949 - val_loss: 0.6743 - val_acc: 0.6279 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 161: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 161/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5655 - acc: 0.6913 - val_loss: 0.6110 - val_acc: 0.6368 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 162: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 162/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5688 - acc: 0.7017 - val_loss: 0.6045 - val_acc: 0.6432 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 163: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 163/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5626 - acc: 0.6925 - val_loss: 0.6057 - val_acc: 0.6471 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 164: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 164/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5740 - acc: 0.6941 - val_loss: 0.6116 - val_acc: 0.6343 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 165: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 165/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5721 - acc: 0.6961 - val_loss: 0.6096 - val_acc: 0.6317 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 166: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 166/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5670 - acc: 0.7037 - val_loss: 0.6173 - val_acc: 0.6215 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 167: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 167/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5700 - acc: 0.6977 - val_loss: 0.6381 - val_acc: 0.6074 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 168: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 168/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5560 - acc: 0.7061 - val_loss: 0.6759 - val_acc: 0.6164 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 169: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 169/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5591 - acc: 0.7089 - val_loss: 0.7072 - val_acc: 0.6151 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 170: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 170/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5643 - acc: 0.6997 - val_loss: 0.6719 - val_acc: 0.6189 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 171: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 171/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5518 - acc: 0.7013 - val_loss: 0.6485 - val_acc: 0.6253 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 172: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 172/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5508 - acc: 0.7069 - val_loss: 0.6482 - val_acc: 0.6253 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 173: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 173/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5478 - acc: 0.7157 - val_loss: 0.6412 - val_acc: 0.6343 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 174: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 174/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5472 - acc: 0.7121 - val_loss: 0.6227 - val_acc: 0.6368 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 175: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 175/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5522 - acc: 0.7121 - val_loss: 0.6266 - val_acc: 0.6560 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 176: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 176/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5527 - acc: 0.7025 - val_loss: 0.6254 - val_acc: 0.6509 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 177: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 177/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5496 - acc: 0.7121 - val_loss: 0.6284 - val_acc: 0.6496 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 178: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 178/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5496 - acc: 0.7145 - val_loss: 0.7108 - val_acc: 0.6432 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 179: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 179/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5457 - acc: 0.7225 - val_loss: 0.7513 - val_acc: 0.6368 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 180: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 180/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5440 - acc: 0.7117 - val_loss: 0.7637 - val_acc: 0.6381 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 181: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 181/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5350 - acc: 0.7165 - val_loss: 0.7517 - val_acc: 0.6522 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 182: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 182/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5448 - acc: 0.7149 - val_loss: 0.6733 - val_acc: 0.6535 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 183: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 183/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5334 - acc: 0.7217 - val_loss: 0.6484 - val_acc: 0.6586 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 184: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 184/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5426 - acc: 0.7149 - val_loss: 0.6131 - val_acc: 0.6650 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 185: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 185/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5358 - acc: 0.7189 - val_loss: 0.6003 - val_acc: 0.6688 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 186: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 186/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5371 - acc: 0.7137 - val_loss: 0.6367 - val_acc: 0.6688 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 187: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 187/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5342 - acc: 0.7165 - val_loss: 0.6329 - val_acc: 0.6777 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 188: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 188/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5327 - acc: 0.7281 - val_loss: 0.6329 - val_acc: 0.6726 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 189: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 189/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5397 - acc: 0.7101 - val_loss: 0.6285 - val_acc: 0.6726 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 190: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 190/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5373 - acc: 0.7189 - val_loss: 0.5899 - val_acc: 0.6509 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 191: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 191/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5311 - acc: 0.7269 - val_loss: 0.5962 - val_acc: 0.6598 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 192: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 192/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5309 - acc: 0.7241 - val_loss: 0.6642 - val_acc: 0.6637 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 193: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 193/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5426 - acc: 0.7197 - val_loss: 0.6475 - val_acc: 0.6675 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 194: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 194/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5243 - acc: 0.7269 - val_loss: 0.6015 - val_acc: 0.6701 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 195: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 195/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5248 - acc: 0.7193 - val_loss: 0.5982 - val_acc: 0.6957 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 196: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 196/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5241 - acc: 0.7181 - val_loss: 0.5947 - val_acc: 0.6957 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 197: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 197/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5260 - acc: 0.7229 - val_loss: 0.6180 - val_acc: 0.6880 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 198: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 198/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5279 - acc: 0.7201 - val_loss: 0.5684 - val_acc: 0.7084 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 199: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 199/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5320 - acc: 0.7213 - val_loss: 0.5610 - val_acc: 0.7008 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 200: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 200/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5203 - acc: 0.7277 - val_loss: 0.5572 - val_acc: 0.7110 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 201: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 201/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5200 - acc: 0.7289 - val_loss: 0.5578 - val_acc: 0.7033 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 202: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 202/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5205 - acc: 0.7269 - val_loss: 0.5559 - val_acc: 0.7059 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 203: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 203/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5164 - acc: 0.7425 - val_loss: 0.5545 - val_acc: 0.7008 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 204: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 204/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5176 - acc: 0.7357 - val_loss: 0.5531 - val_acc: 0.7033 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 205: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 205/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5095 - acc: 0.7277 - val_loss: 0.5507 - val_acc: 0.7033 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 206: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 206/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5208 - acc: 0.7237 - val_loss: 0.5492 - val_acc: 0.7059 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 207: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 207/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5203 - acc: 0.7301 - val_loss: 0.5484 - val_acc: 0.6982 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 208: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 208/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5252 - acc: 0.7241 - val_loss: 0.5484 - val_acc: 0.6982 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 209: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 209/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5101 - acc: 0.7297 - val_loss: 0.5477 - val_acc: 0.6995 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 210: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 210/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5145 - acc: 0.7289 - val_loss: 0.5456 - val_acc: 0.7008 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 211: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 211/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5211 - acc: 0.7341 - val_loss: 0.5438 - val_acc: 0.7008 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 212: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 212/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5276 - acc: 0.7241 - val_loss: 0.5417 - val_acc: 0.7059 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 213: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 213/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5184 - acc: 0.7309 - val_loss: 0.5408 - val_acc: 0.7097 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 214: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 214/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5181 - acc: 0.7361 - val_loss: 0.5396 - val_acc: 0.7199 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 215: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 215/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5038 - acc: 0.7453 - val_loss: 0.5392 - val_acc: 0.7148 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 216: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 216/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5096 - acc: 0.7361 - val_loss: 0.5395 - val_acc: 0.7097 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 217: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 217/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4989 - acc: 0.7373 - val_loss: 0.5394 - val_acc: 0.7110 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 218: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 218/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5190 - acc: 0.7269 - val_loss: 0.5386 - val_acc: 0.7110 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 219: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 219/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5153 - acc: 0.7365 - val_loss: 0.5375 - val_acc: 0.7148 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 220: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 220/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5103 - acc: 0.7333 - val_loss: 0.5363 - val_acc: 0.7174 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 221: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 221/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5050 - acc: 0.7361 - val_loss: 0.5352 - val_acc: 0.7199 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 222: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 222/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5154 - acc: 0.7325 - val_loss: 0.5340 - val_acc: 0.7199 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 223: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 223/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5061 - acc: 0.7349 - val_loss: 0.5330 - val_acc: 0.7225 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 224: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 224/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5056 - acc: 0.7413 - val_loss: 0.5326 - val_acc: 0.7225 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 225: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 225/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5241 - acc: 0.7221 - val_loss: 0.5325 - val_acc: 0.7225 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 226: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 226/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5190 - acc: 0.7285 - val_loss: 0.5327 - val_acc: 0.7199 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 227: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 227/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5099 - acc: 0.7301 - val_loss: 0.5331 - val_acc: 0.7187 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 228: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 228/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5177 - acc: 0.7349 - val_loss: 0.5340 - val_acc: 0.7199 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 229: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 229/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5097 - acc: 0.7297 - val_loss: 0.5356 - val_acc: 0.7148 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 230: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 230/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5201 - acc: 0.7285 - val_loss: 0.5376 - val_acc: 0.7084 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 231: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 231/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5095 - acc: 0.7341 - val_loss: 0.5384 - val_acc: 0.7046 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 232: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 232/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5144 - acc: 0.7361 - val_loss: 0.5395 - val_acc: 0.7033 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 233: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 233/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5106 - acc: 0.7321 - val_loss: 0.5400 - val_acc: 0.7008 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 234: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 234/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5008 - acc: 0.7321 - val_loss: 0.5396 - val_acc: 0.7020 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 235: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 235/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5136 - acc: 0.7325 - val_loss: 0.5410 - val_acc: 0.6957 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 236: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 236/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5085 - acc: 0.7321 - val_loss: 0.5430 - val_acc: 0.6931 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 237: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 237/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5109 - acc: 0.7289 - val_loss: 0.5447 - val_acc: 0.6957 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 238: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 238/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5124 - acc: 0.7233 - val_loss: 0.5457 - val_acc: 0.6918 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 239: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 239/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5129 - acc: 0.7321 - val_loss: 0.5443 - val_acc: 0.6931 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 240: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 240/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5065 - acc: 0.7361 - val_loss: 0.5449 - val_acc: 0.6944 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 241: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 241/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5089 - acc: 0.7269 - val_loss: 0.5448 - val_acc: 0.6982 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 242: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 242/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5085 - acc: 0.7353 - val_loss: 0.5449 - val_acc: 0.6969 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 243: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 243/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5140 - acc: 0.7333 - val_loss: 0.5453 - val_acc: 0.6931 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 244: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 244/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5061 - acc: 0.7313 - val_loss: 0.5476 - val_acc: 0.6867 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 245: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 245/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5105 - acc: 0.7425 - val_loss: 0.5482 - val_acc: 0.6867 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 246: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 246/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5070 - acc: 0.7381 - val_loss: 0.5475 - val_acc: 0.6918 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 247: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 247/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5187 - acc: 0.7293 - val_loss: 0.5463 - val_acc: 0.6918 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 248: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 248/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5077 - acc: 0.7349 - val_loss: 0.5450 - val_acc: 0.6957 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 249: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 249/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5206 - acc: 0.7313 - val_loss: 0.5417 - val_acc: 0.6944 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 250: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 250/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5111 - acc: 0.7337 - val_loss: 0.5393 - val_acc: 0.6969 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 251: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 251/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5096 - acc: 0.7325 - val_loss: 0.5374 - val_acc: 0.6957 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 252: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 252/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5081 - acc: 0.7281 - val_loss: 0.5372 - val_acc: 0.6957 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 253: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 253/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4994 - acc: 0.7445 - val_loss: 0.5385 - val_acc: 0.6957 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 254: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 254/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5034 - acc: 0.7349 - val_loss: 0.5405 - val_acc: 0.6982 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 255: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 255/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5063 - acc: 0.7341 - val_loss: 0.5383 - val_acc: 0.6982 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 256: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 256/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5050 - acc: 0.7469 - val_loss: 0.5373 - val_acc: 0.6982 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 257: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 257/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5141 - acc: 0.7313 - val_loss: 0.5369 - val_acc: 0.6982 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 258: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 258/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5133 - acc: 0.7337 - val_loss: 0.5374 - val_acc: 0.6982 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 259: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 259/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5163 - acc: 0.7337 - val_loss: 0.5380 - val_acc: 0.6995 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 260: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 260/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5073 - acc: 0.7321 - val_loss: 0.5388 - val_acc: 0.6982 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 261: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 261/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5161 - acc: 0.7285 - val_loss: 0.5401 - val_acc: 0.6969 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 262: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 262/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5046 - acc: 0.7349 - val_loss: 0.5407 - val_acc: 0.6969 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 263: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 263/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5162 - acc: 0.7369 - val_loss: 0.5396 - val_acc: 0.6982 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 264: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 264/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5113 - acc: 0.7361 - val_loss: 0.5367 - val_acc: 0.6995 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 265: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 265/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5090 - acc: 0.7365 - val_loss: 0.5376 - val_acc: 0.7008 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 266: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 266/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5131 - acc: 0.7381 - val_loss: 0.5364 - val_acc: 0.6995 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 267: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 267/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5058 - acc: 0.7365 - val_loss: 0.5354 - val_acc: 0.6995 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 268: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 268/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5049 - acc: 0.7253 - val_loss: 0.5349 - val_acc: 0.7008 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 269: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 269/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5094 - acc: 0.7305 - val_loss: 0.5335 - val_acc: 0.7008 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 270: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 270/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5203 - acc: 0.7317 - val_loss: 0.5347 - val_acc: 0.7008 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 271: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 271/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5027 - acc: 0.7349 - val_loss: 0.5351 - val_acc: 0.7008 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 272: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 272/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4983 - acc: 0.7429 - val_loss: 0.5354 - val_acc: 0.7008 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 273: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 273/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5142 - acc: 0.7321 - val_loss: 0.5374 - val_acc: 0.7033 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 274: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 274/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5055 - acc: 0.7413 - val_loss: 0.5359 - val_acc: 0.7033 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 275: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 275/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5040 - acc: 0.7357 - val_loss: 0.5338 - val_acc: 0.7033 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 276: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 276/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5139 - acc: 0.7437 - val_loss: 0.5326 - val_acc: 0.7059 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 277: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 277/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5073 - acc: 0.7345 - val_loss: 0.5318 - val_acc: 0.7084 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 278: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 278/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5103 - acc: 0.7305 - val_loss: 0.5333 - val_acc: 0.7033 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 279: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 279/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5156 - acc: 0.7305 - val_loss: 0.5336 - val_acc: 0.7033 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 280: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 280/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5158 - acc: 0.7401 - val_loss: 0.5343 - val_acc: 0.7033 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 281: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 281/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5032 - acc: 0.7313 - val_loss: 0.5329 - val_acc: 0.7046 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 282: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 282/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5114 - acc: 0.7357 - val_loss: 0.5304 - val_acc: 0.7084 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 283: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 283/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5097 - acc: 0.7265 - val_loss: 0.5303 - val_acc: 0.7072 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 284: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 284/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5090 - acc: 0.7353 - val_loss: 0.5304 - val_acc: 0.7072 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 285: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 285/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5101 - acc: 0.7325 - val_loss: 0.5303 - val_acc: 0.7072 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 286: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 286/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5136 - acc: 0.7321 - val_loss: 0.5294 - val_acc: 0.7059 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 287: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 287/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5126 - acc: 0.7389 - val_loss: 0.5302 - val_acc: 0.7084 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 288: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 288/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5029 - acc: 0.7329 - val_loss: 0.5316 - val_acc: 0.7072 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 289: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 289/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4957 - acc: 0.7397 - val_loss: 0.5321 - val_acc: 0.7059 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 290: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 290/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5012 - acc: 0.7421 - val_loss: 0.5312 - val_acc: 0.7059 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 291: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 291/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5084 - acc: 0.7305 - val_loss: 0.5319 - val_acc: 0.7072 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 292: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 292/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5000 - acc: 0.7473 - val_loss: 0.5322 - val_acc: 0.7072 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 293: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 293/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5141 - acc: 0.7237 - val_loss: 0.5330 - val_acc: 0.7072 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 294: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 294/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5089 - acc: 0.7357 - val_loss: 0.5333 - val_acc: 0.7072 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 295: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 295/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5093 - acc: 0.7325 - val_loss: 0.5331 - val_acc: 0.7059 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 296: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 296/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5112 - acc: 0.7353 - val_loss: 0.5338 - val_acc: 0.7033 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 297: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 297/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4955 - acc: 0.7381 - val_loss: 0.5342 - val_acc: 0.7059 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 298: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 298/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4969 - acc: 0.7433 - val_loss: 0.5340 - val_acc: 0.7072 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 299: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 299/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5090 - acc: 0.7301 - val_loss: 0.5330 - val_acc: 0.7072 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 300: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 300/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5021 - acc: 0.7421 - val_loss: 0.5325 - val_acc: 0.7084 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 301: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 301/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5017 - acc: 0.7389 - val_loss: 0.5325 - val_acc: 0.7084 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 302: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 302/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5054 - acc: 0.7377 - val_loss: 0.5314 - val_acc: 0.7084 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 303: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 303/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5044 - acc: 0.7381 - val_loss: 0.5323 - val_acc: 0.7084 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 304: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 304/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4987 - acc: 0.7357 - val_loss: 0.5316 - val_acc: 0.7084 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 305: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 305/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5114 - acc: 0.7269 - val_loss: 0.5320 - val_acc: 0.7072 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 306: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 306/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4998 - acc: 0.7437 - val_loss: 0.5319 - val_acc: 0.7084 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 307: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 307/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4993 - acc: 0.7345 - val_loss: 0.5321 - val_acc: 0.7072 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 308: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 308/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5044 - acc: 0.7369 - val_loss: 0.5301 - val_acc: 0.7072 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 309: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 309/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5061 - acc: 0.7313 - val_loss: 0.5296 - val_acc: 0.7084 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 310: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 310/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5052 - acc: 0.7365 - val_loss: 0.5304 - val_acc: 0.7072 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 311: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 311/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4972 - acc: 0.7409 - val_loss: 0.5322 - val_acc: 0.7059 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 312: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 312/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5008 - acc: 0.7325 - val_loss: 0.5353 - val_acc: 0.7008 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 313: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 313/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5022 - acc: 0.7389 - val_loss: 0.5375 - val_acc: 0.6982 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 314: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 314/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5058 - acc: 0.7333 - val_loss: 0.5373 - val_acc: 0.6982 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 315: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 315/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5036 - acc: 0.7369 - val_loss: 0.5367 - val_acc: 0.6995 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 316: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 316/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5018 - acc: 0.7393 - val_loss: 0.5346 - val_acc: 0.7008 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 317: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 317/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5012 - acc: 0.7381 - val_loss: 0.5330 - val_acc: 0.7046 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 318: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 318/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5014 - acc: 0.7457 - val_loss: 0.5319 - val_acc: 0.7072 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 319: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 319/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5000 - acc: 0.7365 - val_loss: 0.5314 - val_acc: 0.7072 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 320: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 320/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5083 - acc: 0.7325 - val_loss: 0.5310 - val_acc: 0.7072 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 321: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 321/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5093 - acc: 0.7289 - val_loss: 0.5323 - val_acc: 0.7008 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 322: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 322/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4941 - acc: 0.7413 - val_loss: 0.5339 - val_acc: 0.7008 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 323: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 323/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5099 - acc: 0.7353 - val_loss: 0.5344 - val_acc: 0.6982 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 324: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 324/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4981 - acc: 0.7349 - val_loss: 0.5345 - val_acc: 0.6995 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 325: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 325/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5126 - acc: 0.7349 - val_loss: 0.5349 - val_acc: 0.6995 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 326: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 326/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4948 - acc: 0.7425 - val_loss: 0.5340 - val_acc: 0.6995 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 327: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 327/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5025 - acc: 0.7405 - val_loss: 0.5349 - val_acc: 0.6995 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 328: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 328/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5020 - acc: 0.7445 - val_loss: 0.5337 - val_acc: 0.6995 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 329: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 329/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4973 - acc: 0.7409 - val_loss: 0.5334 - val_acc: 0.6995 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 330: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 330/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4998 - acc: 0.7449 - val_loss: 0.5344 - val_acc: 0.6995 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 331: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 331/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4999 - acc: 0.7381 - val_loss: 0.5346 - val_acc: 0.7008 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 332: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 332/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5009 - acc: 0.7309 - val_loss: 0.5353 - val_acc: 0.7008 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 333: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 333/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5074 - acc: 0.7449 - val_loss: 0.5335 - val_acc: 0.6995 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 334: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 334/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5112 - acc: 0.7317 - val_loss: 0.5328 - val_acc: 0.6982 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 335: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 335/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4988 - acc: 0.7453 - val_loss: 0.5312 - val_acc: 0.6995 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 336: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 336/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4959 - acc: 0.7401 - val_loss: 0.5312 - val_acc: 0.6995 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 337: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 337/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4976 - acc: 0.7457 - val_loss: 0.5311 - val_acc: 0.6995 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 338: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 338/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5019 - acc: 0.7337 - val_loss: 0.5330 - val_acc: 0.6995 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 339: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 339/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4969 - acc: 0.7361 - val_loss: 0.5336 - val_acc: 0.6982 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 340: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 340/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5038 - acc: 0.7397 - val_loss: 0.5318 - val_acc: 0.6982 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 341: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 341/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4941 - acc: 0.7517 - val_loss: 0.5316 - val_acc: 0.7008 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 342: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 342/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5118 - acc: 0.7385 - val_loss: 0.5310 - val_acc: 0.7020 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 343: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 343/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4943 - acc: 0.7413 - val_loss: 0.5295 - val_acc: 0.7046 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 344: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 344/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4992 - acc: 0.7357 - val_loss: 0.5289 - val_acc: 0.7072 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 345: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 345/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4952 - acc: 0.7465 - val_loss: 0.5290 - val_acc: 0.7072 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 346: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 346/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5076 - acc: 0.7405 - val_loss: 0.5287 - val_acc: 0.7084 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 347: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 347/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5001 - acc: 0.7413 - val_loss: 0.5306 - val_acc: 0.7033 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 348: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 348/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5088 - acc: 0.7345 - val_loss: 0.5338 - val_acc: 0.6982 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 349: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 349/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5011 - acc: 0.7437 - val_loss: 0.5378 - val_acc: 0.6918 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 350: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 350/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4894 - acc: 0.7461 - val_loss: 0.5398 - val_acc: 0.6918 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 351: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 351/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4940 - acc: 0.7397 - val_loss: 0.5374 - val_acc: 0.6931 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 352: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 352/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4987 - acc: 0.7421 - val_loss: 0.5358 - val_acc: 0.6982 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 353: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 353/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5036 - acc: 0.7385 - val_loss: 0.5338 - val_acc: 0.6982 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 354: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 354/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5098 - acc: 0.7361 - val_loss: 0.5313 - val_acc: 0.7033 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 355: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 355/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5008 - acc: 0.7365 - val_loss: 0.5307 - val_acc: 0.7033 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 356: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 356/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4967 - acc: 0.7401 - val_loss: 0.5298 - val_acc: 0.7072 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 357: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 357/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4921 - acc: 0.7477 - val_loss: 0.5299 - val_acc: 0.7059 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 358: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 358/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4972 - acc: 0.7421 - val_loss: 0.5292 - val_acc: 0.7072 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 359: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 359/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5032 - acc: 0.7453 - val_loss: 0.5302 - val_acc: 0.7072 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 360: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 360/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5014 - acc: 0.7353 - val_loss: 0.5296 - val_acc: 0.7046 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 361: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 361/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5078 - acc: 0.7393 - val_loss: 0.5308 - val_acc: 0.6995 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 362: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 362/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4999 - acc: 0.7385 - val_loss: 0.5310 - val_acc: 0.6995 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 363: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 363/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4945 - acc: 0.7397 - val_loss: 0.5311 - val_acc: 0.6995 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 364: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 364/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4950 - acc: 0.7445 - val_loss: 0.5317 - val_acc: 0.6995 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 365: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 365/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4999 - acc: 0.7377 - val_loss: 0.5315 - val_acc: 0.6995 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 366: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 366/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5006 - acc: 0.7481 - val_loss: 0.5322 - val_acc: 0.6995 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 367: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 367/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5002 - acc: 0.7465 - val_loss: 0.5355 - val_acc: 0.7008 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 368: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 368/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4815 - acc: 0.7445 - val_loss: 0.5354 - val_acc: 0.7008 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 369: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 369/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5042 - acc: 0.7393 - val_loss: 0.5368 - val_acc: 0.6995 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 370: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 370/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4939 - acc: 0.7357 - val_loss: 0.5367 - val_acc: 0.6995 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 371: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 371/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4939 - acc: 0.7417 - val_loss: 0.5353 - val_acc: 0.6995 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 372: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 372/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4942 - acc: 0.7385 - val_loss: 0.5366 - val_acc: 0.6982 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 373: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 373/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5006 - acc: 0.7397 - val_loss: 0.5398 - val_acc: 0.6957 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 374: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 374/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5087 - acc: 0.7345 - val_loss: 0.5380 - val_acc: 0.6982 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 375: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 375/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4965 - acc: 0.7405 - val_loss: 0.5402 - val_acc: 0.6957 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 376: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 376/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4927 - acc: 0.7373 - val_loss: 0.5391 - val_acc: 0.6982 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 377: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 377/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4959 - acc: 0.7389 - val_loss: 0.5355 - val_acc: 0.6982 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 378: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 378/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5084 - acc: 0.7469 - val_loss: 0.5313 - val_acc: 0.7046 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 379: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 379/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5043 - acc: 0.7361 - val_loss: 0.5297 - val_acc: 0.7059 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 380: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 380/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5015 - acc: 0.7417 - val_loss: 0.5294 - val_acc: 0.7059 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 381: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 381/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4922 - acc: 0.7421 - val_loss: 0.5290 - val_acc: 0.7084 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 382: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 382/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4952 - acc: 0.7421 - val_loss: 0.5290 - val_acc: 0.7084 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 383: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 383/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4934 - acc: 0.7457 - val_loss: 0.5284 - val_acc: 0.7072 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 384: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 384/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4911 - acc: 0.7397 - val_loss: 0.5266 - val_acc: 0.7059 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 385: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 385/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4927 - acc: 0.7389 - val_loss: 0.5259 - val_acc: 0.7110 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 386: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 386/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5032 - acc: 0.7401 - val_loss: 0.5269 - val_acc: 0.7123 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 387: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 387/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4987 - acc: 0.7413 - val_loss: 0.5266 - val_acc: 0.7123 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 388: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 388/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4949 - acc: 0.7369 - val_loss: 0.5260 - val_acc: 0.7136 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 389: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 389/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5023 - acc: 0.7401 - val_loss: 0.5272 - val_acc: 0.7110 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 390: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 390/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5010 - acc: 0.7405 - val_loss: 0.5280 - val_acc: 0.7110 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 391: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 391/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4984 - acc: 0.7493 - val_loss: 0.5289 - val_acc: 0.7110 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 392: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 392/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4977 - acc: 0.7409 - val_loss: 0.5302 - val_acc: 0.7110 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 393: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 393/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5060 - acc: 0.7325 - val_loss: 0.5307 - val_acc: 0.7084 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 394: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 394/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5052 - acc: 0.7433 - val_loss: 0.5293 - val_acc: 0.7110 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 395: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 395/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.4987 - acc: 0.7381 - val_loss: 0.5312 - val_acc: 0.7072 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 396: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 396/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4989 - acc: 0.7441 - val_loss: 0.5309 - val_acc: 0.7084 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 397: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 397/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4901 - acc: 0.7429 - val_loss: 0.5294 - val_acc: 0.7084 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 398: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 398/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4943 - acc: 0.7449 - val_loss: 0.5286 - val_acc: 0.7072 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 399: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 399/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4927 - acc: 0.7517 - val_loss: 0.5292 - val_acc: 0.7084 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 400: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 400/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5010 - acc: 0.7361 - val_loss: 0.5282 - val_acc: 0.7072 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 401: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 401/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4990 - acc: 0.7393 - val_loss: 0.5294 - val_acc: 0.7072 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 402: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 402/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4923 - acc: 0.7453 - val_loss: 0.5317 - val_acc: 0.7033 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 403: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 403/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4957 - acc: 0.7357 - val_loss: 0.5317 - val_acc: 0.7020 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 404: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 404/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4984 - acc: 0.7405 - val_loss: 0.5320 - val_acc: 0.7008 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 405: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 405/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4936 - acc: 0.7405 - val_loss: 0.5304 - val_acc: 0.7033 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 406: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 406/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4912 - acc: 0.7413 - val_loss: 0.5285 - val_acc: 0.7046 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 407: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 407/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4876 - acc: 0.7549 - val_loss: 0.5281 - val_acc: 0.7046 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 408: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 408/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5019 - acc: 0.7473 - val_loss: 0.5275 - val_acc: 0.7084 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 409: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 409/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4958 - acc: 0.7393 - val_loss: 0.5283 - val_acc: 0.7110 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 410: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 410/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4950 - acc: 0.7441 - val_loss: 0.5261 - val_acc: 0.7148 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 411: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 411/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4885 - acc: 0.7437 - val_loss: 0.5213 - val_acc: 0.7148 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 412: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 412/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4981 - acc: 0.7281 - val_loss: 0.5185 - val_acc: 0.7174 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 413: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 413/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4970 - acc: 0.7409 - val_loss: 0.5162 - val_acc: 0.7225 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 414: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 414/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5000 - acc: 0.7397 - val_loss: 0.5152 - val_acc: 0.7225 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 415: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 415/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4958 - acc: 0.7305 - val_loss: 0.5142 - val_acc: 0.7238 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 416: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 416/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4948 - acc: 0.7449 - val_loss: 0.5142 - val_acc: 0.7212 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 417: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 417/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4888 - acc: 0.7445 - val_loss: 0.5141 - val_acc: 0.7225 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 418: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 418/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5002 - acc: 0.7497 - val_loss: 0.5155 - val_acc: 0.7212 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 419: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 419/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4811 - acc: 0.7513 - val_loss: 0.5177 - val_acc: 0.7148 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 420: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 420/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4942 - acc: 0.7393 - val_loss: 0.5212 - val_acc: 0.7187 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 421: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 421/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4964 - acc: 0.7405 - val_loss: 0.5268 - val_acc: 0.7136 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 422: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 422/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.4872 - acc: 0.7385 - val_loss: 0.5307 - val_acc: 0.7084 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 423: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 423/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4966 - acc: 0.7385 - val_loss: 0.5283 - val_acc: 0.7123 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 424: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 424/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4964 - acc: 0.7417 - val_loss: 0.5308 - val_acc: 0.7084 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 425: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 425/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4903 - acc: 0.7477 - val_loss: 0.5319 - val_acc: 0.7072 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 426: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 426/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4895 - acc: 0.7513 - val_loss: 0.5312 - val_acc: 0.7072 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 427: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 427/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4885 - acc: 0.7377 - val_loss: 0.5306 - val_acc: 0.7072 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 428: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 428/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4956 - acc: 0.7401 - val_loss: 0.5286 - val_acc: 0.7084 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 429: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 429/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4927 - acc: 0.7393 - val_loss: 0.5228 - val_acc: 0.7136 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 430: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 430/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5002 - acc: 0.7409 - val_loss: 0.5192 - val_acc: 0.7187 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 431: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 431/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4873 - acc: 0.7489 - val_loss: 0.5198 - val_acc: 0.7174 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 432: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 432/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4869 - acc: 0.7453 - val_loss: 0.5230 - val_acc: 0.7174 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 433: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 433/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.4873 - acc: 0.7425 - val_loss: 0.5277 - val_acc: 0.7097 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 434: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 434/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4933 - acc: 0.7481 - val_loss: 0.5280 - val_acc: 0.7084 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 435: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 435/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.4953 - acc: 0.7485 - val_loss: 0.5275 - val_acc: 0.7110 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 436: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 436/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4998 - acc: 0.7397 - val_loss: 0.5265 - val_acc: 0.7123 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 437: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 437/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4828 - acc: 0.7453 - val_loss: 0.5241 - val_acc: 0.7148 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 438: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 438/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4941 - acc: 0.7473 - val_loss: 0.5231 - val_acc: 0.7136 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 439: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 439/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.4788 - acc: 0.7409 - val_loss: 0.5237 - val_acc: 0.7161 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 440: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 440/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4888 - acc: 0.7453 - val_loss: 0.5239 - val_acc: 0.7161 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 441: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 441/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4886 - acc: 0.7561 - val_loss: 0.5270 - val_acc: 0.7136 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 442: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 442/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4811 - acc: 0.7489 - val_loss: 0.5275 - val_acc: 0.7148 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 443: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 443/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5010 - acc: 0.7325 - val_loss: 0.5336 - val_acc: 0.7046 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 444: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 444/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4966 - acc: 0.7337 - val_loss: 0.5367 - val_acc: 0.6982 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 445: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 445/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4949 - acc: 0.7477 - val_loss: 0.5405 - val_acc: 0.7008 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 446: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 446/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4949 - acc: 0.7469 - val_loss: 0.5415 - val_acc: 0.7008 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 447: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 447/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.4965 - acc: 0.7393 - val_loss: 0.5434 - val_acc: 0.6918 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 448: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 448/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4962 - acc: 0.7373 - val_loss: 0.5382 - val_acc: 0.6995 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 449: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 449/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4802 - acc: 0.7489 - val_loss: 0.5366 - val_acc: 0.7072 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 450: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 450/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4958 - acc: 0.7457 - val_loss: 0.5339 - val_acc: 0.7084 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 451: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 451/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4950 - acc: 0.7413 - val_loss: 0.5316 - val_acc: 0.7097 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 452: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 452/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4922 - acc: 0.7497 - val_loss: 0.5318 - val_acc: 0.7084 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 453: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 453/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4881 - acc: 0.7473 - val_loss: 0.5292 - val_acc: 0.7097 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 454: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 454/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4799 - acc: 0.7457 - val_loss: 0.5256 - val_acc: 0.7161 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 455: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 455/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4963 - acc: 0.7409 - val_loss: 0.5213 - val_acc: 0.7161 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 456: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 456/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4829 - acc: 0.7489 - val_loss: 0.5200 - val_acc: 0.7187 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 457: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 457/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4828 - acc: 0.7421 - val_loss: 0.5216 - val_acc: 0.7148 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 458: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 458/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4887 - acc: 0.7477 - val_loss: 0.5239 - val_acc: 0.7148 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 459: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 459/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4898 - acc: 0.7469 - val_loss: 0.5250 - val_acc: 0.7136 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 460: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 460/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4930 - acc: 0.7417 - val_loss: 0.5223 - val_acc: 0.7148 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 461: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 461/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4833 - acc: 0.7513 - val_loss: 0.5203 - val_acc: 0.7187 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 462: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 462/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4887 - acc: 0.7517 - val_loss: 0.5236 - val_acc: 0.7136 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 463: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 463/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4853 - acc: 0.7437 - val_loss: 0.5218 - val_acc: 0.7161 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 464: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 464/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4890 - acc: 0.7453 - val_loss: 0.5247 - val_acc: 0.7136 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 465: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 465/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4743 - acc: 0.7533 - val_loss: 0.5266 - val_acc: 0.7136 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 466: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 466/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.4911 - acc: 0.7537 - val_loss: 0.5293 - val_acc: 0.7110 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 467: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 467/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4848 - acc: 0.7473 - val_loss: 0.5315 - val_acc: 0.7072 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 468: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 468/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4873 - acc: 0.7465 - val_loss: 0.5318 - val_acc: 0.7059 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 469: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 469/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.4920 - acc: 0.7505 - val_loss: 0.5355 - val_acc: 0.7020 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 470: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 470/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4883 - acc: 0.7385 - val_loss: 0.5329 - val_acc: 0.7008 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 471: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 471/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4898 - acc: 0.7457 - val_loss: 0.5329 - val_acc: 0.6995 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 472: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 472/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4862 - acc: 0.7513 - val_loss: 0.5325 - val_acc: 0.6982 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 473: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 473/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.4811 - acc: 0.7477 - val_loss: 0.5309 - val_acc: 0.7046 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 474: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 474/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4901 - acc: 0.7417 - val_loss: 0.5285 - val_acc: 0.7110 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 475: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 475/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4744 - acc: 0.7517 - val_loss: 0.5277 - val_acc: 0.7123 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 476: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 476/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4763 - acc: 0.7513 - val_loss: 0.5279 - val_acc: 0.7123 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 477: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 477/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4865 - acc: 0.7465 - val_loss: 0.5260 - val_acc: 0.7136 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 478: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 478/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.4908 - acc: 0.7369 - val_loss: 0.5232 - val_acc: 0.7161 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 479: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 479/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4842 - acc: 0.7581 - val_loss: 0.5211 - val_acc: 0.7148 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 480: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 480/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4859 - acc: 0.7481 - val_loss: 0.5183 - val_acc: 0.7148 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 481: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 481/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4832 - acc: 0.7485 - val_loss: 0.5170 - val_acc: 0.7161 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 482: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 482/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.4820 - acc: 0.7425 - val_loss: 0.5189 - val_acc: 0.7161 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 483: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 483/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4786 - acc: 0.7545 - val_loss: 0.5226 - val_acc: 0.7123 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 484: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 484/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4890 - acc: 0.7433 - val_loss: 0.5225 - val_acc: 0.7123 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 485: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 485/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4845 - acc: 0.7473 - val_loss: 0.5226 - val_acc: 0.7123 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 486: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 486/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.4861 - acc: 0.7541 - val_loss: 0.5248 - val_acc: 0.7097 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 487: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 487/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4847 - acc: 0.7493 - val_loss: 0.5256 - val_acc: 0.7097 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 488: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 488/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.4860 - acc: 0.7453 - val_loss: 0.5249 - val_acc: 0.7097 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 489: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 489/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4871 - acc: 0.7457 - val_loss: 0.5233 - val_acc: 0.7148 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 490: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 490/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4786 - acc: 0.7509 - val_loss: 0.5247 - val_acc: 0.7110 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 491: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 491/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4942 - acc: 0.7489 - val_loss: 0.5228 - val_acc: 0.7123 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 492: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 492/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4856 - acc: 0.7437 - val_loss: 0.5210 - val_acc: 0.7110 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 493: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 493/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.4796 - acc: 0.7545 - val_loss: 0.5168 - val_acc: 0.7148 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 494: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 494/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4788 - acc: 0.7461 - val_loss: 0.5167 - val_acc: 0.7136 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 495: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 495/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4855 - acc: 0.7489 - val_loss: 0.5193 - val_acc: 0.7136 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 496: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 496/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4776 - acc: 0.7501 - val_loss: 0.5241 - val_acc: 0.7136 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 497: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 497/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4823 - acc: 0.7425 - val_loss: 0.5251 - val_acc: 0.7123 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 498: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 498/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4712 - acc: 0.7525 - val_loss: 0.5271 - val_acc: 0.7097 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 499: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 499/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4883 - acc: 0.7453 - val_loss: 0.5276 - val_acc: 0.7084 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 500: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 500/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4819 - acc: 0.7489 - val_loss: 0.5292 - val_acc: 0.7072 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 501: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 501/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4807 - acc: 0.7585 - val_loss: 0.5249 - val_acc: 0.7110 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 502: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 502/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4903 - acc: 0.7493 - val_loss: 0.5208 - val_acc: 0.7123 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 503: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 503/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4821 - acc: 0.7557 - val_loss: 0.5155 - val_acc: 0.7212 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 504: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 504/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.4842 - acc: 0.7441 - val_loss: 0.5149 - val_acc: 0.7174 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 505: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 505/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4766 - acc: 0.7545 - val_loss: 0.5170 - val_acc: 0.7161 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 506: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 506/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4860 - acc: 0.7481 - val_loss: 0.5226 - val_acc: 0.7148 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 507: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 507/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4922 - acc: 0.7493 - val_loss: 0.5236 - val_acc: 0.7123 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 508: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 508/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4777 - acc: 0.7513 - val_loss: 0.5253 - val_acc: 0.7084 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 509: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 509/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4917 - acc: 0.7469 - val_loss: 0.5237 - val_acc: 0.7110 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 510: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 510/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4799 - acc: 0.7565 - val_loss: 0.5232 - val_acc: 0.7097 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 511: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 511/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.4907 - acc: 0.7433 - val_loss: 0.5235 - val_acc: 0.7097 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 512: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 512/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4868 - acc: 0.7521 - val_loss: 0.5209 - val_acc: 0.7110 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 513: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 513/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4772 - acc: 0.7457 - val_loss: 0.5197 - val_acc: 0.7110 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 514: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 514/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4834 - acc: 0.7461 - val_loss: 0.5191 - val_acc: 0.7110 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 515: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 515/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4713 - acc: 0.7569 - val_loss: 0.5184 - val_acc: 0.7110 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 516: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 516/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4840 - acc: 0.7517 - val_loss: 0.5212 - val_acc: 0.7110 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 517: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 517/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4802 - acc: 0.7565 - val_loss: 0.5227 - val_acc: 0.7110 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 518: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 518/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4757 - acc: 0.7525 - val_loss: 0.5221 - val_acc: 0.7110 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 519: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 519/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4818 - acc: 0.7437 - val_loss: 0.5201 - val_acc: 0.7136 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 520: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 520/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4862 - acc: 0.7453 - val_loss: 0.5201 - val_acc: 0.7136 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 521: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 521/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4861 - acc: 0.7457 - val_loss: 0.5198 - val_acc: 0.7136 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 522: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 522/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.4855 - acc: 0.7425 - val_loss: 0.5220 - val_acc: 0.7110 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 523: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 523/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4796 - acc: 0.7473 - val_loss: 0.5207 - val_acc: 0.7123 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 524: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 524/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4745 - acc: 0.7569 - val_loss: 0.5233 - val_acc: 0.7084 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 525: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 525/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4870 - acc: 0.7441 - val_loss: 0.5234 - val_acc: 0.7084 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 526: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 526/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4758 - acc: 0.7497 - val_loss: 0.5204 - val_acc: 0.7148 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 527: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 527/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4930 - acc: 0.7445 - val_loss: 0.5219 - val_acc: 0.7084 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 528: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 528/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4864 - acc: 0.7513 - val_loss: 0.5235 - val_acc: 0.7084 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 529: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 529/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4771 - acc: 0.7557 - val_loss: 0.5209 - val_acc: 0.7110 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 530: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 530/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4808 - acc: 0.7445 - val_loss: 0.5188 - val_acc: 0.7148 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 531: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 531/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4712 - acc: 0.7533 - val_loss: 0.5193 - val_acc: 0.7148 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 532: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 532/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4798 - acc: 0.7501 - val_loss: 0.5217 - val_acc: 0.7136 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 533: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 533/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4734 - acc: 0.7621 - val_loss: 0.5246 - val_acc: 0.7123 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 534: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 534/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4794 - acc: 0.7513 - val_loss: 0.5287 - val_acc: 0.7072 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 535: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 535/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4788 - acc: 0.7477 - val_loss: 0.5342 - val_acc: 0.7008 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 536: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 536/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4745 - acc: 0.7497 - val_loss: 0.5374 - val_acc: 0.7020 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 537: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 537/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4820 - acc: 0.7493 - val_loss: 0.5371 - val_acc: 0.7008 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 538: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 538/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4772 - acc: 0.7549 - val_loss: 0.5327 - val_acc: 0.6982 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 539: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 539/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4808 - acc: 0.7509 - val_loss: 0.5313 - val_acc: 0.6995 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 540: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 540/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4831 - acc: 0.7493 - val_loss: 0.5294 - val_acc: 0.7059 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 541: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 541/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4716 - acc: 0.7617 - val_loss: 0.5273 - val_acc: 0.7084 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 542: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 542/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4761 - acc: 0.7437 - val_loss: 0.5267 - val_acc: 0.7123 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 543: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 543/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4724 - acc: 0.7601 - val_loss: 0.5252 - val_acc: 0.7123 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 544: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 544/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4804 - acc: 0.7509 - val_loss: 0.5278 - val_acc: 0.7059 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 545: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 545/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4726 - acc: 0.7529 - val_loss: 0.5273 - val_acc: 0.7059 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 546: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 546/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4764 - acc: 0.7485 - val_loss: 0.5234 - val_acc: 0.7123 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 547: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 547/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4783 - acc: 0.7489 - val_loss: 0.5200 - val_acc: 0.7097 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 548: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 548/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4675 - acc: 0.7677 - val_loss: 0.5159 - val_acc: 0.7123 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 549: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 549/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4716 - acc: 0.7549 - val_loss: 0.5126 - val_acc: 0.7123 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 550: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 550/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4800 - acc: 0.7405 - val_loss: 0.5123 - val_acc: 0.7148 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 551: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 551/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4718 - acc: 0.7477 - val_loss: 0.5144 - val_acc: 0.7123 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 552: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 552/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4749 - acc: 0.7533 - val_loss: 0.5153 - val_acc: 0.7123 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 553: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 553/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4793 - acc: 0.7533 - val_loss: 0.5168 - val_acc: 0.7161 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 554: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 554/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4782 - acc: 0.7501 - val_loss: 0.5146 - val_acc: 0.7136 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 555: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 555/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4712 - acc: 0.7585 - val_loss: 0.5120 - val_acc: 0.7174 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 556: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 556/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4768 - acc: 0.7573 - val_loss: 0.5088 - val_acc: 0.7212 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 557: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 557/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.4786 - acc: 0.7585 - val_loss: 0.5060 - val_acc: 0.7187 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 558: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 558/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4743 - acc: 0.7549 - val_loss: 0.5059 - val_acc: 0.7212 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 559: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 559/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4912 - acc: 0.7413 - val_loss: 0.5050 - val_acc: 0.7238 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 560: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 560/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4764 - acc: 0.7569 - val_loss: 0.5063 - val_acc: 0.7225 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 561: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 561/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4750 - acc: 0.7517 - val_loss: 0.5076 - val_acc: 0.7199 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 562: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 562/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4744 - acc: 0.7581 - val_loss: 0.5082 - val_acc: 0.7225 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 563: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 563/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4743 - acc: 0.7537 - val_loss: 0.5087 - val_acc: 0.7187 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 564: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 564/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4736 - acc: 0.7565 - val_loss: 0.5093 - val_acc: 0.7174 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 565: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 565/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4668 - acc: 0.7557 - val_loss: 0.5101 - val_acc: 0.7161 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 566: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 566/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4684 - acc: 0.7549 - val_loss: 0.5107 - val_acc: 0.7161 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 567: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 567/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4753 - acc: 0.7489 - val_loss: 0.5119 - val_acc: 0.7161 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 568: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 568/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4764 - acc: 0.7517 - val_loss: 0.5148 - val_acc: 0.7148 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 569: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 569/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4812 - acc: 0.7525 - val_loss: 0.5151 - val_acc: 0.7148 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 570: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 570/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4750 - acc: 0.7449 - val_loss: 0.5119 - val_acc: 0.7148 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 571: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 571/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4765 - acc: 0.7513 - val_loss: 0.5145 - val_acc: 0.7161 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 572: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 572/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4674 - acc: 0.7589 - val_loss: 0.5166 - val_acc: 0.7123 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 573: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 573/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4777 - acc: 0.7513 - val_loss: 0.5180 - val_acc: 0.7123 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 574: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 574/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4656 - acc: 0.7549 - val_loss: 0.5141 - val_acc: 0.7161 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 575: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 575/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4791 - acc: 0.7457 - val_loss: 0.5121 - val_acc: 0.7174 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 576: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 576/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4751 - acc: 0.7537 - val_loss: 0.5149 - val_acc: 0.7148 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 577: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 577/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4674 - acc: 0.7553 - val_loss: 0.5162 - val_acc: 0.7136 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 578: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 578/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4749 - acc: 0.7537 - val_loss: 0.5150 - val_acc: 0.7148 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 579: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 579/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4739 - acc: 0.7561 - val_loss: 0.5155 - val_acc: 0.7148 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 580: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 580/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4765 - acc: 0.7505 - val_loss: 0.5165 - val_acc: 0.7123 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 581: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 581/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4721 - acc: 0.7541 - val_loss: 0.5175 - val_acc: 0.7123 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 582: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 582/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4664 - acc: 0.7605 - val_loss: 0.5167 - val_acc: 0.7123 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 583: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 583/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4757 - acc: 0.7497 - val_loss: 0.5181 - val_acc: 0.7110 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 584: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 584/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4845 - acc: 0.7473 - val_loss: 0.5222 - val_acc: 0.7123 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 585: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 585/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4693 - acc: 0.7617 - val_loss: 0.5253 - val_acc: 0.7097 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 586: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 586/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4795 - acc: 0.7509 - val_loss: 0.5262 - val_acc: 0.7110 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 587: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 587/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4692 - acc: 0.7517 - val_loss: 0.5263 - val_acc: 0.7084 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 588: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 588/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4635 - acc: 0.7641 - val_loss: 0.5280 - val_acc: 0.7084 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 589: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 589/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4729 - acc: 0.7521 - val_loss: 0.5271 - val_acc: 0.7084 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 590: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 590/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4677 - acc: 0.7505 - val_loss: 0.5230 - val_acc: 0.7097 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 591: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 591/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4715 - acc: 0.7605 - val_loss: 0.5220 - val_acc: 0.7097 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 592: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 592/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4752 - acc: 0.7525 - val_loss: 0.5258 - val_acc: 0.7084 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 593: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 593/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4856 - acc: 0.7525 - val_loss: 0.5293 - val_acc: 0.7059 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 594: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 594/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4773 - acc: 0.7517 - val_loss: 0.5234 - val_acc: 0.7097 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 595: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 595/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4660 - acc: 0.7585 - val_loss: 0.5209 - val_acc: 0.7123 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 596: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 596/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4637 - acc: 0.7569 - val_loss: 0.5172 - val_acc: 0.7084 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 597: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 597/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4724 - acc: 0.7553 - val_loss: 0.5142 - val_acc: 0.7097 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 598: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 598/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4781 - acc: 0.7509 - val_loss: 0.5118 - val_acc: 0.7123 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 599: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 599/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4743 - acc: 0.7581 - val_loss: 0.5096 - val_acc: 0.7123 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 600: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 600/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4721 - acc: 0.7585 - val_loss: 0.5091 - val_acc: 0.7161 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 601: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 601/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4722 - acc: 0.7561 - val_loss: 0.5056 - val_acc: 0.7251 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 602: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 602/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4703 - acc: 0.7553 - val_loss: 0.5060 - val_acc: 0.7238 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 603: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 603/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4710 - acc: 0.7549 - val_loss: 0.5063 - val_acc: 0.7225 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 604: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 604/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4733 - acc: 0.7549 - val_loss: 0.5067 - val_acc: 0.7212 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 605: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 605/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4638 - acc: 0.7517 - val_loss: 0.5071 - val_acc: 0.7212 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 606: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 606/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4683 - acc: 0.7561 - val_loss: 0.5075 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 607: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 607/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4716 - acc: 0.7557 - val_loss: 0.5083 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 608: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 608/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4677 - acc: 0.7493 - val_loss: 0.5092 - val_acc: 0.7187 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 609: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 609/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4838 - acc: 0.7557 - val_loss: 0.5100 - val_acc: 0.7148 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 610: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 610/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4646 - acc: 0.7641 - val_loss: 0.5105 - val_acc: 0.7148 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 611: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 611/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4778 - acc: 0.7509 - val_loss: 0.5109 - val_acc: 0.7136 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 612: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 612/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4717 - acc: 0.7549 - val_loss: 0.5115 - val_acc: 0.7136 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 613: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 613/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4672 - acc: 0.7585 - val_loss: 0.5121 - val_acc: 0.7136 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 614: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 614/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4734 - acc: 0.7601 - val_loss: 0.5127 - val_acc: 0.7148 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 615: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 615/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4628 - acc: 0.7669 - val_loss: 0.5130 - val_acc: 0.7148 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 616: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 616/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4764 - acc: 0.7561 - val_loss: 0.5133 - val_acc: 0.7136 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 617: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 617/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4598 - acc: 0.7569 - val_loss: 0.5136 - val_acc: 0.7136 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 618: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 618/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4806 - acc: 0.7497 - val_loss: 0.5141 - val_acc: 0.7136 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 619: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 619/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4637 - acc: 0.7533 - val_loss: 0.5146 - val_acc: 0.7136 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 620: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 620/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4660 - acc: 0.7609 - val_loss: 0.5149 - val_acc: 0.7148 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 621: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 621/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4680 - acc: 0.7493 - val_loss: 0.5151 - val_acc: 0.7148 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 622: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 622/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.4699 - acc: 0.7501 - val_loss: 0.5152 - val_acc: 0.7148 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 623: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 623/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4586 - acc: 0.7637 - val_loss: 0.5154 - val_acc: 0.7148 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 624: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 624/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4702 - acc: 0.7589 - val_loss: 0.5157 - val_acc: 0.7136 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 625: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 625/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4721 - acc: 0.7613 - val_loss: 0.5160 - val_acc: 0.7136 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 626: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 626/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4677 - acc: 0.7617 - val_loss: 0.5161 - val_acc: 0.7136 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 627: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 627/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4588 - acc: 0.7641 - val_loss: 0.5161 - val_acc: 0.7136 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 628: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 628/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4705 - acc: 0.7513 - val_loss: 0.5161 - val_acc: 0.7136 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 629: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 629/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4712 - acc: 0.7565 - val_loss: 0.5163 - val_acc: 0.7136 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 630: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 630/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.4668 - acc: 0.7525 - val_loss: 0.5163 - val_acc: 0.7148 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 631: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 631/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4744 - acc: 0.7517 - val_loss: 0.5164 - val_acc: 0.7148 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 632: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 632/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4774 - acc: 0.7485 - val_loss: 0.5166 - val_acc: 0.7136 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 633: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 633/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4736 - acc: 0.7557 - val_loss: 0.5167 - val_acc: 0.7136 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 634: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 634/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4717 - acc: 0.7597 - val_loss: 0.5166 - val_acc: 0.7136 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 635: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 635/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4736 - acc: 0.7621 - val_loss: 0.5167 - val_acc: 0.7136 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 636: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 636/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4726 - acc: 0.7589 - val_loss: 0.5167 - val_acc: 0.7136 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 637: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 637/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4714 - acc: 0.7573 - val_loss: 0.5167 - val_acc: 0.7136 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 638: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 638/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4645 - acc: 0.7597 - val_loss: 0.5165 - val_acc: 0.7136 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 639: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 639/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4733 - acc: 0.7617 - val_loss: 0.5165 - val_acc: 0.7136 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 640: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 640/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4767 - acc: 0.7501 - val_loss: 0.5162 - val_acc: 0.7136 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 641: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 641/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4773 - acc: 0.7589 - val_loss: 0.5161 - val_acc: 0.7136 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 642: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 642/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4748 - acc: 0.7605 - val_loss: 0.5158 - val_acc: 0.7123 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 643: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 643/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4638 - acc: 0.7589 - val_loss: 0.5158 - val_acc: 0.7136 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 644: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 644/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4772 - acc: 0.7549 - val_loss: 0.5157 - val_acc: 0.7136 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 645: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 645/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4690 - acc: 0.7485 - val_loss: 0.5156 - val_acc: 0.7136 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 646: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 646/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4697 - acc: 0.7573 - val_loss: 0.5156 - val_acc: 0.7148 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 647: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 647/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4722 - acc: 0.7549 - val_loss: 0.5158 - val_acc: 0.7148 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 648: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 648/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4746 - acc: 0.7533 - val_loss: 0.5163 - val_acc: 0.7148 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 649: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 649/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4733 - acc: 0.7565 - val_loss: 0.5168 - val_acc: 0.7136 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 650: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 650/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4737 - acc: 0.7513 - val_loss: 0.5171 - val_acc: 0.7123 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 651: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 651/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4662 - acc: 0.7557 - val_loss: 0.5172 - val_acc: 0.7110 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 652: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 652/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4696 - acc: 0.7573 - val_loss: 0.5174 - val_acc: 0.7097 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 653: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 653/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4723 - acc: 0.7561 - val_loss: 0.5174 - val_acc: 0.7110 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 654: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 654/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4739 - acc: 0.7589 - val_loss: 0.5175 - val_acc: 0.7110 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 655: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 655/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.4668 - acc: 0.7565 - val_loss: 0.5174 - val_acc: 0.7110 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 656: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 656/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4747 - acc: 0.7505 - val_loss: 0.5174 - val_acc: 0.7110 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 657: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 657/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4713 - acc: 0.7593 - val_loss: 0.5173 - val_acc: 0.7110 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 658: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 658/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4785 - acc: 0.7541 - val_loss: 0.5171 - val_acc: 0.7110 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 659: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 659/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4785 - acc: 0.7489 - val_loss: 0.5171 - val_acc: 0.7110 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 660: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 660/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4671 - acc: 0.7561 - val_loss: 0.5173 - val_acc: 0.7097 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 661: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 661/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4679 - acc: 0.7557 - val_loss: 0.5172 - val_acc: 0.7097 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 662: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 662/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4632 - acc: 0.7609 - val_loss: 0.5174 - val_acc: 0.7097 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 663: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 663/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4667 - acc: 0.7617 - val_loss: 0.5174 - val_acc: 0.7097 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 664: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 664/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4781 - acc: 0.7477 - val_loss: 0.5172 - val_acc: 0.7097 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 665: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 665/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4700 - acc: 0.7569 - val_loss: 0.5172 - val_acc: 0.7097 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 666: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 666/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4676 - acc: 0.7521 - val_loss: 0.5174 - val_acc: 0.7097 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 667: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 667/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4698 - acc: 0.7569 - val_loss: 0.5172 - val_acc: 0.7097 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 668: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 668/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4752 - acc: 0.7577 - val_loss: 0.5170 - val_acc: 0.7097 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 669: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 669/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4741 - acc: 0.7565 - val_loss: 0.5170 - val_acc: 0.7097 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 670: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 670/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4744 - acc: 0.7453 - val_loss: 0.5172 - val_acc: 0.7097 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 671: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 671/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4693 - acc: 0.7493 - val_loss: 0.5169 - val_acc: 0.7097 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 672: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 672/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4816 - acc: 0.7581 - val_loss: 0.5167 - val_acc: 0.7123 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 673: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 673/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4666 - acc: 0.7597 - val_loss: 0.5164 - val_acc: 0.7123 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 674: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 674/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4715 - acc: 0.7533 - val_loss: 0.5160 - val_acc: 0.7148 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 675: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 675/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.4780 - acc: 0.7545 - val_loss: 0.5159 - val_acc: 0.7148 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 676: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 676/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4590 - acc: 0.7621 - val_loss: 0.5156 - val_acc: 0.7148 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 677: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 677/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4696 - acc: 0.7581 - val_loss: 0.5152 - val_acc: 0.7148 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 678: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 678/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4706 - acc: 0.7501 - val_loss: 0.5149 - val_acc: 0.7148 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 679: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 679/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4694 - acc: 0.7585 - val_loss: 0.5150 - val_acc: 0.7148 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 680: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 680/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4784 - acc: 0.7585 - val_loss: 0.5150 - val_acc: 0.7148 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 681: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 681/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4703 - acc: 0.7573 - val_loss: 0.5150 - val_acc: 0.7148 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 682: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 682/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4711 - acc: 0.7529 - val_loss: 0.5149 - val_acc: 0.7148 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 683: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 683/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4787 - acc: 0.7517 - val_loss: 0.5150 - val_acc: 0.7148 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 684: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 684/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4672 - acc: 0.7609 - val_loss: 0.5150 - val_acc: 0.7148 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 685: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 685/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4713 - acc: 0.7541 - val_loss: 0.5151 - val_acc: 0.7148 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 686: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 686/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4578 - acc: 0.7617 - val_loss: 0.5150 - val_acc: 0.7148 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 687: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 687/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4741 - acc: 0.7517 - val_loss: 0.5148 - val_acc: 0.7148 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 688: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 688/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4763 - acc: 0.7445 - val_loss: 0.5147 - val_acc: 0.7148 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 689: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 689/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4701 - acc: 0.7581 - val_loss: 0.5147 - val_acc: 0.7148 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 690: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 690/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4687 - acc: 0.7525 - val_loss: 0.5148 - val_acc: 0.7148 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 691: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 691/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4801 - acc: 0.7557 - val_loss: 0.5147 - val_acc: 0.7148 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 692: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 692/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4649 - acc: 0.7565 - val_loss: 0.5143 - val_acc: 0.7148 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 693: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 693/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4836 - acc: 0.7413 - val_loss: 0.5140 - val_acc: 0.7148 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 694: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 694/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4661 - acc: 0.7589 - val_loss: 0.5139 - val_acc: 0.7148 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 695: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 695/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4745 - acc: 0.7585 - val_loss: 0.5140 - val_acc: 0.7148 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 696: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 696/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4764 - acc: 0.7557 - val_loss: 0.5142 - val_acc: 0.7148 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 697: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 697/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4706 - acc: 0.7529 - val_loss: 0.5145 - val_acc: 0.7148 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 698: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 698/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4651 - acc: 0.7573 - val_loss: 0.5147 - val_acc: 0.7148 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 699: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 699/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4659 - acc: 0.7585 - val_loss: 0.5149 - val_acc: 0.7148 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 700: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 700/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4743 - acc: 0.7577 - val_loss: 0.5149 - val_acc: 0.7148 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 701: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 701/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4622 - acc: 0.7585 - val_loss: 0.5148 - val_acc: 0.7148 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 702: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 702/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4643 - acc: 0.7581 - val_loss: 0.5126 - val_acc: 0.7161 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 703: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 703/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4643 - acc: 0.7629 - val_loss: 0.5124 - val_acc: 0.7148 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 704: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 704/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4701 - acc: 0.7557 - val_loss: 0.5210 - val_acc: 0.7059 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 705: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 705/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4698 - acc: 0.7549 - val_loss: 0.5204 - val_acc: 0.7059 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 706: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 706/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4769 - acc: 0.7513 - val_loss: 0.5150 - val_acc: 0.7136 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 707: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 707/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4678 - acc: 0.7569 - val_loss: 0.5171 - val_acc: 0.7136 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 708: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 708/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4677 - acc: 0.7585 - val_loss: 0.5139 - val_acc: 0.7136 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 709: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 709/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4665 - acc: 0.7565 - val_loss: 0.5141 - val_acc: 0.7136 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 710: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 710/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4818 - acc: 0.7493 - val_loss: 0.5086 - val_acc: 0.7187 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 711: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 711/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4630 - acc: 0.7685 - val_loss: 0.5013 - val_acc: 0.7251 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 712: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 712/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4741 - acc: 0.7577 - val_loss: 0.5000 - val_acc: 0.7263 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 713: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 713/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4762 - acc: 0.7573 - val_loss: 0.5036 - val_acc: 0.7276 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 714: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 714/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4642 - acc: 0.7629 - val_loss: 0.5069 - val_acc: 0.7199 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 715: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 715/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4698 - acc: 0.7593 - val_loss: 0.5107 - val_acc: 0.7187 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 716: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 716/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4687 - acc: 0.7609 - val_loss: 0.5143 - val_acc: 0.7123 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 717: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 717/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4698 - acc: 0.7589 - val_loss: 0.5119 - val_acc: 0.7136 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 718: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 718/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4701 - acc: 0.7505 - val_loss: 0.5123 - val_acc: 0.7148 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 719: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 719/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4713 - acc: 0.7473 - val_loss: 0.5103 - val_acc: 0.7136 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 720: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 720/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4669 - acc: 0.7589 - val_loss: 0.5062 - val_acc: 0.7161 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 721: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 721/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4748 - acc: 0.7517 - val_loss: 0.5100 - val_acc: 0.7123 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 722: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 722/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4602 - acc: 0.7565 - val_loss: 0.5089 - val_acc: 0.7123 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 723: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 723/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4778 - acc: 0.7557 - val_loss: 0.5223 - val_acc: 0.7097 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 724: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 724/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4714 - acc: 0.7589 - val_loss: 0.5269 - val_acc: 0.7110 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 725: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 725/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4740 - acc: 0.7505 - val_loss: 0.5201 - val_acc: 0.7097 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 726: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 726/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4588 - acc: 0.7625 - val_loss: 0.5121 - val_acc: 0.7097 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 727: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 727/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4726 - acc: 0.7493 - val_loss: 0.5113 - val_acc: 0.7136 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 728: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 728/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4682 - acc: 0.7545 - val_loss: 0.5082 - val_acc: 0.7161 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 729: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 729/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4564 - acc: 0.7645 - val_loss: 0.5111 - val_acc: 0.7174 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 730: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 730/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4729 - acc: 0.7537 - val_loss: 0.5139 - val_acc: 0.7161 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 731: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 731/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4658 - acc: 0.7573 - val_loss: 0.5188 - val_acc: 0.7110 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 732: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 732/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4628 - acc: 0.7637 - val_loss: 0.5201 - val_acc: 0.7097 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 733: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 733/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4718 - acc: 0.7549 - val_loss: 0.5186 - val_acc: 0.7110 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 734: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 734/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4683 - acc: 0.7581 - val_loss: 0.5181 - val_acc: 0.7020 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 735: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 735/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4684 - acc: 0.7541 - val_loss: 0.5103 - val_acc: 0.7174 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 736: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 736/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4685 - acc: 0.7557 - val_loss: 0.5100 - val_acc: 0.7161 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 737: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 737/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4645 - acc: 0.7609 - val_loss: 0.5134 - val_acc: 0.7136 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 738: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 738/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4553 - acc: 0.7697 - val_loss: 0.5128 - val_acc: 0.7161 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 739: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 739/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4691 - acc: 0.7525 - val_loss: 0.5113 - val_acc: 0.7161 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 740: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 740/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4696 - acc: 0.7589 - val_loss: 0.5106 - val_acc: 0.7161 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 741: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 741/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4754 - acc: 0.7541 - val_loss: 0.5048 - val_acc: 0.7251 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 742: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 742/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4564 - acc: 0.7649 - val_loss: 0.5080 - val_acc: 0.7187 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 743: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 743/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4670 - acc: 0.7505 - val_loss: 0.5119 - val_acc: 0.7123 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 744: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 744/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4668 - acc: 0.7593 - val_loss: 0.5139 - val_acc: 0.7110 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 745: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 745/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4602 - acc: 0.7549 - val_loss: 0.5127 - val_acc: 0.7123 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 746: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 746/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4633 - acc: 0.7661 - val_loss: 0.5058 - val_acc: 0.7212 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 747: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 747/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4608 - acc: 0.7573 - val_loss: 0.5048 - val_acc: 0.7212 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 748: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 748/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4668 - acc: 0.7525 - val_loss: 0.5011 - val_acc: 0.7263 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 749: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 749/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4655 - acc: 0.7577 - val_loss: 0.5074 - val_acc: 0.7174 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 750: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 750/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4589 - acc: 0.7613 - val_loss: 0.5126 - val_acc: 0.7161 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 751: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 751/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4717 - acc: 0.7577 - val_loss: 0.5114 - val_acc: 0.7174 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 752: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 752/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4604 - acc: 0.7625 - val_loss: 0.5136 - val_acc: 0.7161 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 753: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 753/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4594 - acc: 0.7569 - val_loss: 0.5170 - val_acc: 0.7161 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 754: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 754/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4767 - acc: 0.7501 - val_loss: 0.5189 - val_acc: 0.7136 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 755: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 755/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4578 - acc: 0.7613 - val_loss: 0.5181 - val_acc: 0.7084 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 756: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 756/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4498 - acc: 0.7661 - val_loss: 0.5118 - val_acc: 0.7136 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 757: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 757/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4645 - acc: 0.7613 - val_loss: 0.5093 - val_acc: 0.7174 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 758: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 758/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4658 - acc: 0.7649 - val_loss: 0.5064 - val_acc: 0.7225 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 759: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 759/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4542 - acc: 0.7661 - val_loss: 0.5057 - val_acc: 0.7212 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 760: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 760/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4644 - acc: 0.7621 - val_loss: 0.5104 - val_acc: 0.7187 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 761: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 761/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4587 - acc: 0.7609 - val_loss: 0.5120 - val_acc: 0.7187 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 762: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 762/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.4627 - acc: 0.7565 - val_loss: 0.5111 - val_acc: 0.7212 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 763: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 763/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4623 - acc: 0.7629 - val_loss: 0.5149 - val_acc: 0.7084 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 764: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 764/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4633 - acc: 0.7569 - val_loss: 0.5226 - val_acc: 0.7059 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 765: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 765/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4664 - acc: 0.7601 - val_loss: 0.5261 - val_acc: 0.7059 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 766: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 766/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4703 - acc: 0.7593 - val_loss: 0.5269 - val_acc: 0.7072 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 767: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 767/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4740 - acc: 0.7489 - val_loss: 0.5213 - val_acc: 0.7097 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 768: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 768/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4610 - acc: 0.7657 - val_loss: 0.5117 - val_acc: 0.7148 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 769: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 769/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4581 - acc: 0.7501 - val_loss: 0.5124 - val_acc: 0.7123 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 770: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 770/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4621 - acc: 0.7545 - val_loss: 0.5124 - val_acc: 0.7136 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 771: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 771/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4633 - acc: 0.7521 - val_loss: 0.5154 - val_acc: 0.7084 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 772: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 772/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4591 - acc: 0.7589 - val_loss: 0.5231 - val_acc: 0.7020 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 773: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 773/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4620 - acc: 0.7629 - val_loss: 0.5244 - val_acc: 0.7020 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 774: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 774/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4673 - acc: 0.7549 - val_loss: 0.5205 - val_acc: 0.7110 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 775: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 775/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4662 - acc: 0.7569 - val_loss: 0.5166 - val_acc: 0.7110 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 776: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 776/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4518 - acc: 0.7649 - val_loss: 0.5158 - val_acc: 0.7110 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 777: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 777/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4718 - acc: 0.7645 - val_loss: 0.5142 - val_acc: 0.7199 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 778: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 778/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4566 - acc: 0.7601 - val_loss: 0.5147 - val_acc: 0.7148 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 779: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 779/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4624 - acc: 0.7641 - val_loss: 0.5154 - val_acc: 0.7174 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 780: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 780/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4587 - acc: 0.7645 - val_loss: 0.5169 - val_acc: 0.7072 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 781: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 781/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4573 - acc: 0.7693 - val_loss: 0.5157 - val_acc: 0.7097 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 782: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 782/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4621 - acc: 0.7589 - val_loss: 0.5155 - val_acc: 0.7110 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 783: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 783/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4569 - acc: 0.7641 - val_loss: 0.5157 - val_acc: 0.7174 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 784: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 784/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4680 - acc: 0.7585 - val_loss: 0.5171 - val_acc: 0.7123 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 785: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 785/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4530 - acc: 0.7621 - val_loss: 0.5145 - val_acc: 0.7161 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 786: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 786/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4552 - acc: 0.7661 - val_loss: 0.5100 - val_acc: 0.7187 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 787: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 787/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4573 - acc: 0.7549 - val_loss: 0.5046 - val_acc: 0.7174 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 788: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 788/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4609 - acc: 0.7605 - val_loss: 0.4987 - val_acc: 0.7276 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 789: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 789/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4566 - acc: 0.7685 - val_loss: 0.4958 - val_acc: 0.7276 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 790: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 790/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4614 - acc: 0.7629 - val_loss: 0.5004 - val_acc: 0.7225 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 791: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 791/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4629 - acc: 0.7581 - val_loss: 0.5112 - val_acc: 0.7174 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 792: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 792/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4573 - acc: 0.7713 - val_loss: 0.5095 - val_acc: 0.7212 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 793: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 793/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4606 - acc: 0.7697 - val_loss: 0.5027 - val_acc: 0.7238 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 794: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 794/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4405 - acc: 0.7753 - val_loss: 0.5020 - val_acc: 0.7238 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 795: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 795/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4612 - acc: 0.7633 - val_loss: 0.5048 - val_acc: 0.7225 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 796: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 796/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4555 - acc: 0.7693 - val_loss: 0.5004 - val_acc: 0.7315 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 797: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 797/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4545 - acc: 0.7617 - val_loss: 0.5023 - val_acc: 0.7251 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 798: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 798/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4508 - acc: 0.7665 - val_loss: 0.5048 - val_acc: 0.7225 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 799: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 799/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4547 - acc: 0.7609 - val_loss: 0.5136 - val_acc: 0.7161 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 800: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 800/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4551 - acc: 0.7625 - val_loss: 0.5069 - val_acc: 0.7187 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 801: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 801/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4557 - acc: 0.7597 - val_loss: 0.5059 - val_acc: 0.7199 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 802: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 802/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4516 - acc: 0.7645 - val_loss: 0.5061 - val_acc: 0.7238 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 803: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 803/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4491 - acc: 0.7709 - val_loss: 0.5091 - val_acc: 0.7238 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 804: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 804/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4652 - acc: 0.7649 - val_loss: 0.5109 - val_acc: 0.7212 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 805: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 805/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4551 - acc: 0.7585 - val_loss: 0.5137 - val_acc: 0.7174 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 806: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 806/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4536 - acc: 0.7569 - val_loss: 0.5117 - val_acc: 0.7187 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 807: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 807/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4585 - acc: 0.7637 - val_loss: 0.5085 - val_acc: 0.7199 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 808: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 808/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4538 - acc: 0.7641 - val_loss: 0.5049 - val_acc: 0.7225 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 809: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 809/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4650 - acc: 0.7653 - val_loss: 0.4949 - val_acc: 0.7289 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 810: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 810/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4539 - acc: 0.7625 - val_loss: 0.4929 - val_acc: 0.7276 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 811: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 811/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4576 - acc: 0.7545 - val_loss: 0.4927 - val_acc: 0.7302 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 812: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 812/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4620 - acc: 0.7509 - val_loss: 0.4944 - val_acc: 0.7276 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 813: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 813/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4556 - acc: 0.7637 - val_loss: 0.4988 - val_acc: 0.7251 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 814: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 814/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4507 - acc: 0.7641 - val_loss: 0.5045 - val_acc: 0.7276 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 815: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 815/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4489 - acc: 0.7629 - val_loss: 0.5048 - val_acc: 0.7289 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 816: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 816/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4551 - acc: 0.7637 - val_loss: 0.5051 - val_acc: 0.7276 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 817: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 817/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4573 - acc: 0.7673 - val_loss: 0.5035 - val_acc: 0.7302 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 818: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 818/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4565 - acc: 0.7689 - val_loss: 0.5007 - val_acc: 0.7327 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 819: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 819/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4448 - acc: 0.7585 - val_loss: 0.4975 - val_acc: 0.7353 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 820: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 820/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4616 - acc: 0.7601 - val_loss: 0.4929 - val_acc: 0.7379 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 821: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 821/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4491 - acc: 0.7697 - val_loss: 0.4951 - val_acc: 0.7442 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 822: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 822/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4608 - acc: 0.7593 - val_loss: 0.4998 - val_acc: 0.7340 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 823: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 823/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4562 - acc: 0.7613 - val_loss: 0.4986 - val_acc: 0.7366 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 824: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 824/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.4481 - acc: 0.7697 - val_loss: 0.4975 - val_acc: 0.7379 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 825: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 825/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4564 - acc: 0.7633 - val_loss: 0.4963 - val_acc: 0.7366 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 826: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 826/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4519 - acc: 0.7757 - val_loss: 0.4982 - val_acc: 0.7327 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 827: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 827/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4536 - acc: 0.7701 - val_loss: 0.5002 - val_acc: 0.7302 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 828: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 828/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4411 - acc: 0.7745 - val_loss: 0.5042 - val_acc: 0.7302 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 829: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 829/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4399 - acc: 0.7677 - val_loss: 0.5077 - val_acc: 0.7199 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 830: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 830/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4460 - acc: 0.7653 - val_loss: 0.5054 - val_acc: 0.7302 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 831: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 831/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4475 - acc: 0.7741 - val_loss: 0.5007 - val_acc: 0.7353 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 832: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 832/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4537 - acc: 0.7613 - val_loss: 0.5012 - val_acc: 0.7340 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 833: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 833/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4474 - acc: 0.7749 - val_loss: 0.5093 - val_acc: 0.7212 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 834: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 834/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4401 - acc: 0.7757 - val_loss: 0.5086 - val_acc: 0.7212 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 835: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 835/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4575 - acc: 0.7661 - val_loss: 0.5094 - val_acc: 0.7238 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 836: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 836/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.4532 - acc: 0.7665 - val_loss: 0.4986 - val_acc: 0.7327 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 837: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 837/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.4515 - acc: 0.7633 - val_loss: 0.4955 - val_acc: 0.7353 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 838: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 838/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4456 - acc: 0.7689 - val_loss: 0.4962 - val_acc: 0.7340 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 839: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 839/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4498 - acc: 0.7657 - val_loss: 0.5008 - val_acc: 0.7315 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 840: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 840/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4486 - acc: 0.7701 - val_loss: 0.5013 - val_acc: 0.7302 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 841: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 841/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4495 - acc: 0.7717 - val_loss: 0.5038 - val_acc: 0.7238 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 842: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 842/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4472 - acc: 0.7645 - val_loss: 0.5071 - val_acc: 0.7263 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 843: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 843/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4544 - acc: 0.7613 - val_loss: 0.5103 - val_acc: 0.7199 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 844: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 844/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4551 - acc: 0.7717 - val_loss: 0.5078 - val_acc: 0.7187 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 845: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 845/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4339 - acc: 0.7809 - val_loss: 0.5033 - val_acc: 0.7276 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 846: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 846/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4439 - acc: 0.7709 - val_loss: 0.4995 - val_acc: 0.7327 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 847: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 847/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4492 - acc: 0.7693 - val_loss: 0.4986 - val_acc: 0.7340 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 848: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 848/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4539 - acc: 0.7645 - val_loss: 0.5010 - val_acc: 0.7379 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 849: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 849/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4523 - acc: 0.7745 - val_loss: 0.5057 - val_acc: 0.7315 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 850: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 850/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4471 - acc: 0.7665 - val_loss: 0.5005 - val_acc: 0.7417 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 851: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 851/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4355 - acc: 0.7653 - val_loss: 0.4987 - val_acc: 0.7442 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 852: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 852/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4526 - acc: 0.7625 - val_loss: 0.5009 - val_acc: 0.7430 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 853: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 853/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4454 - acc: 0.7613 - val_loss: 0.5064 - val_acc: 0.7302 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 854: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 854/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4440 - acc: 0.7673 - val_loss: 0.5085 - val_acc: 0.7289 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 855: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 855/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4502 - acc: 0.7661 - val_loss: 0.4989 - val_acc: 0.7315 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 856: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 856/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4455 - acc: 0.7709 - val_loss: 0.4890 - val_acc: 0.7340 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 857: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 857/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4551 - acc: 0.7705 - val_loss: 0.4890 - val_acc: 0.7366 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 858: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 858/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4423 - acc: 0.7653 - val_loss: 0.5058 - val_acc: 0.7315 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 859: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 859/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4547 - acc: 0.7621 - val_loss: 0.5287 - val_acc: 0.7212 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 860: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 860/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4538 - acc: 0.7697 - val_loss: 0.5291 - val_acc: 0.7187 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 861: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 861/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4408 - acc: 0.7705 - val_loss: 0.5000 - val_acc: 0.7327 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 862: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 862/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4542 - acc: 0.7661 - val_loss: 0.4861 - val_acc: 0.7442 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 863: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 863/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4417 - acc: 0.7725 - val_loss: 0.4851 - val_acc: 0.7417 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 864: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 864/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4459 - acc: 0.7669 - val_loss: 0.4895 - val_acc: 0.7353 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 865: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 865/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4441 - acc: 0.7685 - val_loss: 0.5034 - val_acc: 0.7225 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 866: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 866/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4576 - acc: 0.7573 - val_loss: 0.5027 - val_acc: 0.7225 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 867: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 867/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4383 - acc: 0.7789 - val_loss: 0.4888 - val_acc: 0.7379 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 868: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 868/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4562 - acc: 0.7641 - val_loss: 0.4790 - val_acc: 0.7417 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 869: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 869/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4550 - acc: 0.7697 - val_loss: 0.4817 - val_acc: 0.7430 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 870: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 870/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4547 - acc: 0.7597 - val_loss: 0.4883 - val_acc: 0.7404 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 871: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 871/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4428 - acc: 0.7709 - val_loss: 0.5005 - val_acc: 0.7251 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 872: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 872/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4491 - acc: 0.7617 - val_loss: 0.4966 - val_acc: 0.7327 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 873: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 873/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4449 - acc: 0.7633 - val_loss: 0.4853 - val_acc: 0.7289 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 874: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 874/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4404 - acc: 0.7705 - val_loss: 0.4785 - val_acc: 0.7417 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 875: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 875/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4450 - acc: 0.7645 - val_loss: 0.4775 - val_acc: 0.7442 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 876: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 876/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4396 - acc: 0.7741 - val_loss: 0.4779 - val_acc: 0.7481 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 877: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 877/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4490 - acc: 0.7641 - val_loss: 0.4796 - val_acc: 0.7391 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 878: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 878/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4437 - acc: 0.7773 - val_loss: 0.4810 - val_acc: 0.7391 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 879: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 879/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4569 - acc: 0.7625 - val_loss: 0.4794 - val_acc: 0.7481 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 880: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 880/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4342 - acc: 0.7741 - val_loss: 0.4813 - val_acc: 0.7506 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 881: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 881/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4443 - acc: 0.7777 - val_loss: 0.4831 - val_acc: 0.7455 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 882: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 882/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4418 - acc: 0.7745 - val_loss: 0.4852 - val_acc: 0.7404 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 883: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 883/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4557 - acc: 0.7745 - val_loss: 0.4892 - val_acc: 0.7391 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 884: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 884/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4552 - acc: 0.7669 - val_loss: 0.4921 - val_acc: 0.7327 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 885: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 885/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4392 - acc: 0.7789 - val_loss: 0.4829 - val_acc: 0.7442 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 886: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 886/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4406 - acc: 0.7717 - val_loss: 0.4814 - val_acc: 0.7506 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 887: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 887/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4439 - acc: 0.7697 - val_loss: 0.4799 - val_acc: 0.7494 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 888: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 888/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4364 - acc: 0.7789 - val_loss: 0.4781 - val_acc: 0.7545 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 889: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 889/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4427 - acc: 0.7713 - val_loss: 0.4787 - val_acc: 0.7468 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 890: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 890/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4391 - acc: 0.7629 - val_loss: 0.4809 - val_acc: 0.7430 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 891: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 891/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4384 - acc: 0.7673 - val_loss: 0.4790 - val_acc: 0.7442 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 892: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 892/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4392 - acc: 0.7697 - val_loss: 0.4818 - val_acc: 0.7417 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 893: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 893/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4443 - acc: 0.7689 - val_loss: 0.4896 - val_acc: 0.7327 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 894: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 894/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4389 - acc: 0.7713 - val_loss: 0.4841 - val_acc: 0.7391 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 895: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 895/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4308 - acc: 0.7833 - val_loss: 0.4786 - val_acc: 0.7545 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 896: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 896/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4517 - acc: 0.7653 - val_loss: 0.4786 - val_acc: 0.7545 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 897: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 897/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4305 - acc: 0.7733 - val_loss: 0.4792 - val_acc: 0.7519 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 898: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 898/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4390 - acc: 0.7769 - val_loss: 0.5014 - val_acc: 0.7315 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 899: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 899/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4400 - acc: 0.7653 - val_loss: 0.5136 - val_acc: 0.7289 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 900: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 900/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4438 - acc: 0.7725 - val_loss: 0.5072 - val_acc: 0.7353 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 901: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 901/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4344 - acc: 0.7797 - val_loss: 0.4950 - val_acc: 0.7494 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 902: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 902/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4295 - acc: 0.7785 - val_loss: 0.4866 - val_acc: 0.7442 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 903: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 903/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4399 - acc: 0.7725 - val_loss: 0.4829 - val_acc: 0.7545 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 904: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 904/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4429 - acc: 0.7661 - val_loss: 0.4820 - val_acc: 0.7494 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 905: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 905/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4417 - acc: 0.7745 - val_loss: 0.4926 - val_acc: 0.7442 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 906: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 906/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4301 - acc: 0.7809 - val_loss: 0.5128 - val_acc: 0.7187 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 907: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 907/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4493 - acc: 0.7737 - val_loss: 0.5156 - val_acc: 0.7148 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 908: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 908/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4430 - acc: 0.7685 - val_loss: 0.4953 - val_acc: 0.7353 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 909: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 909/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4367 - acc: 0.7741 - val_loss: 0.4824 - val_acc: 0.7481 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 910: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 910/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4381 - acc: 0.7709 - val_loss: 0.4817 - val_acc: 0.7481 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 911: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 911/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4401 - acc: 0.7749 - val_loss: 0.4887 - val_acc: 0.7404 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 912: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 912/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4466 - acc: 0.7685 - val_loss: 0.5016 - val_acc: 0.7302 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 913: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 913/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4374 - acc: 0.7629 - val_loss: 0.5114 - val_acc: 0.7276 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 914: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 914/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4295 - acc: 0.7729 - val_loss: 0.5220 - val_acc: 0.7199 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 915: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 915/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4333 - acc: 0.7773 - val_loss: 0.5030 - val_acc: 0.7289 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 916: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 916/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4486 - acc: 0.7725 - val_loss: 0.4800 - val_acc: 0.7404 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 917: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 917/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4507 - acc: 0.7701 - val_loss: 0.4766 - val_acc: 0.7532 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 918: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 918/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4399 - acc: 0.7657 - val_loss: 0.4764 - val_acc: 0.7519 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 919: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 919/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4363 - acc: 0.7757 - val_loss: 0.4834 - val_acc: 0.7430 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 920: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 920/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4393 - acc: 0.7765 - val_loss: 0.4859 - val_acc: 0.7430 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 921: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 921/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4336 - acc: 0.7749 - val_loss: 0.4836 - val_acc: 0.7417 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 922: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 922/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4458 - acc: 0.7769 - val_loss: 0.4852 - val_acc: 0.7391 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 923: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 923/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4351 - acc: 0.7701 - val_loss: 0.4828 - val_acc: 0.7442 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 924: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 924/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4283 - acc: 0.7801 - val_loss: 0.4838 - val_acc: 0.7404 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 925: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 925/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4295 - acc: 0.7801 - val_loss: 0.4844 - val_acc: 0.7391 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 926: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 926/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4353 - acc: 0.7745 - val_loss: 0.4955 - val_acc: 0.7353 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 927: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 927/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4293 - acc: 0.7729 - val_loss: 0.5009 - val_acc: 0.7251 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 928: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 928/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4318 - acc: 0.7753 - val_loss: 0.4937 - val_acc: 0.7353 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 929: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 929/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4373 - acc: 0.7737 - val_loss: 0.4897 - val_acc: 0.7315 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 930: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 930/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4249 - acc: 0.7809 - val_loss: 0.4868 - val_acc: 0.7353 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 931: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 931/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4324 - acc: 0.7817 - val_loss: 0.4888 - val_acc: 0.7417 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 932: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 932/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4363 - acc: 0.7813 - val_loss: 0.4881 - val_acc: 0.7455 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 933: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 933/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4343 - acc: 0.7705 - val_loss: 0.4785 - val_acc: 0.7442 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 934: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 934/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4322 - acc: 0.7837 - val_loss: 0.4752 - val_acc: 0.7494 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 935: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 935/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4281 - acc: 0.7781 - val_loss: 0.4796 - val_acc: 0.7468 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 936: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 936/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4365 - acc: 0.7829 - val_loss: 0.4864 - val_acc: 0.7404 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 937: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 937/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.4258 - acc: 0.7917 - val_loss: 0.4830 - val_acc: 0.7455 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 938: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 938/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4360 - acc: 0.7677 - val_loss: 0.4840 - val_acc: 0.7391 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 939: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 939/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4296 - acc: 0.7785 - val_loss: 0.4789 - val_acc: 0.7468 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 940: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 940/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4291 - acc: 0.7837 - val_loss: 0.4759 - val_acc: 0.7468 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 941: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 941/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4337 - acc: 0.7685 - val_loss: 0.4725 - val_acc: 0.7545 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 942: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 942/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4285 - acc: 0.7841 - val_loss: 0.4716 - val_acc: 0.7519 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 943: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 943/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4314 - acc: 0.7765 - val_loss: 0.4755 - val_acc: 0.7391 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 944: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 944/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4418 - acc: 0.7741 - val_loss: 0.4779 - val_acc: 0.7366 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 945: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 945/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.4149 - acc: 0.7885 - val_loss: 0.4756 - val_acc: 0.7391 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 946: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 946/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4240 - acc: 0.7869 - val_loss: 0.4717 - val_acc: 0.7506 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 947: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 947/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4415 - acc: 0.7729 - val_loss: 0.4755 - val_acc: 0.7532 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 948: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 948/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4324 - acc: 0.7729 - val_loss: 0.4719 - val_acc: 0.7430 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 949: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 949/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4222 - acc: 0.7785 - val_loss: 0.4806 - val_acc: 0.7327 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 950: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 950/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4305 - acc: 0.7737 - val_loss: 0.4842 - val_acc: 0.7353 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 951: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 951/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4311 - acc: 0.7745 - val_loss: 0.4854 - val_acc: 0.7353 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 952: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 952/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4266 - acc: 0.7777 - val_loss: 0.4792 - val_acc: 0.7366 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 953: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 953/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4274 - acc: 0.7801 - val_loss: 0.4754 - val_acc: 0.7379 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 954: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 954/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4304 - acc: 0.7829 - val_loss: 0.4747 - val_acc: 0.7404 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 955: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 955/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4187 - acc: 0.7837 - val_loss: 0.4750 - val_acc: 0.7417 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 956: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 956/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4281 - acc: 0.7805 - val_loss: 0.4779 - val_acc: 0.7430 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 957: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 957/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4282 - acc: 0.7821 - val_loss: 0.4834 - val_acc: 0.7442 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 958: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 958/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4275 - acc: 0.7665 - val_loss: 0.4826 - val_acc: 0.7417 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 959: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 959/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4334 - acc: 0.7865 - val_loss: 0.4764 - val_acc: 0.7494 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 960: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 960/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.4371 - acc: 0.7701 - val_loss: 0.4733 - val_acc: 0.7532 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 961: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 961/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.4372 - acc: 0.7773 - val_loss: 0.4833 - val_acc: 0.7404 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 962: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 962/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4346 - acc: 0.7801 - val_loss: 0.4994 - val_acc: 0.7302 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 963: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 963/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4343 - acc: 0.7745 - val_loss: 0.4924 - val_acc: 0.7391 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 964: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 964/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.4268 - acc: 0.7901 - val_loss: 0.4775 - val_acc: 0.7506 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 965: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 965/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4239 - acc: 0.7741 - val_loss: 0.4743 - val_acc: 0.7506 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 966: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 966/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4222 - acc: 0.7901 - val_loss: 0.4740 - val_acc: 0.7494 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 967: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 967/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4229 - acc: 0.7753 - val_loss: 0.4781 - val_acc: 0.7468 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 968: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 968/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4276 - acc: 0.7777 - val_loss: 0.4888 - val_acc: 0.7442 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 969: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 969/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4178 - acc: 0.7873 - val_loss: 0.4879 - val_acc: 0.7442 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 970: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 970/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4154 - acc: 0.7829 - val_loss: 0.4921 - val_acc: 0.7417 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 971: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 971/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4278 - acc: 0.7729 - val_loss: 0.4911 - val_acc: 0.7417 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 972: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 972/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4295 - acc: 0.7781 - val_loss: 0.4863 - val_acc: 0.7442 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 973: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 973/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4238 - acc: 0.7745 - val_loss: 0.4934 - val_acc: 0.7353 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 974: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 974/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4254 - acc: 0.7785 - val_loss: 0.4895 - val_acc: 0.7404 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 975: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 975/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4272 - acc: 0.7833 - val_loss: 0.4900 - val_acc: 0.7442 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 976: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 976/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4296 - acc: 0.7813 - val_loss: 0.4849 - val_acc: 0.7506 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 977: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 977/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4179 - acc: 0.7741 - val_loss: 0.4914 - val_acc: 0.7391 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 978: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 978/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4250 - acc: 0.7721 - val_loss: 0.5070 - val_acc: 0.7276 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 979: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 979/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4233 - acc: 0.7777 - val_loss: 0.5133 - val_acc: 0.7276 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 980: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 980/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4230 - acc: 0.7765 - val_loss: 0.4954 - val_acc: 0.7327 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 981: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 981/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4220 - acc: 0.7877 - val_loss: 0.4775 - val_acc: 0.7481 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 982: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 982/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4232 - acc: 0.7785 - val_loss: 0.4747 - val_acc: 0.7558 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 983: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 983/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4271 - acc: 0.7809 - val_loss: 0.4757 - val_acc: 0.7506 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 984: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 984/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4202 - acc: 0.7801 - val_loss: 0.4865 - val_acc: 0.7391 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 985: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 985/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4270 - acc: 0.7749 - val_loss: 0.4960 - val_acc: 0.7340 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 986: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 986/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4211 - acc: 0.7765 - val_loss: 0.4873 - val_acc: 0.7391 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 987: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 987/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4186 - acc: 0.7825 - val_loss: 0.4743 - val_acc: 0.7455 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 988: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 988/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4152 - acc: 0.7881 - val_loss: 0.4728 - val_acc: 0.7481 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 989: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 989/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4200 - acc: 0.7893 - val_loss: 0.4789 - val_acc: 0.7379 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 990: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 990/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4262 - acc: 0.7825 - val_loss: 0.4909 - val_acc: 0.7391 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 991: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 991/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4305 - acc: 0.7773 - val_loss: 0.4835 - val_acc: 0.7391 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 992: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 992/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4115 - acc: 0.7877 - val_loss: 0.4756 - val_acc: 0.7404 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 993: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 993/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4164 - acc: 0.7889 - val_loss: 0.4707 - val_acc: 0.7570 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 994: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 994/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4216 - acc: 0.7717 - val_loss: 0.4726 - val_acc: 0.7519 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 995: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 995/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4131 - acc: 0.7801 - val_loss: 0.4888 - val_acc: 0.7583 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 996: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 996/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4236 - acc: 0.7849 - val_loss: 0.4998 - val_acc: 0.7417 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 997: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 997/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4245 - acc: 0.7841 - val_loss: 0.5022 - val_acc: 0.7430 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 998: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 998/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4216 - acc: 0.7785 - val_loss: 0.4864 - val_acc: 0.7442 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 999: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 999/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4223 - acc: 0.7797 - val_loss: 0.4860 - val_acc: 0.7442 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 1000: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 1000/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4179 - acc: 0.7849 - val_loss: 0.4786 - val_acc: 0.7494 - lr: 4.0000e-05\n"
          ]
        }
      ],
      "source": [
        "history_simple = model_simple.fit(X_train,\n",
        "                                  y_train,\n",
        "                                  validation_data = (X_val, y_val),\n",
        "                                  callbacks = [callback],\n",
        "                                  epochs = 1000,\n",
        "                                  batch_size = 512)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# list all data in history_simple\n",
        "print(history_simple.history.keys())\n",
        "# summarize history_simple for accuracy\n",
        "plt.plot(history_simple.history['acc'])\n",
        "plt.plot(history_simple.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history_simple for loss\n",
        "plt.plot(history_simple.history['loss'])\n",
        "plt.plot(history_simple.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 944
        },
        "id": "sr4el_Y2P4AW",
        "outputId": "a7f6fc5a-6479-43d2-b1be-074fe352f2f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'acc', 'val_loss', 'val_acc', 'lr'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model because it has a balanced performance\n",
        "model_simple.save(\"/content/drive/MyDrive/models/base_model.keras\")\n",
        "\n",
        "# Save history of base model\n",
        "with open('/content/drive/MyDrive/models/base_model_history', 'wb') as file_pi:\n",
        "    pickle.dump(history_simple.history, file_pi)"
      ],
      "metadata": {
        "id": "SIKg72gU1KxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next I'll continue the training of the simple model but with different learning schedules."
      ],
      "metadata": {
        "id": "7JP22Z7jpvzS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_simple_c = Sequential()\n",
        "\n",
        "# 1st Conv Layer\n",
        "model_simple_c.add(Conv2D(32, (2, 2), padding = \"same\", strides = (1, 1), input_shape = (20, 20, 14)))\n",
        "model_simple_c.add(BatchNormalization())\n",
        "model_simple_c.add(Activation(\"relu\"))\n",
        "model_simple_c.add(Dropout(0.2))\n",
        "\n",
        "# 2nd Conv layer\n",
        "model_simple_c.add(Conv2D(64, (4, 4), padding = \"same\", strides = (1, 1)))\n",
        "model_simple_c.add(BatchNormalization())\n",
        "model_simple_c.add(Activation(\"relu\"))\n",
        "model_simple_c.add(Dropout(0.5))\n",
        "\n",
        "# 3rd Conv layer\n",
        "model_simple_c.add(Conv2D(128, (2, 2), padding = \"same\", strides = (2, 2)))\n",
        "model_simple_c.add(BatchNormalization())\n",
        "model_simple_c.add(Activation(\"relu\"))\n",
        "model_simple_c.add(Dropout(0.5))\n",
        "model_simple_c.add(MaxPool2D(2, 2))\n",
        "\n",
        "# Dense layer\n",
        "model_simple_c.add(Flatten())\n",
        "model_simple_c.add(Dense(256))\n",
        "model_simple_c.add(Activation(\"relu\"))\n",
        "model_simple_c.add(Dropout(0.6))\n",
        "model_simple_c.add(Dense(512))\n",
        "model_simple_c.add(Activation(\"relu\"))\n",
        "model_simple_c.add(Dropout(0.3))\n",
        "model_simple_c.add(Dense(1))\n",
        "model_simple_c.add(Activation(\"sigmoid\"))\n",
        "\n",
        "model_simple_c.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ummjdK9d1_NS",
        "outputId": "9305c8f8-12c6-4890-c1e4-ac9b45b35b56"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 20, 20, 32)        1824      \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 20, 20, 32)       128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " activation (Activation)     (None, 20, 20, 32)        0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 20, 20, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 20, 20, 64)        32832     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 20, 20, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 20, 20, 64)        0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 20, 20, 64)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 10, 10, 128)       32896     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 10, 10, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 10, 10, 128)       0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 10, 10, 128)       0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 5, 5, 128)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 3200)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               819456    \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 512)               131584    \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 513       \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,020,001\n",
            "Trainable params: 1,019,553\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load base model\n",
        "base_model = load_model(\"/content/drive/MyDrive/models/base_model.keras\")\n",
        "\n",
        "# Set weights from base model\n",
        "model_simple_c.set_weights(base_model.get_weights())"
      ],
      "metadata": {
        "id": "d3GbGSsD3IFp"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scheduler(epoch, lr):\n",
        "    l = 0.000001\n",
        "    if epoch > 200:\n",
        "        l = 0.00005\n",
        "    if epoch > 400:\n",
        "        l = 0.000015\n",
        "    if epoch > 600:\n",
        "        l = 0.000001\n",
        "    if epoch > 700:\n",
        "        l = 0.000025\n",
        "    if epoch > 850:\n",
        "        l = 0.00004\n",
        "\n",
        "    return l"
      ],
      "metadata": {
        "id": "8Hii6LMv2QtI"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callback = LearningRateScheduler(scheduler, verbose = 1)"
      ],
      "metadata": {
        "id": "UThQBxeG2VgP"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optim_simple_c = optimizers.Adam()"
      ],
      "metadata": {
        "id": "dugN4__a2bfg"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_simple_c.compile(optimizer = optim_simple_c,\n",
        "                     loss = \"binary_crossentropy\",\n",
        "                     metrics = [\"acc\"])"
      ],
      "metadata": {
        "id": "Wy2F-T9C2gao"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_simple_c = model_simple_c.fit(X_train,\n",
        "                                  y_train,\n",
        "                                  validation_data = (X_val, y_val),\n",
        "                                  callbacks = [callback],\n",
        "                                  epochs = 300,\n",
        "                                  batch_size = 256)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCLd3Gfc2hWz",
        "outputId": "7c5eb6ec-07b0-410d-baf5-1de202df0eff"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 1/300\n",
            "10/10 [==============================] - 14s 74ms/step - loss: 0.4771 - acc: 0.7689 - val_loss: 0.4405 - val_acc: 0.7801 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 2/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4720 - acc: 0.7597 - val_loss: 0.4418 - val_acc: 0.7801 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 3/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4719 - acc: 0.7609 - val_loss: 0.4435 - val_acc: 0.7788 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 4/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4712 - acc: 0.7665 - val_loss: 0.4450 - val_acc: 0.7749 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 5/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4563 - acc: 0.7777 - val_loss: 0.4467 - val_acc: 0.7749 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 6/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4752 - acc: 0.7705 - val_loss: 0.4487 - val_acc: 0.7749 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 7/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4674 - acc: 0.7717 - val_loss: 0.4505 - val_acc: 0.7724 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 8/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4788 - acc: 0.7589 - val_loss: 0.4517 - val_acc: 0.7737 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 9/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4736 - acc: 0.7689 - val_loss: 0.4529 - val_acc: 0.7724 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 10/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4714 - acc: 0.7685 - val_loss: 0.4541 - val_acc: 0.7711 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 11/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4703 - acc: 0.7645 - val_loss: 0.4555 - val_acc: 0.7660 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 12/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4664 - acc: 0.7681 - val_loss: 0.4567 - val_acc: 0.7698 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 13/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4705 - acc: 0.7649 - val_loss: 0.4574 - val_acc: 0.7685 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 14/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4669 - acc: 0.7749 - val_loss: 0.4582 - val_acc: 0.7685 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 15/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4583 - acc: 0.7689 - val_loss: 0.4592 - val_acc: 0.7685 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 16: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 16/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4602 - acc: 0.7677 - val_loss: 0.4591 - val_acc: 0.7685 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 17: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 17/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4560 - acc: 0.7705 - val_loss: 0.4590 - val_acc: 0.7685 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 18: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 18/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4525 - acc: 0.7733 - val_loss: 0.4591 - val_acc: 0.7685 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 19: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 19/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4591 - acc: 0.7617 - val_loss: 0.4597 - val_acc: 0.7685 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 20: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 20/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4732 - acc: 0.7701 - val_loss: 0.4601 - val_acc: 0.7685 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 21: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 21/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4704 - acc: 0.7653 - val_loss: 0.4599 - val_acc: 0.7685 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 22: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 22/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4712 - acc: 0.7641 - val_loss: 0.4595 - val_acc: 0.7685 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 23: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 23/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4659 - acc: 0.7677 - val_loss: 0.4598 - val_acc: 0.7685 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 24: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 24/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4673 - acc: 0.7701 - val_loss: 0.4597 - val_acc: 0.7685 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 25: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 25/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4611 - acc: 0.7765 - val_loss: 0.4595 - val_acc: 0.7698 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 26: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 26/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4641 - acc: 0.7665 - val_loss: 0.4598 - val_acc: 0.7698 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 27: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 27/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4559 - acc: 0.7725 - val_loss: 0.4593 - val_acc: 0.7698 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 28: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 28/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4624 - acc: 0.7717 - val_loss: 0.4593 - val_acc: 0.7698 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 29: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 29/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4626 - acc: 0.7709 - val_loss: 0.4590 - val_acc: 0.7685 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 30: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 30/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4580 - acc: 0.7717 - val_loss: 0.4593 - val_acc: 0.7685 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 31: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 31/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4649 - acc: 0.7709 - val_loss: 0.4586 - val_acc: 0.7685 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 32: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 32/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4682 - acc: 0.7773 - val_loss: 0.4583 - val_acc: 0.7685 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 33: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 33/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4700 - acc: 0.7669 - val_loss: 0.4576 - val_acc: 0.7660 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 34: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 34/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4668 - acc: 0.7781 - val_loss: 0.4577 - val_acc: 0.7660 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 35: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 35/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4655 - acc: 0.7709 - val_loss: 0.4583 - val_acc: 0.7673 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 36: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 36/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4648 - acc: 0.7677 - val_loss: 0.4584 - val_acc: 0.7673 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 37: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 37/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4665 - acc: 0.7729 - val_loss: 0.4573 - val_acc: 0.7647 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 38: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 38/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4570 - acc: 0.7733 - val_loss: 0.4572 - val_acc: 0.7660 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 39: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 39/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4712 - acc: 0.7665 - val_loss: 0.4572 - val_acc: 0.7660 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 40: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 40/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4666 - acc: 0.7741 - val_loss: 0.4568 - val_acc: 0.7660 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 41: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 41/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4657 - acc: 0.7617 - val_loss: 0.4565 - val_acc: 0.7660 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 42: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 42/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4719 - acc: 0.7669 - val_loss: 0.4565 - val_acc: 0.7660 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 43: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 43/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4624 - acc: 0.7649 - val_loss: 0.4556 - val_acc: 0.7660 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 44: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 44/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4607 - acc: 0.7657 - val_loss: 0.4557 - val_acc: 0.7660 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 45: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 45/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4497 - acc: 0.7693 - val_loss: 0.4560 - val_acc: 0.7660 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 46: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 46/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4709 - acc: 0.7669 - val_loss: 0.4557 - val_acc: 0.7660 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 47: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 47/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4600 - acc: 0.7753 - val_loss: 0.4555 - val_acc: 0.7660 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 48: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 48/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4756 - acc: 0.7681 - val_loss: 0.4553 - val_acc: 0.7660 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 49: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 49/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4699 - acc: 0.7641 - val_loss: 0.4553 - val_acc: 0.7673 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 50: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 50/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4692 - acc: 0.7589 - val_loss: 0.4553 - val_acc: 0.7673 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 51: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 51/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4636 - acc: 0.7689 - val_loss: 0.4555 - val_acc: 0.7660 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 52: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 52/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4630 - acc: 0.7673 - val_loss: 0.4552 - val_acc: 0.7673 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 53: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 53/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4580 - acc: 0.7749 - val_loss: 0.4555 - val_acc: 0.7660 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 54: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 54/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4676 - acc: 0.7629 - val_loss: 0.4558 - val_acc: 0.7660 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 55: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 55/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4609 - acc: 0.7645 - val_loss: 0.4558 - val_acc: 0.7660 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 56: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 56/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4610 - acc: 0.7693 - val_loss: 0.4561 - val_acc: 0.7660 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 57: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 57/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4606 - acc: 0.7745 - val_loss: 0.4560 - val_acc: 0.7660 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 58: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 58/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4670 - acc: 0.7649 - val_loss: 0.4563 - val_acc: 0.7660 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 59: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 59/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4635 - acc: 0.7749 - val_loss: 0.4565 - val_acc: 0.7660 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 60: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 60/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4739 - acc: 0.7641 - val_loss: 0.4560 - val_acc: 0.7673 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 61: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 61/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4598 - acc: 0.7685 - val_loss: 0.4559 - val_acc: 0.7673 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 62: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 62/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4641 - acc: 0.7649 - val_loss: 0.4552 - val_acc: 0.7673 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 63: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 63/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4652 - acc: 0.7669 - val_loss: 0.4551 - val_acc: 0.7673 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 64: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 64/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4658 - acc: 0.7693 - val_loss: 0.4545 - val_acc: 0.7685 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 65: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 65/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4767 - acc: 0.7705 - val_loss: 0.4546 - val_acc: 0.7685 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 66: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 66/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4697 - acc: 0.7669 - val_loss: 0.4554 - val_acc: 0.7673 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 67: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 67/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4655 - acc: 0.7673 - val_loss: 0.4558 - val_acc: 0.7673 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 68: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 68/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4597 - acc: 0.7741 - val_loss: 0.4562 - val_acc: 0.7673 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 69: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 69/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4626 - acc: 0.7729 - val_loss: 0.4568 - val_acc: 0.7673 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 70: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 70/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4561 - acc: 0.7793 - val_loss: 0.4569 - val_acc: 0.7660 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 71: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 71/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4570 - acc: 0.7669 - val_loss: 0.4568 - val_acc: 0.7660 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 72: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 72/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4661 - acc: 0.7685 - val_loss: 0.4564 - val_acc: 0.7685 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 73: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 73/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4585 - acc: 0.7737 - val_loss: 0.4558 - val_acc: 0.7685 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 74: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 74/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4521 - acc: 0.7729 - val_loss: 0.4557 - val_acc: 0.7685 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 75: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 75/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4508 - acc: 0.7745 - val_loss: 0.4553 - val_acc: 0.7685 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 76: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 76/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4565 - acc: 0.7681 - val_loss: 0.4549 - val_acc: 0.7685 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 77: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 77/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4653 - acc: 0.7673 - val_loss: 0.4545 - val_acc: 0.7685 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 78: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 78/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4580 - acc: 0.7681 - val_loss: 0.4541 - val_acc: 0.7698 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 79: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 79/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4639 - acc: 0.7601 - val_loss: 0.4542 - val_acc: 0.7698 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 80: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 80/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4705 - acc: 0.7761 - val_loss: 0.4543 - val_acc: 0.7711 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 81: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 81/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4552 - acc: 0.7709 - val_loss: 0.4548 - val_acc: 0.7711 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 82: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 82/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4636 - acc: 0.7705 - val_loss: 0.4550 - val_acc: 0.7711 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 83: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 83/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4714 - acc: 0.7633 - val_loss: 0.4555 - val_acc: 0.7711 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 84: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 84/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4662 - acc: 0.7769 - val_loss: 0.4556 - val_acc: 0.7711 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 85: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 85/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4471 - acc: 0.7757 - val_loss: 0.4553 - val_acc: 0.7711 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 86: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 86/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4633 - acc: 0.7681 - val_loss: 0.4548 - val_acc: 0.7711 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 87: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 87/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4611 - acc: 0.7709 - val_loss: 0.4548 - val_acc: 0.7711 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 88: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 88/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4591 - acc: 0.7749 - val_loss: 0.4547 - val_acc: 0.7711 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 89: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 89/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4653 - acc: 0.7665 - val_loss: 0.4548 - val_acc: 0.7711 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 90: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 90/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4609 - acc: 0.7609 - val_loss: 0.4551 - val_acc: 0.7711 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 91: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 91/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4510 - acc: 0.7821 - val_loss: 0.4552 - val_acc: 0.7711 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 92: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 92/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4530 - acc: 0.7653 - val_loss: 0.4557 - val_acc: 0.7698 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 93: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 93/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4467 - acc: 0.7757 - val_loss: 0.4559 - val_acc: 0.7698 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 94: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 94/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4622 - acc: 0.7609 - val_loss: 0.4558 - val_acc: 0.7698 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 95: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 95/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4517 - acc: 0.7741 - val_loss: 0.4557 - val_acc: 0.7698 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 96: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 96/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4541 - acc: 0.7673 - val_loss: 0.4559 - val_acc: 0.7698 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 97: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 97/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4657 - acc: 0.7621 - val_loss: 0.4558 - val_acc: 0.7698 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 98: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 98/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4564 - acc: 0.7621 - val_loss: 0.4560 - val_acc: 0.7698 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 99: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 99/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4342 - acc: 0.7857 - val_loss: 0.4564 - val_acc: 0.7698 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 100: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 100/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4655 - acc: 0.7729 - val_loss: 0.4563 - val_acc: 0.7698 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 101: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 101/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4560 - acc: 0.7681 - val_loss: 0.4560 - val_acc: 0.7711 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 102: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 102/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4511 - acc: 0.7681 - val_loss: 0.4564 - val_acc: 0.7711 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 103: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 103/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4550 - acc: 0.7649 - val_loss: 0.4559 - val_acc: 0.7711 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 104: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 104/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4626 - acc: 0.7597 - val_loss: 0.4569 - val_acc: 0.7698 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 105: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 105/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4635 - acc: 0.7581 - val_loss: 0.4566 - val_acc: 0.7698 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 106: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 106/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4647 - acc: 0.7681 - val_loss: 0.4567 - val_acc: 0.7698 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 107: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 107/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4671 - acc: 0.7645 - val_loss: 0.4564 - val_acc: 0.7698 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 108: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 108/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4551 - acc: 0.7665 - val_loss: 0.4570 - val_acc: 0.7685 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 109: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 109/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4557 - acc: 0.7637 - val_loss: 0.4574 - val_acc: 0.7673 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 110: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 110/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4759 - acc: 0.7721 - val_loss: 0.4575 - val_acc: 0.7673 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 111: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 111/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4546 - acc: 0.7737 - val_loss: 0.4575 - val_acc: 0.7673 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 112: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 112/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4459 - acc: 0.7697 - val_loss: 0.4578 - val_acc: 0.7673 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 113: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 113/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4574 - acc: 0.7729 - val_loss: 0.4585 - val_acc: 0.7673 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 114: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 114/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4584 - acc: 0.7649 - val_loss: 0.4586 - val_acc: 0.7673 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 115: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 115/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4564 - acc: 0.7685 - val_loss: 0.4583 - val_acc: 0.7673 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 116: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 116/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4592 - acc: 0.7777 - val_loss: 0.4581 - val_acc: 0.7673 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 117: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 117/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4624 - acc: 0.7721 - val_loss: 0.4578 - val_acc: 0.7673 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 118: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 118/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4530 - acc: 0.7733 - val_loss: 0.4573 - val_acc: 0.7685 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 119: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 119/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4566 - acc: 0.7689 - val_loss: 0.4571 - val_acc: 0.7685 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 120: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 120/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4582 - acc: 0.7705 - val_loss: 0.4572 - val_acc: 0.7685 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 121: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 121/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4605 - acc: 0.7629 - val_loss: 0.4567 - val_acc: 0.7685 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 122: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 122/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4613 - acc: 0.7717 - val_loss: 0.4566 - val_acc: 0.7685 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 123: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 123/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4645 - acc: 0.7597 - val_loss: 0.4568 - val_acc: 0.7685 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 124: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 124/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4701 - acc: 0.7609 - val_loss: 0.4561 - val_acc: 0.7698 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 125: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 125/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4494 - acc: 0.7749 - val_loss: 0.4555 - val_acc: 0.7711 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 126: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 126/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4541 - acc: 0.7665 - val_loss: 0.4556 - val_acc: 0.7711 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 127: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 127/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4641 - acc: 0.7721 - val_loss: 0.4555 - val_acc: 0.7711 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 128: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 128/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4687 - acc: 0.7641 - val_loss: 0.4557 - val_acc: 0.7711 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 129: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 129/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4614 - acc: 0.7693 - val_loss: 0.4555 - val_acc: 0.7724 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 130: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 130/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4527 - acc: 0.7725 - val_loss: 0.4557 - val_acc: 0.7711 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 131: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 131/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4564 - acc: 0.7645 - val_loss: 0.4560 - val_acc: 0.7711 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 132: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 132/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4572 - acc: 0.7605 - val_loss: 0.4560 - val_acc: 0.7711 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 133: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 133/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4611 - acc: 0.7693 - val_loss: 0.4558 - val_acc: 0.7711 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 134: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 134/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4577 - acc: 0.7733 - val_loss: 0.4551 - val_acc: 0.7724 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 135: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 135/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4618 - acc: 0.7649 - val_loss: 0.4552 - val_acc: 0.7724 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 136: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 136/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4588 - acc: 0.7745 - val_loss: 0.4552 - val_acc: 0.7711 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 137: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 137/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4672 - acc: 0.7725 - val_loss: 0.4552 - val_acc: 0.7711 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 138: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 138/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4570 - acc: 0.7657 - val_loss: 0.4551 - val_acc: 0.7724 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 139: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 139/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4680 - acc: 0.7661 - val_loss: 0.4555 - val_acc: 0.7711 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 140: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 140/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4536 - acc: 0.7657 - val_loss: 0.4561 - val_acc: 0.7698 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 141: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 141/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4547 - acc: 0.7689 - val_loss: 0.4568 - val_acc: 0.7673 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 142: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 142/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4552 - acc: 0.7773 - val_loss: 0.4570 - val_acc: 0.7673 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 143: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 143/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4591 - acc: 0.7721 - val_loss: 0.4567 - val_acc: 0.7685 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 144: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 144/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4669 - acc: 0.7689 - val_loss: 0.4562 - val_acc: 0.7698 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 145: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 145/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4663 - acc: 0.7717 - val_loss: 0.4561 - val_acc: 0.7724 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 146: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 146/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4574 - acc: 0.7749 - val_loss: 0.4557 - val_acc: 0.7724 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 147: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 147/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4599 - acc: 0.7765 - val_loss: 0.4557 - val_acc: 0.7724 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 148: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 148/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4624 - acc: 0.7685 - val_loss: 0.4561 - val_acc: 0.7724 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 149: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 149/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4641 - acc: 0.7673 - val_loss: 0.4559 - val_acc: 0.7724 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 150: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 150/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4532 - acc: 0.7725 - val_loss: 0.4556 - val_acc: 0.7724 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 151: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 151/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4477 - acc: 0.7729 - val_loss: 0.4555 - val_acc: 0.7711 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 152: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 152/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4558 - acc: 0.7737 - val_loss: 0.4555 - val_acc: 0.7711 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 153: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 153/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4584 - acc: 0.7745 - val_loss: 0.4554 - val_acc: 0.7724 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 154: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 154/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4588 - acc: 0.7653 - val_loss: 0.4559 - val_acc: 0.7711 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 155: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 155/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4526 - acc: 0.7745 - val_loss: 0.4561 - val_acc: 0.7711 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 156: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 156/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4464 - acc: 0.7693 - val_loss: 0.4561 - val_acc: 0.7711 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 157: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 157/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4585 - acc: 0.7741 - val_loss: 0.4566 - val_acc: 0.7711 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 158: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 158/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4671 - acc: 0.7601 - val_loss: 0.4569 - val_acc: 0.7711 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 159: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 159/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4574 - acc: 0.7685 - val_loss: 0.4564 - val_acc: 0.7724 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 160: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 160/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4481 - acc: 0.7733 - val_loss: 0.4563 - val_acc: 0.7724 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 161: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 161/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4507 - acc: 0.7781 - val_loss: 0.4562 - val_acc: 0.7724 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 162: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 162/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4472 - acc: 0.7741 - val_loss: 0.4566 - val_acc: 0.7711 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 163: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 163/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4552 - acc: 0.7709 - val_loss: 0.4570 - val_acc: 0.7685 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 164: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 164/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4502 - acc: 0.7761 - val_loss: 0.4577 - val_acc: 0.7673 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 165: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 165/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4600 - acc: 0.7681 - val_loss: 0.4581 - val_acc: 0.7673 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 166: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 166/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4620 - acc: 0.7633 - val_loss: 0.4580 - val_acc: 0.7673 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 167: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 167/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4567 - acc: 0.7653 - val_loss: 0.4584 - val_acc: 0.7673 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 168: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 168/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4557 - acc: 0.7633 - val_loss: 0.4583 - val_acc: 0.7673 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 169: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 169/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4618 - acc: 0.7681 - val_loss: 0.4577 - val_acc: 0.7673 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 170: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 170/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4566 - acc: 0.7693 - val_loss: 0.4573 - val_acc: 0.7685 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 171: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 171/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4579 - acc: 0.7677 - val_loss: 0.4568 - val_acc: 0.7724 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 172: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 172/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4465 - acc: 0.7725 - val_loss: 0.4568 - val_acc: 0.7724 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 173: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 173/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4492 - acc: 0.7721 - val_loss: 0.4565 - val_acc: 0.7724 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 174: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 174/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4628 - acc: 0.7645 - val_loss: 0.4559 - val_acc: 0.7737 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 175: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 175/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4688 - acc: 0.7677 - val_loss: 0.4561 - val_acc: 0.7737 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 176: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 176/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4621 - acc: 0.7685 - val_loss: 0.4559 - val_acc: 0.7737 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 177: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 177/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4536 - acc: 0.7725 - val_loss: 0.4561 - val_acc: 0.7724 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 178: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 178/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4613 - acc: 0.7629 - val_loss: 0.4566 - val_acc: 0.7711 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 179: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 179/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4490 - acc: 0.7681 - val_loss: 0.4564 - val_acc: 0.7724 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 180: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 180/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4500 - acc: 0.7721 - val_loss: 0.4566 - val_acc: 0.7724 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 181: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 181/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4588 - acc: 0.7657 - val_loss: 0.4576 - val_acc: 0.7673 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 182: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 182/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4557 - acc: 0.7761 - val_loss: 0.4580 - val_acc: 0.7673 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 183: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 183/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4528 - acc: 0.7717 - val_loss: 0.4579 - val_acc: 0.7673 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 184: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 184/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4522 - acc: 0.7605 - val_loss: 0.4577 - val_acc: 0.7673 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 185: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 185/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4497 - acc: 0.7693 - val_loss: 0.4573 - val_acc: 0.7673 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 186: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 186/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4551 - acc: 0.7689 - val_loss: 0.4576 - val_acc: 0.7673 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 187: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 187/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4575 - acc: 0.7725 - val_loss: 0.4575 - val_acc: 0.7685 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 188: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 188/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4630 - acc: 0.7581 - val_loss: 0.4578 - val_acc: 0.7685 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 189: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 189/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4501 - acc: 0.7689 - val_loss: 0.4575 - val_acc: 0.7685 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 190: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 190/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4531 - acc: 0.7673 - val_loss: 0.4572 - val_acc: 0.7711 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 191: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 191/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4519 - acc: 0.7669 - val_loss: 0.4570 - val_acc: 0.7724 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 192: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 192/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4474 - acc: 0.7761 - val_loss: 0.4570 - val_acc: 0.7724 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 193: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 193/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4463 - acc: 0.7765 - val_loss: 0.4571 - val_acc: 0.7698 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 194: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 194/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4716 - acc: 0.7625 - val_loss: 0.4565 - val_acc: 0.7737 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 195: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 195/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4621 - acc: 0.7717 - val_loss: 0.4564 - val_acc: 0.7724 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 196: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 196/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4566 - acc: 0.7761 - val_loss: 0.4572 - val_acc: 0.7711 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 197: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 197/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4408 - acc: 0.7789 - val_loss: 0.4574 - val_acc: 0.7685 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 198: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 198/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4633 - acc: 0.7649 - val_loss: 0.4575 - val_acc: 0.7685 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 199: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 199/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4542 - acc: 0.7725 - val_loss: 0.4579 - val_acc: 0.7673 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 200: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 200/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4625 - acc: 0.7661 - val_loss: 0.4575 - val_acc: 0.7711 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 201: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 201/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4619 - acc: 0.7673 - val_loss: 0.4578 - val_acc: 0.7685 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 202: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 202/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4565 - acc: 0.7693 - val_loss: 0.4630 - val_acc: 0.7673 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 203: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 203/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4465 - acc: 0.7717 - val_loss: 0.4561 - val_acc: 0.7724 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 204: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 204/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4506 - acc: 0.7677 - val_loss: 0.4660 - val_acc: 0.7711 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 205: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 205/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4593 - acc: 0.7705 - val_loss: 0.4708 - val_acc: 0.7711 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 206: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 206/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4610 - acc: 0.7613 - val_loss: 0.4929 - val_acc: 0.7532 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 207: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 207/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4546 - acc: 0.7685 - val_loss: 0.4751 - val_acc: 0.7609 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 208: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 208/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4537 - acc: 0.7733 - val_loss: 0.4745 - val_acc: 0.7609 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 209: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 209/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4524 - acc: 0.7721 - val_loss: 0.4652 - val_acc: 0.7724 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 210: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 210/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4550 - acc: 0.7557 - val_loss: 0.4770 - val_acc: 0.7660 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 211: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 211/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4641 - acc: 0.7621 - val_loss: 0.4680 - val_acc: 0.7711 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 212: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 212/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4425 - acc: 0.7753 - val_loss: 0.4539 - val_acc: 0.7775 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 213: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 213/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4539 - acc: 0.7697 - val_loss: 0.4619 - val_acc: 0.7749 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 214: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 214/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4426 - acc: 0.7737 - val_loss: 0.4564 - val_acc: 0.7698 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 215: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 215/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4472 - acc: 0.7705 - val_loss: 0.4603 - val_acc: 0.7685 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 216: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 216/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4507 - acc: 0.7705 - val_loss: 0.4717 - val_acc: 0.7660 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 217: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 217/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4475 - acc: 0.7669 - val_loss: 0.4636 - val_acc: 0.7660 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 218: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 218/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4428 - acc: 0.7733 - val_loss: 0.4713 - val_acc: 0.7685 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 219: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 219/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4526 - acc: 0.7689 - val_loss: 0.4544 - val_acc: 0.7685 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 220: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 220/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4392 - acc: 0.7733 - val_loss: 0.4652 - val_acc: 0.7660 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 221: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 221/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4422 - acc: 0.7689 - val_loss: 0.4487 - val_acc: 0.7698 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 222: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 222/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4318 - acc: 0.7761 - val_loss: 0.4483 - val_acc: 0.7698 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 223: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 223/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4371 - acc: 0.7757 - val_loss: 0.4532 - val_acc: 0.7749 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 224: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 224/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4397 - acc: 0.7709 - val_loss: 0.4496 - val_acc: 0.7737 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 225: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 225/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4447 - acc: 0.7705 - val_loss: 0.4493 - val_acc: 0.7801 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 226: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 226/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4526 - acc: 0.7737 - val_loss: 0.4515 - val_acc: 0.7698 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 227: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 227/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4472 - acc: 0.7677 - val_loss: 0.4567 - val_acc: 0.7685 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 228: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 228/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4371 - acc: 0.7717 - val_loss: 0.4566 - val_acc: 0.7698 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 229: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 229/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4389 - acc: 0.7769 - val_loss: 0.4536 - val_acc: 0.7647 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 230: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 230/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4439 - acc: 0.7665 - val_loss: 0.4521 - val_acc: 0.7634 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 231: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 231/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4434 - acc: 0.7677 - val_loss: 0.4557 - val_acc: 0.7583 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 232: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 232/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4520 - acc: 0.7669 - val_loss: 0.4473 - val_acc: 0.7737 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 233: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 233/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4546 - acc: 0.7689 - val_loss: 0.4437 - val_acc: 0.7737 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 234: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 234/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4325 - acc: 0.7685 - val_loss: 0.4450 - val_acc: 0.7788 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 235: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 235/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4306 - acc: 0.7701 - val_loss: 0.4545 - val_acc: 0.7673 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 236: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 236/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4364 - acc: 0.7809 - val_loss: 0.4438 - val_acc: 0.7596 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 237: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 237/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4338 - acc: 0.7725 - val_loss: 0.4459 - val_acc: 0.7737 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 238: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 238/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4335 - acc: 0.7689 - val_loss: 0.4484 - val_acc: 0.7749 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 239: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 239/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4311 - acc: 0.7737 - val_loss: 0.4440 - val_acc: 0.7673 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 240: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 240/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4293 - acc: 0.7713 - val_loss: 0.4504 - val_acc: 0.7711 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 241: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 241/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4460 - acc: 0.7689 - val_loss: 0.4425 - val_acc: 0.7673 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 242: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 242/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4397 - acc: 0.7773 - val_loss: 0.4428 - val_acc: 0.7660 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 243: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 243/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4319 - acc: 0.7769 - val_loss: 0.4567 - val_acc: 0.7685 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 244: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 244/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4307 - acc: 0.7837 - val_loss: 0.4450 - val_acc: 0.7660 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 245: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 245/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4362 - acc: 0.7809 - val_loss: 0.4481 - val_acc: 0.7660 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 246: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 246/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4293 - acc: 0.7841 - val_loss: 0.4474 - val_acc: 0.7673 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 247: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 247/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4318 - acc: 0.7753 - val_loss: 0.4471 - val_acc: 0.7698 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 248: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 248/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4340 - acc: 0.7777 - val_loss: 0.4510 - val_acc: 0.7621 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 249: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 249/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4364 - acc: 0.7641 - val_loss: 0.4487 - val_acc: 0.7621 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 250: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 250/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4348 - acc: 0.7729 - val_loss: 0.4499 - val_acc: 0.7570 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 251: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 251/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4348 - acc: 0.7753 - val_loss: 0.4451 - val_acc: 0.7673 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 252: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 252/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4352 - acc: 0.7625 - val_loss: 0.4513 - val_acc: 0.7647 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 253: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 253/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4327 - acc: 0.7713 - val_loss: 0.4535 - val_acc: 0.7647 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 254: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 254/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4397 - acc: 0.7777 - val_loss: 0.4600 - val_acc: 0.7647 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 255: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 255/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4179 - acc: 0.7789 - val_loss: 0.4541 - val_acc: 0.7647 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 256: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 256/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4395 - acc: 0.7653 - val_loss: 0.4561 - val_acc: 0.7673 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 257: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 257/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4325 - acc: 0.7625 - val_loss: 0.4802 - val_acc: 0.7519 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 258: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 258/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4315 - acc: 0.7745 - val_loss: 0.4770 - val_acc: 0.7545 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 259: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 259/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4295 - acc: 0.7757 - val_loss: 0.4569 - val_acc: 0.7634 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 260: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 260/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4239 - acc: 0.7777 - val_loss: 0.4608 - val_acc: 0.7621 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 261: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 261/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4366 - acc: 0.7769 - val_loss: 0.4510 - val_acc: 0.7583 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 262: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 262/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4289 - acc: 0.7773 - val_loss: 0.4724 - val_acc: 0.7545 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 263: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 263/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4323 - acc: 0.7825 - val_loss: 0.4647 - val_acc: 0.7545 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 264: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 264/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4316 - acc: 0.7789 - val_loss: 0.4446 - val_acc: 0.7711 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 265: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 265/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4293 - acc: 0.7717 - val_loss: 0.4529 - val_acc: 0.7634 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 266: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 266/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4181 - acc: 0.7749 - val_loss: 0.4592 - val_acc: 0.7660 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 267: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 267/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4186 - acc: 0.7833 - val_loss: 0.4563 - val_acc: 0.7609 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 268: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 268/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4274 - acc: 0.7781 - val_loss: 0.4479 - val_acc: 0.7609 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 269: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 269/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4307 - acc: 0.7753 - val_loss: 0.4515 - val_acc: 0.7673 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 270: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 270/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4225 - acc: 0.7809 - val_loss: 0.4566 - val_acc: 0.7570 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 271: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 271/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4328 - acc: 0.7713 - val_loss: 0.4744 - val_acc: 0.7570 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 272: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 272/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4225 - acc: 0.7725 - val_loss: 0.4494 - val_acc: 0.7660 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 273: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 273/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4308 - acc: 0.7709 - val_loss: 0.4488 - val_acc: 0.7583 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 274: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 274/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4231 - acc: 0.7829 - val_loss: 0.4616 - val_acc: 0.7621 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 275: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 275/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4205 - acc: 0.7781 - val_loss: 0.4592 - val_acc: 0.7609 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 276: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 276/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4266 - acc: 0.7773 - val_loss: 0.4522 - val_acc: 0.7634 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 277: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 277/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4303 - acc: 0.7809 - val_loss: 0.4575 - val_acc: 0.7647 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 278: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 278/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4237 - acc: 0.7781 - val_loss: 0.4639 - val_acc: 0.7609 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 279: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 279/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4235 - acc: 0.7797 - val_loss: 0.4986 - val_acc: 0.7570 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 280: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 280/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4179 - acc: 0.7789 - val_loss: 0.4723 - val_acc: 0.7570 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 281: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 281/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4246 - acc: 0.7789 - val_loss: 0.4521 - val_acc: 0.7570 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 282: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 282/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4263 - acc: 0.7805 - val_loss: 0.4616 - val_acc: 0.7647 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 283: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 283/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4274 - acc: 0.7781 - val_loss: 0.4483 - val_acc: 0.7609 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 284: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 284/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4262 - acc: 0.7745 - val_loss: 0.4493 - val_acc: 0.7609 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 285: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 285/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4182 - acc: 0.7789 - val_loss: 0.4592 - val_acc: 0.7647 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 286: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 286/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4146 - acc: 0.7885 - val_loss: 0.4952 - val_acc: 0.7558 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 287: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 287/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4263 - acc: 0.7805 - val_loss: 0.4540 - val_acc: 0.7519 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 288: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 288/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4216 - acc: 0.7797 - val_loss: 0.4596 - val_acc: 0.7634 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 289: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 289/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4180 - acc: 0.7777 - val_loss: 0.4635 - val_acc: 0.7621 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 290: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 290/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4171 - acc: 0.7885 - val_loss: 0.4607 - val_acc: 0.7609 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 291: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 291/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4220 - acc: 0.7769 - val_loss: 0.4593 - val_acc: 0.7532 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 292: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 292/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4216 - acc: 0.7685 - val_loss: 0.4597 - val_acc: 0.7621 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 293: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 293/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4126 - acc: 0.7853 - val_loss: 0.4576 - val_acc: 0.7634 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 294: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 294/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4170 - acc: 0.7761 - val_loss: 0.4551 - val_acc: 0.7545 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 295: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 295/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4214 - acc: 0.7793 - val_loss: 0.4524 - val_acc: 0.7609 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 296: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 296/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4078 - acc: 0.7805 - val_loss: 0.4506 - val_acc: 0.7596 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 297: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 297/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4142 - acc: 0.7857 - val_loss: 0.4558 - val_acc: 0.7647 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 298: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 298/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4216 - acc: 0.7789 - val_loss: 0.4720 - val_acc: 0.7570 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 299: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 299/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4210 - acc: 0.7785 - val_loss: 0.4615 - val_acc: 0.7455 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 300: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 300/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4069 - acc: 0.7937 - val_loss: 0.4569 - val_acc: 0.7558 - lr: 5.0000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The red line in the following plots represents the performance of the model after implementing the new learning schedule."
      ],
      "metadata": {
        "id": "EsVOPTgQp-9O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load history from base model\n",
        "with open(\"/content/drive/MyDrive/models/base_model_history\", \"rb\") as file_pi:\n",
        "    base_model_history = pickle.load(file_pi)\n",
        "\n",
        "# Append data from fine tuning history\n",
        "for key in base_model_history.keys():\n",
        "    for i in range(0, len(history_simple_c.history[key])):\n",
        "        value = history_simple_c.history[key][i]\n",
        "        base_model_history[key].append(value)\n",
        "\n",
        "# list all data in_simple_c\n",
        "print(base_model_history.keys())\n",
        "# summarize base_model for accuracy\n",
        "plt.plot(base_model_history['acc'])\n",
        "plt.plot(base_model_history['val_acc'])\n",
        "plt.axvline(x = 1000, color = \"r\")\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize base_model for loss\n",
        "plt.plot(base_model_history['loss'])\n",
        "plt.plot(base_model_history['val_loss'])\n",
        "plt.axvline(x = 1000, color = \"r\")\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 945
        },
        "id": "7Q_UUA_L2mwA",
        "outputId": "da9f0cce-faea-4724-cccf-2820add76418"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'acc', 'val_loss', 'val_acc', 'lr'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_simple_c.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJzbc3vYyYxe",
        "outputId": "eacf6a2d-0979-478d-fdaa-9ca85e94bef9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4032 - acc: 0.8051\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4032142758369446, 0.805111825466156]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# See predictions by class\n",
        "model_simple_c_pred = model_simple_c.predict(X_test, batch_size = 64)\n",
        "\n",
        "print(classification_report(y_test, np.where(model_simple_c_pred > 0.5, 1, 0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7gfmIRg0A2K",
        "outputId": "7c65711d-00a0-4be5-a007-bf57323f2b19"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 0s 8ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.72      0.79       323\n",
            "           1       0.75      0.89      0.82       303\n",
            "\n",
            "    accuracy                           0.81       626\n",
            "   macro avg       0.81      0.81      0.80       626\n",
            "weighted avg       0.82      0.81      0.80       626\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model with 81% accuracy\n",
        "model_simple_c.save(\"/content/drive/MyDrive/models/model_81acc.keras\")\n",
        "\n",
        "# Save history of model with 81% accuracy\n",
        "with open('/content/drive/MyDrive/models/model_81acc_history', 'wb') as file_pi:\n",
        "    pickle.dump(base_model_history, file_pi)"
      ],
      "metadata": {
        "id": "PudlFYrvnxpK"
      },
      "execution_count": 27,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}