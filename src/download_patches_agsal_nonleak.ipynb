{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patch download - AgSal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils\n",
    "import os\n",
    "import requests\n",
    "import winsound\n",
    "import math\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "from datetime import timedelta, datetime\n",
    "\n",
    "# Google Earth Engine\n",
    "import ee\n",
    "\n",
    "# Download, utils and LST classes\n",
    "from src_download import  ee_download, ee_utils, ee_LST\n",
    "ee_dwld = ee_download()\n",
    "ee_utils = ee_utils()\n",
    "ee_LST = ee_LST()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enviromental variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT_PATH = \"../data\"\n",
    "LEAKS_46 = DATA_ROOT_PATH + \"/raw/agsal_46.xlsx\"\n",
    "LEAKS_49 = DATA_ROOT_PATH + \"/raw/agsal_49.xlsx\"\n",
    "SAVE_CLEAN_DATA = DATA_ROOT_PATH + \"/clean\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get image from image collection\n",
    "def get_image(start, end, poi_leak):\n",
    "    \n",
    "    if isinstance(start, str) == False:\n",
    "        start = str(start)\n",
    "        end = str(end)\n",
    "    \n",
    "    collection = ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\")\\\n",
    "    .filterBounds(poi_leak)\\\n",
    "    .filterDate(ee.Date(start), ee.Date(end))\\\n",
    "    .sort(\"system:time_start\", opt_ascending = False)\\\n",
    "    .sort(\"CLOUDY_PIXEL_PERCENTAGE\")\n",
    "\n",
    "    img = collection.first()\n",
    "\n",
    "    print(\"Date of selected image (Sentinel): \", ee.Date(img.get(\"system:time_start\")).format(\"yyyy-MM-dd\").getInfo(),\n",
    "          \"\\nSentinel images found:\", collection.size().getInfo(),\n",
    "          \"\\nCloud %: \", img.get(\"CLOUDY_PIXEL_PERCENTAGE\").getInfo()) \n",
    "    \n",
    "    return img  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the bands to select and the patch size (radius in meters respect to leak point)\n",
    "def bands_clip_image(image, buffer_size = 100, bands = [\"B4\", \"B3\", \"B2\"]):\n",
    "    # Clip image\n",
    "    image = image.clip(poi.buffer(buffer_size).bounds(proj = \"EPSG:32613\", maxError = 0.001))\n",
    "\n",
    "    # Select bands\n",
    "    image = image.select(bands)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download patch image\n",
    "def download_image(image, path, date_label):\n",
    "\n",
    "    if os.path.exists(path + \"S2\" + \"_\" + date_label + \".zip\"):\n",
    "        print(\"S2\" + \"_\" + date_label + \".zip\" + \"already exists.\")\n",
    "    \n",
    "    else:\n",
    "        url = image.getDownloadURL(\n",
    "            {\n",
    "            \"scale\": 10,\n",
    "            \"crs\": \"EPSG:32613\",\n",
    "            \"fileFormat\": \"GeoTIFF\",\n",
    "            \"maxPixels\": 1e13\n",
    "            }\n",
    "        )\n",
    "\n",
    "        r = requests.get(url, allow_redirects = True)\n",
    "        open(path + \"S2\" + \"_\" + date_label + \".zip\", \"wb\").write(r.content)\n",
    "        print(\"Download complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_landsat_images(start, end, poi_leak, buffer_regression):\n",
    "\n",
    "    poi_regression = poi_leak.buffer(buffer_regression).bounds(proj = \"EPSG:32613\", maxError = 0.001)\n",
    " \n",
    "    try:\n",
    "\n",
    "        if isinstance(start, str) == False:\n",
    "            start = str(start)\n",
    "            end = str(end)\n",
    "        \n",
    "        selected_Landsat_collection = ee.ImageCollection(\"LANDSAT/LC08/C02/T1_L2\")\\\n",
    "                                        .filterBounds(poi_leak)\\\n",
    "                                        .filterDate(ee.Date(start), ee.Date(end))\\\n",
    "                                        .sort(\"CLOUD_COVER\")\n",
    "\n",
    "        img_landsat = selected_Landsat_collection.first().clip(poi_regression)\n",
    "\n",
    "        print(\"Date of selected image (Landsat):\", ee.Date(img_landsat.get(\"system:time_start\")).format(\"yyyy-MM-dd\").getInfo(),\n",
    "            \"\\nLandsat images found: \", selected_Landsat_collection.size().getInfo(),\n",
    "            \"\\nCloud %: \", img_landsat.get(\"CLOUD_COVER\").getInfo())\n",
    "    \n",
    "        if selected_Landsat_collection.size().getInfo() == 0:\n",
    "            print(\"THERES NO LANDSAT IMAGES FOR THE SELECTED DATES\")\n",
    "            print(\"Stopped in rep\", rep)\n",
    "\n",
    "    except:\n",
    "        start = start + timedelta(days = 5)\n",
    "\n",
    "        if isinstance(start, str) == False:\n",
    "            start = str(start)\n",
    "            end = str(end)\n",
    "\n",
    "        selected_Landsat_collection = ee.ImageCollection(\"LANDSAT/LC08/C02/T1_L2\")\\\n",
    "                                        .filterBounds(poi_leak)\\\n",
    "                                        .filterDate(ee.Date(start), ee.Date(end))\\\n",
    "                                        .sort(\"CLOUD_COVER\")\n",
    "\n",
    "        img_landsat = selected_Landsat_collection.first().clip(poi_regression)\n",
    "\n",
    "        print(\"Date of selected image (Landsat):\", ee.Date(img_landsat.get(\"system:time_start\")).format(\"yyyy-MM-dd\").getInfo(),\n",
    "            \"\\nLandsat images found: \", selected_Landsat_collection.size().getInfo(),\n",
    "            \"\\nCloud %: \", img_landsat.get(\"CLOUD_COVER\").getInfo())\n",
    "    \n",
    "        if selected_Landsat_collection.size().getInfo() == 0:\n",
    "            print(\"THERES NO LANDSAT IMAGES FOR THE SELECTED DATES\")\n",
    "\n",
    "    return img_landsat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create compund bands in order to perform linear regression\n",
    "def lst_regression(landsat_image, sentinel_image, poi_leak, buffer_size, buffer_regression = 500, error = True):\n",
    "    ndvi_landsat = landsat_image.normalizedDifference([\"SR_B5\", \"SR_B4\"]).rename(\"ndvi\")\n",
    "    ndwi_landsat = landsat_image.normalizedDifference([\"SR_B3\", \"SR_B5\"]).rename(\"ndwi\")\n",
    "    ndbi_landsat = landsat_image.normalizedDifference([\"SR_B6\", \"SR_B5\"]).rename(\"ndbi\")\n",
    "    lst_landsat_30m = landsat_image.select(\"ST_B10\").rename(\"Landsat_LST_30m\")\n",
    "\n",
    "    ndvi_sentinel = sentinel_image.normalizedDifference([\"B8\", \"B4\"]).rename(\"s2_ndvi\")\n",
    "    ndwi_sentinel = sentinel_image.normalizedDifference([\"B3\", \"B11\"]).rename(\"s2_ndwi\")\n",
    "    ndbi_sentinel = sentinel_image.normalizedDifference([\"B11\", \"B8\"]).rename(\"s2_ndbi\")\n",
    "\n",
    "    # Poi for regression, this increases n\n",
    "    poi_regression = poi_leak.buffer(buffer_regression).bounds(proj = \"EPSG:32613\", maxError = 0.001)\n",
    "\n",
    "    # Linear regression\n",
    "    bands = ee.Image(1).addBands(ndvi_landsat).addBands(ndbi_landsat).addBands(ndwi_landsat).addBands(lst_landsat_30m).rename([\"constant\", \"ndvi\", \"ndbi\", \"ndwi\", \"lst\"])\n",
    "\n",
    "    img_landsat_regression = bands.reduceRegion(\n",
    "        reducer = ee.Reducer.linearRegression(4, 1),\n",
    "        geometry = poi_regression,\n",
    "        scale = 30,\n",
    "        maxPixels = 1e13\n",
    "    )\n",
    "\n",
    "    # Get coefficients of linear regression\n",
    "    coefList2 = ee.Array(img_landsat_regression.get(\"coefficients\")).toList()\n",
    "    intercept2 = ee.Image(ee.Number(ee.List(coefList2.get(0)).get(0))).reproject(crs = \"EPSG:32613\")\n",
    "    slopeNDVI2 = ee.Image(ee.Number(ee.List(coefList2.get(1)).get(0))).reproject(crs = \"EPSG:32613\")\n",
    "    slopeNDBI2 = ee.Image(ee.Number(ee.List(coefList2.get(2)).get(0))).reproject(crs = \"EPSG:32613\")\n",
    "    slopeNDWI2 = ee.Image(ee.Number(ee.List(coefList2.get(3)).get(0))).reproject(crs = \"EPSG:32613\")\n",
    "\n",
    "    # Predict LST with Landsat info \n",
    "    LST_model = intercept2.add(slopeNDVI2.multiply(ndvi_landsat))\\\n",
    "                .add(slopeNDBI2.multiply(ndbi_landsat))\\\n",
    "                .add(slopeNDWI2.multiply(ndwi_landsat))\n",
    "\n",
    "    # Get residuals\n",
    "    residuals = lst_landsat_30m.subtract(LST_model)\n",
    "\n",
    "    # Predict LST with Sentinel info (downscaled image)\n",
    "    lst_landsat_10m_final = ee.Image(intercept2).add(slopeNDVI2.multiply(ndvi_sentinel))\\\n",
    "                                                .add(slopeNDBI2.multiply(ndbi_sentinel)).add(slopeNDWI2.multiply(ndwi_sentinel))\\\n",
    "                                                .clip(poi_leak.buffer(buffer_size).bounds(proj = \"EPSG:32613\", maxError = 0.001))\n",
    "\n",
    "    if error == True:\n",
    "        \n",
    "        # Compute number of pixels in the image (n)\n",
    "        n = landsat_image.select(\"ST_B10\").reduceRegion(\n",
    "            reducer = ee.Reducer.count(),\n",
    "            scale = 30,\n",
    "            maxPixels = 1e13\n",
    "        ).getInfo()[\"ST_B10\"]\n",
    "\n",
    "        # Compute Root Mean Squared Error\n",
    "        rmse = math.sqrt(residuals.select(\"Landsat_LST_30m\").pow(2).reduceRegion(\n",
    "            reducer = ee.Reducer.sum(),\n",
    "            scale = 30,\n",
    "            maxPixels = 1e13\n",
    "        ).getInfo()[\"Landsat_LST_30m\"]/n)\n",
    "\n",
    "    return (lst_landsat_10m_final, rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lst10m_band(sentinel_image, lst_image):\n",
    "    \n",
    "    return sentinel_image.addBands(lst_image.rename(\"LST_10m\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_raw_columns = [\"NO. ORDEN\", \"FECHA DE CREACION\", \"FECHA TERMINACION\", \"TIPO DE ORDEN\", \"LATITUD\", \"LONGITUD\"]\n",
    "rename_raw_columns = {\"NO. ORDEN\": \"id\", \n",
    "                      \"FECHA DE CREACION\": \"fecha_de_i\",\n",
    "                      \"FECHA TERMINACION\": \"fechalegal\",\n",
    "                      \"TIPO DE ORDEN\": \"tipo\",\n",
    "                      \"LONGITUD\": \"x\",\n",
    "                      \"LATITUD\": \"y\"}\n",
    "\n",
    "date_format = \"%d-%m-%Y %H:%M:%S\"\n",
    "\n",
    "# Patch download\n",
    "bands = [\"B4\", \"B3\", \"B2\", \"B1\", \"B5\", \"B6\", \"B7\", \"B8\", \"B8A\", \"B9\", \"B11\", \"B12\", \"WVP\"]\n",
    "i = 0\n",
    "download_path = DATA_ROOT_PATH + \"/patches_raw_agsal/nonleak/\"\n",
    "patch_size = 100\n",
    "index_progress = []\n",
    "id = []\n",
    "sentinel_img_date = []\n",
    "landsat_img_date = []\n",
    "date_diff = []\n",
    "date_diff_leak = []\n",
    "sentinel_cloud = []\n",
    "landsat_cloud = []\n",
    "rmse = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaks_46_raw = pd.read_excel(LEAKS_46)\n",
    "leaks_49_raw = pd.read_excel(LEAKS_49)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2030, 22)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaks_46_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FC.FUGA EN CALLE          843\n",
       "FB.FUGA EN BANQUETA       461\n",
       "FP.FUGA EN PIE DERECHO    235\n",
       "TE.TRABAJOS ESPECIALES    228\n",
       "TB.TUBO ROTO              208\n",
       "CT.CAMBIO DE TOMA          55\n",
       "Name: TIPO DE ORDEN, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaks_46_raw[\"TIPO DE ORDEN\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2176, 18)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaks_49_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FC.FUGA EN CALLE          1085\n",
       "FB.FUGA EN BANQUETA        555\n",
       "TB.TUBO ROTO               242\n",
       "TE.TRABAJOS ESPECIALES     145\n",
       "FP.FUGA EN PIE DERECHO      93\n",
       "CT.CAMBIO DE TOMA           51\n",
       "FL.FUGA NO VISIBLE           5\n",
       "Name: TIPO DE ORDEN, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaks_49_raw[\"TIPO DE ORDEN\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NO. ORDEN</th>\n",
       "      <th>FECHA DE CREACION</th>\n",
       "      <th>QUEJA AQUACIS</th>\n",
       "      <th>FECHA  ASIGNACION</th>\n",
       "      <th>FECHA  REALIZACION</th>\n",
       "      <th>FECHA TERMINACION</th>\n",
       "      <th>AREA</th>\n",
       "      <th>ZONA</th>\n",
       "      <th>BRIGADA</th>\n",
       "      <th>NUMERO CONTRATO MARCO</th>\n",
       "      <th>...</th>\n",
       "      <th>CLIENTE</th>\n",
       "      <th>TIPO DE ORDEN</th>\n",
       "      <th>TIPO DE PROYECTO</th>\n",
       "      <th>PROYCTO</th>\n",
       "      <th>POZO</th>\n",
       "      <th>CENTRO DE COSTOS</th>\n",
       "      <th>LATITUD</th>\n",
       "      <th>LONGITUD</th>\n",
       "      <th>TIPO DE ORDEN.1</th>\n",
       "      <th>DIRECCION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2505520</td>\n",
       "      <td>18/12/2023 14:50:44</td>\n",
       "      <td>2469457.0</td>\n",
       "      <td>20/12/2023 10:35:44</td>\n",
       "      <td>20/12/2023 12:44:22</td>\n",
       "      <td>16/01/2024 12:59:05</td>\n",
       "      <td>EFICIENCIA FISICA</td>\n",
       "      <td>ORIENTE</td>\n",
       "      <td>BR JUAN GOMEZ</td>\n",
       "      <td>4.600001e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>7-ELEVEN MEXICO</td>\n",
       "      <td>FP.FUGA EN PIE DERECHO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74000</td>\n",
       "      <td>25.438982</td>\n",
       "      <td>-100.978640</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JOSE MARIA LA FRAGUA         2530      GUANAJU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2505513</td>\n",
       "      <td>18/12/2023 14:42:55</td>\n",
       "      <td>2469451.0</td>\n",
       "      <td>20/12/2023 08:36:06</td>\n",
       "      <td>20/12/2023 12:26:16</td>\n",
       "      <td>16/01/2024 12:58:41</td>\n",
       "      <td>EFICIENCIA FISICA</td>\n",
       "      <td>ORIENTE</td>\n",
       "      <td>BR JUAN GOMEZ</td>\n",
       "      <td>4.600001e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>MOISES HERNANDEZ VALDES</td>\n",
       "      <td>FC.FUGA EN CALLE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74000</td>\n",
       "      <td>25.438315</td>\n",
       "      <td>-100.978401</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DOLORES HIDALGO 220      GUANAJUATO ORIENTE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2505512</td>\n",
       "      <td>18/12/2023 14:42:55</td>\n",
       "      <td>2469450.0</td>\n",
       "      <td>20/12/2023 16:36:58</td>\n",
       "      <td>27/12/2023 15:47:00</td>\n",
       "      <td>16/01/2024 12:57:35</td>\n",
       "      <td>EFICIENCIA FISICA</td>\n",
       "      <td>ORIENTE</td>\n",
       "      <td>BR JOSE RODRIGUEZ</td>\n",
       "      <td>4.600001e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>ALFA REYES VDA DEL BOSQUE</td>\n",
       "      <td>FB.FUGA EN BANQUETA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74000</td>\n",
       "      <td>25.454452</td>\n",
       "      <td>-101.009695</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CORTAZAR 114      GUANAJUATO ORIENTE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2505509</td>\n",
       "      <td>18/12/2023 14:38:48</td>\n",
       "      <td>2469444.0</td>\n",
       "      <td>20/12/2023 08:36:43</td>\n",
       "      <td>20/12/2023 12:28:49</td>\n",
       "      <td>16/01/2024 12:57:07</td>\n",
       "      <td>EFICIENCIA FISICA</td>\n",
       "      <td>ORIENTE</td>\n",
       "      <td>BR JUAN GOMEZ</td>\n",
       "      <td>4.600001e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>ALBERTO PECINA MORENO</td>\n",
       "      <td>FP.FUGA EN PIE DERECHO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74000</td>\n",
       "      <td>25.438911</td>\n",
       "      <td>-100.978670</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DOLORES HIDALGO 124      GUANAJUATO ORIENTE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2501253</td>\n",
       "      <td>12/12/2023 12:28:43</td>\n",
       "      <td>2468338.0</td>\n",
       "      <td>13/12/2023 11:35:44</td>\n",
       "      <td>20/12/2023 11:42:28</td>\n",
       "      <td>16/01/2024 12:38:31</td>\n",
       "      <td>EFICIENCIA FISICA</td>\n",
       "      <td>PONIENTE</td>\n",
       "      <td>BR JUAN GOMEZ</td>\n",
       "      <td>4.600001e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>JOVITA GUTIERREZ AGUILERA</td>\n",
       "      <td>FC.FUGA EN CALLE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74000</td>\n",
       "      <td>25.380674</td>\n",
       "      <td>-101.014129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PASEO DE LAS BEGONIAS 465      PARQUES DE LA C...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   NO. ORDEN    FECHA DE CREACION  QUEJA AQUACIS    FECHA  ASIGNACION  \\\n",
       "0    2505520  18/12/2023 14:50:44      2469457.0  20/12/2023 10:35:44   \n",
       "1    2505513  18/12/2023 14:42:55      2469451.0  20/12/2023 08:36:06   \n",
       "2    2505512  18/12/2023 14:42:55      2469450.0  20/12/2023 16:36:58   \n",
       "3    2505509  18/12/2023 14:38:48      2469444.0  20/12/2023 08:36:43   \n",
       "4    2501253  12/12/2023 12:28:43      2468338.0  13/12/2023 11:35:44   \n",
       "\n",
       "    FECHA  REALIZACION    FECHA TERMINACION               AREA     ZONA   \\\n",
       "0  20/12/2023 12:44:22  16/01/2024 12:59:05  EFICIENCIA FISICA   ORIENTE   \n",
       "1  20/12/2023 12:26:16  16/01/2024 12:58:41  EFICIENCIA FISICA   ORIENTE   \n",
       "2  27/12/2023 15:47:00  16/01/2024 12:57:35  EFICIENCIA FISICA   ORIENTE   \n",
       "3  20/12/2023 12:28:49  16/01/2024 12:57:07  EFICIENCIA FISICA   ORIENTE   \n",
       "4  20/12/2023 11:42:28  16/01/2024 12:38:31  EFICIENCIA FISICA  PONIENTE   \n",
       "\n",
       "             BRIGADA  NUMERO CONTRATO MARCO  ...                    CLIENTE  \\\n",
       "0      BR JUAN GOMEZ           4.600001e+09  ...           7-ELEVEN MEXICO    \n",
       "1      BR JUAN GOMEZ           4.600001e+09  ...    MOISES HERNANDEZ VALDES   \n",
       "2  BR JOSE RODRIGUEZ           4.600001e+09  ...  ALFA REYES VDA DEL BOSQUE   \n",
       "3      BR JUAN GOMEZ           4.600001e+09  ...      ALBERTO PECINA MORENO   \n",
       "4      BR JUAN GOMEZ           4.600001e+09  ...  JOVITA GUTIERREZ AGUILERA   \n",
       "\n",
       "            TIPO DE ORDEN TIPO DE PROYECTO PROYCTO  POZO  CENTRO DE COSTOS  \\\n",
       "0  FP.FUGA EN PIE DERECHO              NaN     NaN   NaN             74000   \n",
       "1        FC.FUGA EN CALLE              NaN     NaN   NaN             74000   \n",
       "2     FB.FUGA EN BANQUETA              NaN     NaN   NaN             74000   \n",
       "3  FP.FUGA EN PIE DERECHO              NaN     NaN   NaN             74000   \n",
       "4        FC.FUGA EN CALLE              NaN     NaN   NaN             74000   \n",
       "\n",
       "     LATITUD    LONGITUD  TIPO DE ORDEN.1  \\\n",
       "0  25.438982 -100.978640              NaN   \n",
       "1  25.438315 -100.978401              NaN   \n",
       "2  25.454452 -101.009695              NaN   \n",
       "3  25.438911 -100.978670              NaN   \n",
       "4  25.380674 -101.014129              NaN   \n",
       "\n",
       "                                           DIRECCION  \n",
       "0  JOSE MARIA LA FRAGUA         2530      GUANAJU...  \n",
       "1        DOLORES HIDALGO 220      GUANAJUATO ORIENTE  \n",
       "2               CORTAZAR 114      GUANAJUATO ORIENTE  \n",
       "3        DOLORES HIDALGO 124      GUANAJUATO ORIENTE  \n",
       "4  PASEO DE LAS BEGONIAS 465      PARQUES DE LA C...  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaks_46_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select important columns and rename it\n",
    "leaks_46_clean = leaks_46_raw[important_raw_columns].rename(columns=rename_raw_columns)\n",
    "leaks_49_clean = leaks_49_raw[important_raw_columns].rename(columns=rename_raw_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract leak type\n",
    "leaks_46_clean[\"tipo_cod\"] = leaks_46_clean[\"tipo\"].str.extract(\"([A-Z]+)(?<=.)\")\n",
    "leaks_49_clean[\"tipo_cod\"] = leaks_49_clean[\"tipo\"].str.extract(\"([A-Z]+)(?<=.)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join both dfs\n",
    "leaks_clean = pd.concat([leaks_46_clean, leaks_49_clean]).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix date format\n",
    "leaks_clean[\"fecha_de_i\"] = leaks_clean[\"fecha_de_i\"].str.replace(\"/\", \"-\")\n",
    "leaks_clean[\"fechalegal\"] = leaks_clean[\"fechalegal\"].str.replace(\"/\", \"-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save clean dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaks_46_clean.to_csv(SAVE_CLEAN_DATA + \"/agsal_46_clean.csv\")\n",
    "leaks_49_clean.to_csv(SAVE_CLEAN_DATA + \"/agsal_49_clean.csv\")\n",
    "leaks_clean.to_csv(SAVE_CLEAN_DATA + \"/agsal_full_clean.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download leak patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaks_clean = pd.read_csv(SAVE_CLEAN_DATA + \"/agsal_full_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4139, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaks_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP dir does not exists! Making directory at ../data/patches_raw_agsal/nonleak/FP...\n",
      "FC dir does not exists! Making directory at ../data/patches_raw_agsal/nonleak/FC...\n",
      "FB dir does not exists! Making directory at ../data/patches_raw_agsal/nonleak/FB...\n",
      "TB dir does not exists! Making directory at ../data/patches_raw_agsal/nonleak/TB...\n",
      "TE dir does not exists! Making directory at ../data/patches_raw_agsal/nonleak/TE...\n",
      "CT dir does not exists! Making directory at ../data/patches_raw_agsal/nonleak/CT...\n",
      "FL dir does not exists! Making directory at ../data/patches_raw_agsal/nonleak/FL...\n"
     ]
    }
   ],
   "source": [
    "# Create leak type subdirectories inside leak and nonleak\n",
    "for tipo in leaks_clean[\"tipo_cod\"].unique():\n",
    "    if os.path.exists(download_path + f\"{tipo}\"):\n",
    "        print(f\"{tipo} dir exists! Skipping...\")\n",
    "        continue\n",
    "    else:\n",
    "        print(f\"{tipo} dir does not exists! Making directory at {download_path + tipo}...\")\n",
    "        os.mkdir(download_path + f\"{tipo}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize GEE API\n",
    "try:\n",
    "    ee.Initialize()\n",
    "except:\n",
    "    ee.Initialize()\n",
    "    ee.Authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaks_clean = leaks_clean[leaks_clean[\"tipo_cod\"] == \"FL\"].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Leak index:  0\n",
      "Date of leak:  2022-07-26\n",
      "Leak type: FL\n",
      "Leak coords:  (-100.979875, 25.3807165) \n",
      "\n",
      "Date of selected image (Landsat): 2022-08-15 \n",
      "Landsat images found:  2 \n",
      "Cloud %:  57.61\n",
      "Date of selected image (Sentinel):  2022-08-12 \n",
      "Sentinel images found: 3 \n",
      "Cloud %:  20.687352\n",
      "Difference between image dates: 3 days, 0:00:00\n",
      "Difference between date of leak and date of image: 17 days, 0:00:00\n",
      "Download complete\n",
      "====================================================================================================\n",
      "Leak index:  1\n",
      "Date of leak:  2022-07-26\n",
      "Leak detected at the same date\n",
      "Leak type: FL\n",
      "Leak coords:  (-100.9798624, 25.3807062) \n",
      "\n",
      "Date of selected image (Landsat): 2022-08-15 \n",
      "Landsat images found:  2 \n",
      "Cloud %:  57.61\n",
      "Date of selected image (Sentinel):  2022-08-12 \n",
      "Sentinel images found: 3 \n",
      "Cloud %:  20.687352\n",
      "Difference between image dates: 3 days, 0:00:00\n",
      "Difference between date of leak and date of image: 17 days, 0:00:00\n",
      "Download complete\n",
      "====================================================================================================\n",
      "Leak index:  2\n",
      "Date of leak:  2022-07-26\n",
      "Leak detected at the same date\n",
      "Leak type: FL\n",
      "Leak coords:  (-100.9798986, 25.3807318) \n",
      "\n",
      "Date of selected image (Landsat): 2022-08-15 \n",
      "Landsat images found:  2 \n",
      "Cloud %:  57.61\n",
      "Date of selected image (Sentinel):  2022-08-12 \n",
      "Sentinel images found: 3 \n",
      "Cloud %:  20.687352\n",
      "Difference between image dates: 3 days, 0:00:00\n",
      "Difference between date of leak and date of image: 17 days, 0:00:00\n",
      "Download complete\n",
      "====================================================================================================\n",
      "Leak index:  3\n",
      "Date of leak:  2022-07-21\n",
      "Leak type: FL\n",
      "Leak coords:  (-100.9798917, 25.3807348) \n",
      "\n",
      "Date of selected image (Landsat): 2022-08-15 \n",
      "Landsat images found:  2 \n",
      "Cloud %:  57.61\n",
      "Date of selected image (Sentinel):  2022-08-12 \n",
      "Sentinel images found: 3 \n",
      "Cloud %:  20.687352\n",
      "Difference between image dates: 3 days, 0:00:00\n",
      "Difference between date of leak and date of image: 22 days, 0:00:00\n",
      "Download complete\n",
      "====================================================================================================\n",
      "Leak index:  4\n",
      "Date of leak:  2022-07-27\n",
      "Leak type: FL\n",
      "Leak coords:  (-100.9799112, 25.3807323) \n",
      "\n",
      "Date of selected image (Landsat): 2022-08-15 \n",
      "Landsat images found:  2 \n",
      "Cloud %:  57.61\n",
      "Date of selected image (Sentinel):  2022-08-12 \n",
      "Sentinel images found: 3 \n",
      "Cloud %:  20.687352\n",
      "Difference between image dates: 3 days, 0:00:00\n",
      "Difference between date of leak and date of image: 16 days, 0:00:00\n",
      "Download complete\n",
      "====================================================================================================\n",
      "Leak index:  5\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Erick\\anaconda3\\envs\\rs_leaks_env\\lib\\site-packages\\pandas\\core\\indexes\\range.py:391\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 391\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_range\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[1;31mValueError\u001b[0m: 5 is not in range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLeak index: \u001b[39m\u001b[38;5;124m\"\u001b[39m, leak)\n\u001b[1;32m----> 7\u001b[0m date_leak \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mstrptime(\u001b[43mleaks_clean\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfechalegal\u001b[49m\u001b[43m[\u001b[49m\u001b[43mleak\u001b[49m\u001b[43m]\u001b[49m, date_format)\u001b[38;5;241m.\u001b[39mdate()\n\u001b[0;32m      8\u001b[0m id_leak \u001b[38;5;241m=\u001b[39m leaks_clean\u001b[38;5;241m.\u001b[39mid[leak]\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m.\u001b[39mappend(id_leak)\n",
      "File \u001b[1;32mc:\\Users\\Erick\\anaconda3\\envs\\rs_leaks_env\\lib\\site-packages\\pandas\\core\\series.py:981\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    978\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m    980\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m--> 981\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m    984\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m    985\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    986\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Erick\\anaconda3\\envs\\rs_leaks_env\\lib\\site-packages\\pandas\\core\\series.py:1089\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1088\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1089\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1090\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_get_values_for_loc(\u001b[38;5;28mself\u001b[39m, loc, label)\n",
      "File \u001b[1;32mc:\\Users\\Erick\\anaconda3\\envs\\rs_leaks_env\\lib\\site-packages\\pandas\\core\\indexes\\range.py:393\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m    391\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_range\u001b[38;5;241m.\u001b[39mindex(new_key)\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 393\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 5"
     ]
    }
   ],
   "source": [
    "prev_rep = 0\n",
    "for rep in list(range(25, len(leaks_clean) + 25, 25)):\n",
    "\n",
    "    for leak in range(prev_rep, rep):\n",
    "        print(\"=\"*100)\n",
    "        print(\"Leak index: \", leak)\n",
    "        date_leak = datetime.strptime(leaks_clean.fechalegal[leak], date_format).date()\n",
    "        id_leak = leaks_clean.id[leak]\n",
    "        id.append(id_leak)\n",
    "        \n",
    "        # Dates for patch after leak\n",
    "        end_date_landsat = date_leak + timedelta(days = 35)\n",
    "        start_date_landsat = end_date_landsat - timedelta(days = 25)    \n",
    "\n",
    "        print(\"Date of leak: \", date_leak)\n",
    "\n",
    "        if leak == 0:\n",
    "            previous_end_date = \"\"\n",
    "\n",
    "        if previous_end_date == date_leak:\n",
    "            i += 1\n",
    "            print(\"Leak detected at the same date\")\n",
    "        else:\n",
    "            i = 0\n",
    "\n",
    "        # Date for zip label\n",
    "        leak_type = leaks_clean.tipo_cod[i]\n",
    "        print(f\"Leak type: {leak_type}\")\n",
    "        date_lab = \"i\" + str(int(id_leak)) + \"d\" + \"_\" + leak_type + \"_\" + str(leaks_clean.fechalegal[leak])[:10] + \"_\" + str(leak)\n",
    "    \n",
    "        # Coords of leaks\n",
    "        leak_lon = leaks_clean[\"y\"][leak]\n",
    "        leak_lat = leaks_clean[\"x\"][leak]\n",
    "\n",
    "        # Point of leak\n",
    "        poi = ee_utils.get_poi(lat=leak_lat, lon=leak_lon)\n",
    " \n",
    "        print(\"Leak coords: \", (leak_lat, leak_lon), \"\\n\")\n",
    "\n",
    "        # Get sentinel and landsat collection of images according to leak coord \n",
    "        img_landsat = ee_dwld.get_landsat_images(start = start_date_landsat, end = end_date_landsat, poi_leak = poi, buffer_regression = 500)\n",
    "        landsat_date = ee.Date(img_landsat.get(\"system:time_start\")).format(\"yyyy-MM-dd\").getInfo()\n",
    "        landsat_date = datetime.strptime(landsat_date, \"%Y-%m-%d\").date()\n",
    "\n",
    "        # Sentinel image is selected after using landsat image date in order to get the minimun time between images\n",
    "        end_date_sentinel = landsat_date\n",
    "        start_date_sentinel = end_date_sentinel - timedelta(days = 5)    \n",
    "\n",
    "        img = ee_dwld.get_image(start = start_date_sentinel, end = end_date_sentinel, poi_leak = poi)\n",
    "        sentinel_date = ee.Date(img.get(\"system:time_start\")).format(\"yyyy-MM-dd\").getInfo()\n",
    "        sentinel_date = datetime.strptime(sentinel_date, \"%Y-%m-%d\").date()\n",
    "        \n",
    "        # Append date of images\n",
    "        sentinel_img_date.append(sentinel_date)\n",
    "        landsat_img_date.append(landsat_date)\n",
    "\n",
    "        # Get difference of days between dates\n",
    "        date_diff.append(abs(sentinel_date - landsat_date))\n",
    "        date_diff_leak.append(sentinel_date - date_leak)\n",
    "        print(\"Difference between image dates:\", abs(sentinel_date - landsat_date))\n",
    "        print(\"Difference between date of leak and date of image:\" , abs(sentinel_date - date_leak))\n",
    "\n",
    "        # Append cloud %\n",
    "        sentinel_cloud.append(img.get(\"CLOUDY_PIXEL_PERCENTAGE\").getInfo())\n",
    "        landsat_cloud.append(img_landsat.get(\"CLOUD_COVER\").getInfo())\n",
    "\n",
    "        # Select bands and reduce the hole image to a patch centered on the leak\n",
    "        img = ee_utils.bands_clip_image(img, poi=poi, buffer_size = patch_size, bands = bands)\n",
    "\n",
    "        # Estimate lst from landsat image and add its lst band to sentinel image\n",
    "        lst_image, rmse_value = ee_LST.lst_regression(landsat_image = img_landsat, sentinel_image = img, poi_leak = poi, buffer_size = patch_size, buffer_regression = 500, error = True)\n",
    "        rmse.append(rmse_value)\n",
    "        img = ee_LST.add_lst10m_band(img, lst_image = lst_image)\n",
    "\n",
    "        # Download image\n",
    "        ee_dwld.download_image(image = img, path = download_path + f\"{leak_type}/\", date_label = date_lab)\n",
    "\n",
    "        previous_end_date = date_leak\n",
    "\n",
    "        index_progress.append(leak)\n",
    "\n",
    "    print(\"+\"*100)\n",
    "    print(\"PATCH DOWNLOAD COMPLETED\", \"Batch:\", rep)\n",
    "    prev_rep = rep\n",
    "    winsound.Beep(2000, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n"
     ]
    }
   ],
   "source": [
    "print(\"finished!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
