{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook contains the code to train the CNN model without the LST band in order to compare the effectivness of this feature."
      ],
      "metadata": {
        "id": "otZ5Peujy4sk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lqa2rdfmhNP1"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "from skimage.io import imread\n",
        "import numpy as np\n",
        "import albumentations as A\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Conv2D, Activation, MaxPool2D, Dropout, BatchNormalization, Dense, Flatten, LayerNormalization\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount Gdrive"
      ],
      "metadata": {
        "id": "VzB2V37YzvX0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkdqB9jimX6i",
        "outputId": "87c998c1-a389-4acb-b638-843aca78d25c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbr8suj3lyhC"
      },
      "source": [
        "## Load X and Y sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5VpSgroxDbA"
      },
      "outputs": [],
      "source": [
        "# Read from google drive\n",
        "X = np.load(\"/content/drive/MyDrive/training/X_full.npy\")\n",
        "Y = np.load(\"/content/drive/MyDrive/training/Y_full.npy\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run to get get only S2 bands (discard LST)\n",
        "X = X[:, :, :, :13]\n",
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1e4BGnwNg-J",
        "outputId": "299d0609-bd28-44a8-ee86-0068ee66cb0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3909, 20, 20, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsU_vFT4lyhF",
        "outputId": "96ffa8b7-4056-4e39-985d-ded33792ded7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (3909, 20, 20, 13)\n",
            "Y shape: (3909, 1)\n"
          ]
        }
      ],
      "source": [
        "print(\"X shape:\", X.shape)\n",
        "print(\"Y shape:\", Y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhZpCHwflyhG"
      },
      "source": [
        "## Define training, validation and test sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQiGg5LQlyhG"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size = 0.2, random_state = 13)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.2, random_state = 13)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeGf_6XplyhG",
        "outputId": "466e7bf7-73a4-4374-eaf1-ff59b5290ac1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train:  (2501, 20, 20, 13)\n",
            "X_val:  (782, 20, 20, 13)\n",
            "X_test:  (626, 20, 20, 13)\n",
            "y_train:  (2501, 1)\n",
            "y_val:  (782, 1)\n",
            "y_test:  (626, 1)\n"
          ]
        }
      ],
      "source": [
        "# Shapes of sets\n",
        "print(\"X_train: \", X_train.shape)\n",
        "print(\"X_val: \", X_val.shape)\n",
        "print(\"X_test: \", X_test.shape)\n",
        "print(\"y_train: \", y_train.shape)\n",
        "print(\"y_val: \", y_val.shape)\n",
        "print(\"y_test: \", y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Js9_qq2glyhG"
      },
      "outputs": [],
      "source": [
        "def see_balance_in_set(set):\n",
        "    print(np.unique(set.ravel(), return_counts = True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvGXLke5lyhG",
        "outputId": "937e3575-4b82-464d-b97c-c65d033211be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([0, 1], dtype=int32), array([1266, 1235]))\n",
            "(array([0, 1], dtype=int32), array([366, 416]))\n",
            "(array([0, 1], dtype=int32), array([323, 303]))\n"
          ]
        }
      ],
      "source": [
        "# Check if classes are balanced\n",
        "see_balance_in_set(y_train)\n",
        "see_balance_in_set(y_val)\n",
        "see_balance_in_set(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple architecture (without LST)"
      ],
      "metadata": {
        "id": "SfoNtYgrpppc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgbtWvdnQV76",
        "outputId": "40883423-51a1-4588-80e1-cf8780c3f84f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 20, 20, 32)        1696      \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 20, 20, 32)       128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " activation (Activation)     (None, 20, 20, 32)        0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 20, 20, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 20, 20, 64)        32832     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 20, 20, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 20, 20, 64)        0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 20, 20, 64)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 10, 10, 128)       32896     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 10, 10, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 10, 10, 128)       0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 10, 10, 128)       0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 5, 5, 128)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 3200)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               819456    \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 512)               131584    \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 513       \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,019,873\n",
            "Trainable params: 1,019,425\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_simple = Sequential()\n",
        "\n",
        "# 1st Conv Layer\n",
        "model_simple.add(Conv2D(32, (2, 2), padding = \"same\", strides = (1, 1), input_shape = (20, 20, 13)))\n",
        "model_simple.add(BatchNormalization())\n",
        "model_simple.add(Activation(\"relu\"))\n",
        "model_simple.add(Dropout(0.2))\n",
        "\n",
        "# 2nd Conv layer\n",
        "model_simple.add(Conv2D(64, (4, 4), padding = \"same\", strides = (1, 1)))\n",
        "model_simple.add(BatchNormalization())\n",
        "model_simple.add(Activation(\"relu\"))\n",
        "model_simple.add(Dropout(0.5))\n",
        "\n",
        "# 3rd Conv layer\n",
        "model_simple.add(Conv2D(128, (2, 2), padding = \"same\", strides = (2, 2)))\n",
        "model_simple.add(BatchNormalization())\n",
        "model_simple.add(Activation(\"relu\"))\n",
        "model_simple.add(Dropout(0.5))\n",
        "model_simple.add(MaxPool2D(2, 2))\n",
        "\n",
        "# Dense layer\n",
        "model_simple.add(Flatten())\n",
        "model_simple.add(Dense(256))\n",
        "model_simple.add(Activation(\"relu\"))\n",
        "model_simple.add(Dropout(0.6))\n",
        "model_simple.add(Dense(512))\n",
        "model_simple.add(Activation(\"relu\"))\n",
        "model_simple.add(Dropout(0.3))\n",
        "model_simple.add(Dense(1))\n",
        "model_simple.add(Activation(\"sigmoid\"))\n",
        "\n",
        "model_simple.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scheduler(epoch, lr):\n",
        "    l = 0.0001\n",
        "    if epoch > 200:\n",
        "        l = 0.00001\n",
        "    if epoch > 400:\n",
        "        l = 0.000015\n",
        "    if epoch > 600:\n",
        "        l = 0.000001\n",
        "    if epoch > 700:\n",
        "        l = 0.000025\n",
        "    if epoch > 850:\n",
        "        l = 0.00004\n",
        "\n",
        "    return l"
      ],
      "metadata": {
        "id": "vFo6kqBjRFqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callback = LearningRateScheduler(scheduler, verbose = 1)"
      ],
      "metadata": {
        "id": "cFfNYgxjRlKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iosm7qkBTTAD"
      },
      "outputs": [],
      "source": [
        "optim_simple = optimizers.Adam()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emvevA5iTX6C"
      },
      "outputs": [],
      "source": [
        "model_simple.compile(optimizer = optim_simple,\n",
        "                     loss = \"binary_crossentropy\",\n",
        "                     metrics = [\"acc\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxbrpGthTqsB",
        "outputId": "56e29085-85d9-4ae2-f24b-94aa8322901a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 1/1000\n",
            "5/5 [==============================] - 14s 222ms/step - loss: 1.1188 - acc: 0.4982 - val_loss: 1.1373 - val_acc: 0.4680 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 2/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.9353 - acc: 0.5082 - val_loss: 0.8158 - val_acc: 0.4693 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 3/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.8508 - acc: 0.4998 - val_loss: 0.7229 - val_acc: 0.4642 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 4/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.8045 - acc: 0.5130 - val_loss: 0.7094 - val_acc: 0.4642 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 5/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.7547 - acc: 0.5174 - val_loss: 0.7203 - val_acc: 0.4668 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 6/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.7436 - acc: 0.5242 - val_loss: 0.7180 - val_acc: 0.4706 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 7/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.7194 - acc: 0.5254 - val_loss: 0.7063 - val_acc: 0.4578 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 8/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.7109 - acc: 0.5098 - val_loss: 0.7005 - val_acc: 0.4719 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 9/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.7094 - acc: 0.5282 - val_loss: 0.6972 - val_acc: 0.4719 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 10/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.7063 - acc: 0.5162 - val_loss: 0.6956 - val_acc: 0.4795 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 11/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6948 - acc: 0.5346 - val_loss: 0.6953 - val_acc: 0.4923 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 12/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.6955 - acc: 0.5330 - val_loss: 0.6947 - val_acc: 0.4859 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 13/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.6953 - acc: 0.5426 - val_loss: 0.6943 - val_acc: 0.4962 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 14/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.6937 - acc: 0.5290 - val_loss: 0.6931 - val_acc: 0.5026 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 15/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.6947 - acc: 0.5206 - val_loss: 0.6921 - val_acc: 0.5000 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 16: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 16/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.6924 - acc: 0.5126 - val_loss: 0.6912 - val_acc: 0.5115 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 17: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 17/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.6860 - acc: 0.5366 - val_loss: 0.6910 - val_acc: 0.5269 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 18: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 18/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6873 - acc: 0.5382 - val_loss: 0.6908 - val_acc: 0.5332 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 19: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 19/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.6833 - acc: 0.5338 - val_loss: 0.6907 - val_acc: 0.5307 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 20: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 20/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6847 - acc: 0.5458 - val_loss: 0.6906 - val_acc: 0.5371 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 21: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 21/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6838 - acc: 0.5386 - val_loss: 0.6900 - val_acc: 0.5396 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 22: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 22/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6860 - acc: 0.5422 - val_loss: 0.6892 - val_acc: 0.5435 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 23: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 23/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6713 - acc: 0.5602 - val_loss: 0.6884 - val_acc: 0.5486 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 24: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 24/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6859 - acc: 0.5390 - val_loss: 0.6875 - val_acc: 0.5575 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 25: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 25/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6759 - acc: 0.5498 - val_loss: 0.6869 - val_acc: 0.5639 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 26: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 26/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6806 - acc: 0.5562 - val_loss: 0.6862 - val_acc: 0.5639 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 27: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 27/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6832 - acc: 0.5498 - val_loss: 0.6861 - val_acc: 0.5729 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 28: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 28/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6769 - acc: 0.5630 - val_loss: 0.6859 - val_acc: 0.5703 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 29: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 29/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6690 - acc: 0.5562 - val_loss: 0.6849 - val_acc: 0.5703 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 30: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 30/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.6734 - acc: 0.5618 - val_loss: 0.6843 - val_acc: 0.5729 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 31: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 31/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6806 - acc: 0.5550 - val_loss: 0.6834 - val_acc: 0.5742 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 32: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 32/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6782 - acc: 0.5582 - val_loss: 0.6824 - val_acc: 0.5729 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 33: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 33/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6702 - acc: 0.5630 - val_loss: 0.6814 - val_acc: 0.5691 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 34: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 34/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6754 - acc: 0.5566 - val_loss: 0.6806 - val_acc: 0.5665 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 35: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 35/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6747 - acc: 0.5546 - val_loss: 0.6805 - val_acc: 0.5678 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 36: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 36/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6655 - acc: 0.5698 - val_loss: 0.6801 - val_acc: 0.5665 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 37: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 37/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.6759 - acc: 0.5590 - val_loss: 0.6796 - val_acc: 0.5678 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 38: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 38/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6656 - acc: 0.5662 - val_loss: 0.6790 - val_acc: 0.5652 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 39: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 39/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6666 - acc: 0.5730 - val_loss: 0.6787 - val_acc: 0.5639 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 40: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 40/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6724 - acc: 0.5730 - val_loss: 0.6782 - val_acc: 0.5691 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 41: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 41/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6693 - acc: 0.5774 - val_loss: 0.6778 - val_acc: 0.5691 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 42: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 42/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6652 - acc: 0.5778 - val_loss: 0.6771 - val_acc: 0.5716 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 43: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 43/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6663 - acc: 0.5802 - val_loss: 0.6764 - val_acc: 0.5678 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 44: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 44/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6626 - acc: 0.5722 - val_loss: 0.6758 - val_acc: 0.5665 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 45: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 45/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6640 - acc: 0.5746 - val_loss: 0.6755 - val_acc: 0.5665 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 46: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 46/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6588 - acc: 0.5694 - val_loss: 0.6746 - val_acc: 0.5691 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 47: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 47/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6649 - acc: 0.5730 - val_loss: 0.6735 - val_acc: 0.5895 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 48: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 48/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6681 - acc: 0.5874 - val_loss: 0.6730 - val_acc: 0.5831 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 49: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 49/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6630 - acc: 0.5882 - val_loss: 0.6728 - val_acc: 0.5831 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 50: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 50/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6689 - acc: 0.5722 - val_loss: 0.6725 - val_acc: 0.5831 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 51: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 51/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6604 - acc: 0.5814 - val_loss: 0.6719 - val_acc: 0.5844 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 52: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 52/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.6650 - acc: 0.5798 - val_loss: 0.6711 - val_acc: 0.5844 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 53: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 53/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6616 - acc: 0.5786 - val_loss: 0.6702 - val_acc: 0.5908 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 54: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 54/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6573 - acc: 0.5754 - val_loss: 0.6692 - val_acc: 0.5946 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 55: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 55/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6607 - acc: 0.5894 - val_loss: 0.6682 - val_acc: 0.5921 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 56: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 56/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6580 - acc: 0.5874 - val_loss: 0.6673 - val_acc: 0.5895 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 57: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 57/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6601 - acc: 0.5786 - val_loss: 0.6667 - val_acc: 0.5997 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 58: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 58/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6549 - acc: 0.5850 - val_loss: 0.6658 - val_acc: 0.6010 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 59: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 59/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.6565 - acc: 0.5782 - val_loss: 0.6655 - val_acc: 0.5972 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 60: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 60/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6563 - acc: 0.5882 - val_loss: 0.6644 - val_acc: 0.5921 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 61: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 61/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6490 - acc: 0.6002 - val_loss: 0.6629 - val_acc: 0.5972 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 62: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 62/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6577 - acc: 0.5814 - val_loss: 0.6622 - val_acc: 0.6049 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 63: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 63/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.6560 - acc: 0.5754 - val_loss: 0.6625 - val_acc: 0.6036 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 64: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 64/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6519 - acc: 0.5834 - val_loss: 0.6620 - val_acc: 0.6010 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 65: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 65/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6590 - acc: 0.5822 - val_loss: 0.6616 - val_acc: 0.6023 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 66: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 66/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6530 - acc: 0.6054 - val_loss: 0.6605 - val_acc: 0.5997 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 67: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 67/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6444 - acc: 0.5994 - val_loss: 0.6591 - val_acc: 0.5997 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 68: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 68/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6525 - acc: 0.5986 - val_loss: 0.6579 - val_acc: 0.6049 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 69: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 69/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6458 - acc: 0.5994 - val_loss: 0.6576 - val_acc: 0.6010 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 70: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 70/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6419 - acc: 0.6054 - val_loss: 0.6573 - val_acc: 0.5997 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 71: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 71/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6498 - acc: 0.5962 - val_loss: 0.6562 - val_acc: 0.5985 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 72: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 72/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6446 - acc: 0.6006 - val_loss: 0.6555 - val_acc: 0.5972 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 73: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 73/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6446 - acc: 0.6014 - val_loss: 0.6547 - val_acc: 0.5985 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 74: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 74/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6483 - acc: 0.6014 - val_loss: 0.6537 - val_acc: 0.5985 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 75: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 75/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6341 - acc: 0.6114 - val_loss: 0.6521 - val_acc: 0.5946 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 76: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 76/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6425 - acc: 0.5998 - val_loss: 0.6513 - val_acc: 0.5985 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 77: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 77/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6330 - acc: 0.6046 - val_loss: 0.6505 - val_acc: 0.5985 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 78: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 78/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6393 - acc: 0.5938 - val_loss: 0.6491 - val_acc: 0.6023 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 79: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 79/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6366 - acc: 0.6174 - val_loss: 0.6484 - val_acc: 0.6074 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 80: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 80/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6430 - acc: 0.5982 - val_loss: 0.6487 - val_acc: 0.6100 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 81: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 81/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6394 - acc: 0.6002 - val_loss: 0.6485 - val_acc: 0.6100 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 82: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 82/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6425 - acc: 0.6058 - val_loss: 0.6480 - val_acc: 0.6176 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 83: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 83/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6409 - acc: 0.5990 - val_loss: 0.6475 - val_acc: 0.6240 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 84: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 84/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6376 - acc: 0.6066 - val_loss: 0.6472 - val_acc: 0.6189 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 85: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 85/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6355 - acc: 0.6122 - val_loss: 0.6467 - val_acc: 0.6164 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 86: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 86/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6434 - acc: 0.6014 - val_loss: 0.6451 - val_acc: 0.6151 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 87: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 87/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6306 - acc: 0.6162 - val_loss: 0.6431 - val_acc: 0.6036 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 88: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 88/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6353 - acc: 0.6154 - val_loss: 0.6413 - val_acc: 0.6061 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 89: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 89/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6232 - acc: 0.6234 - val_loss: 0.6403 - val_acc: 0.6061 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 90: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 90/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6281 - acc: 0.6134 - val_loss: 0.6402 - val_acc: 0.6010 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 91: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 91/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6307 - acc: 0.6122 - val_loss: 0.6404 - val_acc: 0.6074 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 92: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 92/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6243 - acc: 0.6206 - val_loss: 0.6410 - val_acc: 0.6125 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 93: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 93/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6281 - acc: 0.6214 - val_loss: 0.6419 - val_acc: 0.6100 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 94: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 94/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6282 - acc: 0.6066 - val_loss: 0.6411 - val_acc: 0.6138 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 95: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 95/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6327 - acc: 0.6102 - val_loss: 0.6379 - val_acc: 0.6317 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 96: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 96/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6216 - acc: 0.6158 - val_loss: 0.6361 - val_acc: 0.6368 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 97: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 97/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6187 - acc: 0.6178 - val_loss: 0.6344 - val_acc: 0.6343 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 98: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 98/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6251 - acc: 0.6222 - val_loss: 0.6325 - val_acc: 0.6330 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 99: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 99/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6260 - acc: 0.6265 - val_loss: 0.6324 - val_acc: 0.6355 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 100: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 100/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6282 - acc: 0.6238 - val_loss: 0.6331 - val_acc: 0.6240 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 101: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 101/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6191 - acc: 0.6214 - val_loss: 0.6324 - val_acc: 0.6138 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 102: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 102/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6220 - acc: 0.6182 - val_loss: 0.6329 - val_acc: 0.6074 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 103: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 103/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6150 - acc: 0.6337 - val_loss: 0.6333 - val_acc: 0.6113 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 104: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 104/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6194 - acc: 0.6317 - val_loss: 0.6332 - val_acc: 0.5985 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 105: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 105/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6124 - acc: 0.6309 - val_loss: 0.6347 - val_acc: 0.6036 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 106: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 106/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6119 - acc: 0.6309 - val_loss: 0.6362 - val_acc: 0.5997 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 107: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 107/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6166 - acc: 0.6385 - val_loss: 0.6391 - val_acc: 0.5895 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 108: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 108/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6108 - acc: 0.6361 - val_loss: 0.6396 - val_acc: 0.5972 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 109: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 109/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6169 - acc: 0.6389 - val_loss: 0.6372 - val_acc: 0.6010 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 110: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 110/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6113 - acc: 0.6361 - val_loss: 0.6375 - val_acc: 0.5985 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 111: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 111/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6142 - acc: 0.6242 - val_loss: 0.6376 - val_acc: 0.5985 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 112: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 112/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6117 - acc: 0.6349 - val_loss: 0.6376 - val_acc: 0.6049 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 113: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 113/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6058 - acc: 0.6449 - val_loss: 0.6378 - val_acc: 0.6036 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 114: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 114/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6107 - acc: 0.6469 - val_loss: 0.6330 - val_acc: 0.6215 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 115: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 115/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6079 - acc: 0.6349 - val_loss: 0.6316 - val_acc: 0.6151 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 116: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 116/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6023 - acc: 0.6493 - val_loss: 0.6320 - val_acc: 0.6125 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 117: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 117/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6123 - acc: 0.6433 - val_loss: 0.6341 - val_acc: 0.5857 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 118: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 118/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6055 - acc: 0.6441 - val_loss: 0.6308 - val_acc: 0.6164 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 119: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 119/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6013 - acc: 0.6377 - val_loss: 0.6276 - val_acc: 0.6240 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 120: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 120/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5978 - acc: 0.6537 - val_loss: 0.6272 - val_acc: 0.6266 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 121: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 121/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6002 - acc: 0.6481 - val_loss: 0.6238 - val_acc: 0.6189 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 122: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 122/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6043 - acc: 0.6473 - val_loss: 0.6200 - val_acc: 0.6113 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 123: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 123/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6061 - acc: 0.6433 - val_loss: 0.6211 - val_acc: 0.6049 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 124: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 124/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5957 - acc: 0.6505 - val_loss: 0.6204 - val_acc: 0.5946 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 125: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 125/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5961 - acc: 0.6521 - val_loss: 0.6198 - val_acc: 0.5831 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 126: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 126/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6025 - acc: 0.6405 - val_loss: 0.6180 - val_acc: 0.5972 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 127: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 127/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5939 - acc: 0.6545 - val_loss: 0.6153 - val_acc: 0.6228 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 128: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 128/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5949 - acc: 0.6545 - val_loss: 0.6111 - val_acc: 0.6304 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 129: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 129/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5903 - acc: 0.6553 - val_loss: 0.6082 - val_acc: 0.6445 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 130: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 130/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5984 - acc: 0.6389 - val_loss: 0.6075 - val_acc: 0.6496 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 131: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 131/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5891 - acc: 0.6669 - val_loss: 0.6068 - val_acc: 0.6573 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 132: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 132/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5879 - acc: 0.6501 - val_loss: 0.6054 - val_acc: 0.6573 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 133: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 133/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5900 - acc: 0.6553 - val_loss: 0.6050 - val_acc: 0.6611 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 134: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 134/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5865 - acc: 0.6601 - val_loss: 0.6037 - val_acc: 0.6573 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 135: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 135/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5898 - acc: 0.6521 - val_loss: 0.6078 - val_acc: 0.6483 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 136: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 136/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5865 - acc: 0.6701 - val_loss: 0.6097 - val_acc: 0.6535 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 137: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 137/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5912 - acc: 0.6589 - val_loss: 0.6072 - val_acc: 0.6611 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 138: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 138/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5857 - acc: 0.6745 - val_loss: 0.6024 - val_acc: 0.6675 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 139: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 139/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5889 - acc: 0.6685 - val_loss: 0.5989 - val_acc: 0.6586 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 140: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 140/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5811 - acc: 0.6573 - val_loss: 0.5966 - val_acc: 0.6701 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 141: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 141/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5753 - acc: 0.6661 - val_loss: 0.5953 - val_acc: 0.6662 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 142: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 142/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5811 - acc: 0.6689 - val_loss: 0.5946 - val_acc: 0.6586 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 143: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 143/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5723 - acc: 0.6817 - val_loss: 0.5942 - val_acc: 0.6535 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 144: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 144/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5749 - acc: 0.6657 - val_loss: 0.5927 - val_acc: 0.6624 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 145: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 145/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5816 - acc: 0.6865 - val_loss: 0.5917 - val_acc: 0.6598 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 146: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 146/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5736 - acc: 0.6733 - val_loss: 0.5897 - val_acc: 0.6637 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 147: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 147/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5724 - acc: 0.6785 - val_loss: 0.5877 - val_acc: 0.6637 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 148: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 148/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5682 - acc: 0.6861 - val_loss: 0.5859 - val_acc: 0.6726 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 149: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 149/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5723 - acc: 0.6833 - val_loss: 0.5873 - val_acc: 0.6688 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 150: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 150/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5790 - acc: 0.6769 - val_loss: 0.5906 - val_acc: 0.6624 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 151: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 151/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5654 - acc: 0.6817 - val_loss: 0.5915 - val_acc: 0.6598 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 152: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 152/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5647 - acc: 0.6861 - val_loss: 0.5857 - val_acc: 0.6662 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 153: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 153/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5683 - acc: 0.6921 - val_loss: 0.5837 - val_acc: 0.6816 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 154: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 154/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5557 - acc: 0.6905 - val_loss: 0.5824 - val_acc: 0.6765 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 155: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 155/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5600 - acc: 0.6897 - val_loss: 0.5816 - val_acc: 0.6701 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 156: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 156/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5638 - acc: 0.6933 - val_loss: 0.5792 - val_acc: 0.6752 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 157: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 157/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5636 - acc: 0.6869 - val_loss: 0.5786 - val_acc: 0.6714 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 158: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 158/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5607 - acc: 0.6869 - val_loss: 0.5790 - val_acc: 0.6624 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 159: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 159/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5540 - acc: 0.6841 - val_loss: 0.5793 - val_acc: 0.6611 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 160: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 160/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5605 - acc: 0.6897 - val_loss: 0.5769 - val_acc: 0.6611 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 161: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 161/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5582 - acc: 0.6909 - val_loss: 0.5768 - val_acc: 0.6624 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 162: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 162/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5514 - acc: 0.7025 - val_loss: 0.5777 - val_acc: 0.6688 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 163: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 163/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5484 - acc: 0.6953 - val_loss: 0.5782 - val_acc: 0.6701 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 164: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 164/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5511 - acc: 0.6973 - val_loss: 0.5768 - val_acc: 0.6650 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 165: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 165/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5444 - acc: 0.6965 - val_loss: 0.5762 - val_acc: 0.6560 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 166: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 166/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5566 - acc: 0.6905 - val_loss: 0.5758 - val_acc: 0.6637 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 167: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 167/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5530 - acc: 0.6993 - val_loss: 0.5764 - val_acc: 0.6675 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 168: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 168/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5516 - acc: 0.6905 - val_loss: 0.5754 - val_acc: 0.6650 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 169: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 169/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5577 - acc: 0.6981 - val_loss: 0.5756 - val_acc: 0.6675 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 170: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 170/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5576 - acc: 0.6945 - val_loss: 0.5787 - val_acc: 0.6739 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 171: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 171/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5493 - acc: 0.6949 - val_loss: 0.5765 - val_acc: 0.6739 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 172: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 172/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5401 - acc: 0.7117 - val_loss: 0.5715 - val_acc: 0.6714 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 173: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 173/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5397 - acc: 0.6965 - val_loss: 0.5704 - val_acc: 0.6611 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 174: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 174/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5442 - acc: 0.6901 - val_loss: 0.5720 - val_acc: 0.6573 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 175: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 175/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5350 - acc: 0.6957 - val_loss: 0.5719 - val_acc: 0.6752 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 176: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 176/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5343 - acc: 0.7109 - val_loss: 0.5710 - val_acc: 0.6637 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 177: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 177/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5385 - acc: 0.6997 - val_loss: 0.5720 - val_acc: 0.6701 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 178: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 178/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5367 - acc: 0.7093 - val_loss: 0.5731 - val_acc: 0.6752 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 179: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 179/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5321 - acc: 0.7089 - val_loss: 0.5742 - val_acc: 0.6726 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 180: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 180/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5346 - acc: 0.7149 - val_loss: 0.5738 - val_acc: 0.6739 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 181: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 181/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5380 - acc: 0.7125 - val_loss: 0.5743 - val_acc: 0.6752 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 182: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 182/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5388 - acc: 0.7089 - val_loss: 0.5717 - val_acc: 0.6637 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 183: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 183/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5339 - acc: 0.7053 - val_loss: 0.5694 - val_acc: 0.6752 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 184: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 184/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5258 - acc: 0.7105 - val_loss: 0.5681 - val_acc: 0.6726 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 185: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 185/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5277 - acc: 0.7085 - val_loss: 0.5675 - val_acc: 0.6573 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 186: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 186/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5262 - acc: 0.7041 - val_loss: 0.5669 - val_acc: 0.6650 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 187: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 187/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5267 - acc: 0.7177 - val_loss: 0.5699 - val_acc: 0.6637 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 188: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 188/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5253 - acc: 0.7093 - val_loss: 0.5723 - val_acc: 0.6726 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 189: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 189/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5350 - acc: 0.7041 - val_loss: 0.5624 - val_acc: 0.6688 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 190: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 190/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5166 - acc: 0.7129 - val_loss: 0.5618 - val_acc: 0.6688 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 191: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 191/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5281 - acc: 0.7097 - val_loss: 0.5637 - val_acc: 0.6688 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 192: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 192/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5230 - acc: 0.7249 - val_loss: 0.5611 - val_acc: 0.6765 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 193: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 193/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5207 - acc: 0.7137 - val_loss: 0.5592 - val_acc: 0.6790 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 194: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 194/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5167 - acc: 0.7153 - val_loss: 0.5564 - val_acc: 0.6803 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 195: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 195/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5285 - acc: 0.7053 - val_loss: 0.5574 - val_acc: 0.6714 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 196: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 196/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5168 - acc: 0.7193 - val_loss: 0.5566 - val_acc: 0.6893 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 197: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 197/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5240 - acc: 0.7213 - val_loss: 0.5572 - val_acc: 0.6905 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 198: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 198/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5160 - acc: 0.7149 - val_loss: 0.5574 - val_acc: 0.6893 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 199: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 199/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5135 - acc: 0.7129 - val_loss: 0.5562 - val_acc: 0.6880 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 200: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 200/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5162 - acc: 0.7141 - val_loss: 0.5562 - val_acc: 0.6867 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 201: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 201/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5157 - acc: 0.7081 - val_loss: 0.5578 - val_acc: 0.6790 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 202: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 202/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5134 - acc: 0.7169 - val_loss: 0.5573 - val_acc: 0.6765 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 203: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 203/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5217 - acc: 0.7161 - val_loss: 0.5567 - val_acc: 0.6765 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 204: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 204/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5100 - acc: 0.7269 - val_loss: 0.5562 - val_acc: 0.6752 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 205: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 205/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5039 - acc: 0.7241 - val_loss: 0.5557 - val_acc: 0.6726 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 206: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 206/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5039 - acc: 0.7125 - val_loss: 0.5551 - val_acc: 0.6739 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 207: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 207/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5103 - acc: 0.7213 - val_loss: 0.5547 - val_acc: 0.6726 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 208: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 208/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5216 - acc: 0.7141 - val_loss: 0.5547 - val_acc: 0.6701 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 209: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 209/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5190 - acc: 0.7165 - val_loss: 0.5550 - val_acc: 0.6650 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 210: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 210/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5061 - acc: 0.7241 - val_loss: 0.5544 - val_acc: 0.6650 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 211: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 211/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5188 - acc: 0.7205 - val_loss: 0.5539 - val_acc: 0.6662 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 212: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 212/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5073 - acc: 0.7193 - val_loss: 0.5533 - val_acc: 0.6714 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 213: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 213/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5011 - acc: 0.7237 - val_loss: 0.5529 - val_acc: 0.6752 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 214: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 214/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5198 - acc: 0.7277 - val_loss: 0.5522 - val_acc: 0.6739 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 215: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 215/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5157 - acc: 0.7169 - val_loss: 0.5518 - val_acc: 0.6739 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 216: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 216/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5059 - acc: 0.7201 - val_loss: 0.5515 - val_acc: 0.6739 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 217: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 217/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5110 - acc: 0.7285 - val_loss: 0.5513 - val_acc: 0.6726 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 218: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 218/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4990 - acc: 0.7253 - val_loss: 0.5512 - val_acc: 0.6726 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 219: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 219/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5124 - acc: 0.7173 - val_loss: 0.5513 - val_acc: 0.6701 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 220: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 220/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5093 - acc: 0.7161 - val_loss: 0.5512 - val_acc: 0.6701 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 221: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 221/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5011 - acc: 0.7217 - val_loss: 0.5512 - val_acc: 0.6701 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 222: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 222/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4962 - acc: 0.7269 - val_loss: 0.5510 - val_acc: 0.6688 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 223: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 223/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4967 - acc: 0.7321 - val_loss: 0.5508 - val_acc: 0.6675 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 224: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 224/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5006 - acc: 0.7225 - val_loss: 0.5505 - val_acc: 0.6688 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 225: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 225/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5123 - acc: 0.7189 - val_loss: 0.5503 - val_acc: 0.6701 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 226: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 226/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5066 - acc: 0.7257 - val_loss: 0.5503 - val_acc: 0.6701 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 227: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 227/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5132 - acc: 0.7237 - val_loss: 0.5503 - val_acc: 0.6675 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 228: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 228/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5106 - acc: 0.7141 - val_loss: 0.5501 - val_acc: 0.6688 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 229: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 229/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5055 - acc: 0.7189 - val_loss: 0.5499 - val_acc: 0.6688 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 230: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 230/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5103 - acc: 0.7185 - val_loss: 0.5500 - val_acc: 0.6662 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 231: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 231/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5129 - acc: 0.7125 - val_loss: 0.5497 - val_acc: 0.6662 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 232: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 232/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5037 - acc: 0.7241 - val_loss: 0.5493 - val_acc: 0.6675 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 233: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 233/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5063 - acc: 0.7265 - val_loss: 0.5491 - val_acc: 0.6675 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 234: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 234/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5010 - acc: 0.7225 - val_loss: 0.5490 - val_acc: 0.6688 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 235: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 235/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5130 - acc: 0.7177 - val_loss: 0.5492 - val_acc: 0.6688 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 236: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 236/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4988 - acc: 0.7313 - val_loss: 0.5495 - val_acc: 0.6688 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 237: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 237/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5078 - acc: 0.7237 - val_loss: 0.5497 - val_acc: 0.6701 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 238: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 238/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5024 - acc: 0.7253 - val_loss: 0.5497 - val_acc: 0.6701 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 239: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 239/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5101 - acc: 0.7325 - val_loss: 0.5495 - val_acc: 0.6701 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 240: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 240/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5043 - acc: 0.7173 - val_loss: 0.5492 - val_acc: 0.6714 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 241: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 241/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5060 - acc: 0.7189 - val_loss: 0.5490 - val_acc: 0.6688 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 242: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 242/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5008 - acc: 0.7169 - val_loss: 0.5486 - val_acc: 0.6701 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 243: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 243/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5148 - acc: 0.7081 - val_loss: 0.5485 - val_acc: 0.6688 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 244: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 244/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5049 - acc: 0.7285 - val_loss: 0.5489 - val_acc: 0.6650 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 245: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 245/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5035 - acc: 0.7181 - val_loss: 0.5494 - val_acc: 0.6675 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 246: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 246/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4967 - acc: 0.7281 - val_loss: 0.5497 - val_acc: 0.6662 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 247: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 247/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5039 - acc: 0.7317 - val_loss: 0.5494 - val_acc: 0.6662 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 248: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 248/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5121 - acc: 0.7173 - val_loss: 0.5494 - val_acc: 0.6688 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 249: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 249/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5155 - acc: 0.7133 - val_loss: 0.5503 - val_acc: 0.6726 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 250: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 250/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5034 - acc: 0.7321 - val_loss: 0.5511 - val_acc: 0.6777 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 251: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 251/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5050 - acc: 0.7217 - val_loss: 0.5518 - val_acc: 0.6765 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 252: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 252/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4993 - acc: 0.7193 - val_loss: 0.5519 - val_acc: 0.6752 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 253: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 253/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5020 - acc: 0.7189 - val_loss: 0.5513 - val_acc: 0.6765 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 254: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 254/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5024 - acc: 0.7241 - val_loss: 0.5513 - val_acc: 0.6765 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 255: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 255/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5005 - acc: 0.7297 - val_loss: 0.5520 - val_acc: 0.6752 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 256: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 256/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5129 - acc: 0.7241 - val_loss: 0.5521 - val_acc: 0.6752 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 257: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 257/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5017 - acc: 0.7229 - val_loss: 0.5516 - val_acc: 0.6765 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 258: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 258/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5059 - acc: 0.7209 - val_loss: 0.5511 - val_acc: 0.6790 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 259: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 259/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5081 - acc: 0.7121 - val_loss: 0.5502 - val_acc: 0.6777 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 260: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 260/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5096 - acc: 0.7221 - val_loss: 0.5498 - val_acc: 0.6765 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 261: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 261/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4987 - acc: 0.7233 - val_loss: 0.5497 - val_acc: 0.6765 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 262: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 262/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4990 - acc: 0.7301 - val_loss: 0.5502 - val_acc: 0.6790 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 263: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 263/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5127 - acc: 0.7233 - val_loss: 0.5505 - val_acc: 0.6777 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 264: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 264/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4942 - acc: 0.7313 - val_loss: 0.5502 - val_acc: 0.6777 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 265: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 265/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4920 - acc: 0.7389 - val_loss: 0.5499 - val_acc: 0.6765 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 266: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 266/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5022 - acc: 0.7197 - val_loss: 0.5501 - val_acc: 0.6790 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 267: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 267/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5027 - acc: 0.7177 - val_loss: 0.5505 - val_acc: 0.6777 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 268: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 268/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4994 - acc: 0.7345 - val_loss: 0.5507 - val_acc: 0.6752 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 269: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 269/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4993 - acc: 0.7289 - val_loss: 0.5515 - val_acc: 0.6765 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 270: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 270/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5141 - acc: 0.7109 - val_loss: 0.5520 - val_acc: 0.6752 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 271: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 271/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5148 - acc: 0.7189 - val_loss: 0.5512 - val_acc: 0.6739 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 272: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 272/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5089 - acc: 0.7233 - val_loss: 0.5511 - val_acc: 0.6739 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 273: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 273/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5109 - acc: 0.7197 - val_loss: 0.5501 - val_acc: 0.6765 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 274: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 274/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4990 - acc: 0.7377 - val_loss: 0.5490 - val_acc: 0.6790 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 275: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 275/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4999 - acc: 0.7189 - val_loss: 0.5487 - val_acc: 0.6803 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 276: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 276/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5012 - acc: 0.7233 - val_loss: 0.5487 - val_acc: 0.6790 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 277: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 277/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4950 - acc: 0.7313 - val_loss: 0.5488 - val_acc: 0.6777 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 278: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 278/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5061 - acc: 0.7161 - val_loss: 0.5492 - val_acc: 0.6790 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 279: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 279/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5004 - acc: 0.7185 - val_loss: 0.5493 - val_acc: 0.6790 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 280: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 280/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5005 - acc: 0.7221 - val_loss: 0.5489 - val_acc: 0.6777 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 281: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 281/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5048 - acc: 0.7281 - val_loss: 0.5483 - val_acc: 0.6739 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 282: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 282/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5046 - acc: 0.7225 - val_loss: 0.5483 - val_acc: 0.6714 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 283: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 283/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5038 - acc: 0.7245 - val_loss: 0.5488 - val_acc: 0.6752 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 284: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 284/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5085 - acc: 0.7325 - val_loss: 0.5487 - val_acc: 0.6765 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 285: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 285/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4972 - acc: 0.7349 - val_loss: 0.5489 - val_acc: 0.6752 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 286: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 286/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4968 - acc: 0.7285 - val_loss: 0.5493 - val_acc: 0.6777 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 287: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 287/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5015 - acc: 0.7305 - val_loss: 0.5494 - val_acc: 0.6765 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 288: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 288/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5026 - acc: 0.7277 - val_loss: 0.5494 - val_acc: 0.6765 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 289: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 289/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5097 - acc: 0.7189 - val_loss: 0.5485 - val_acc: 0.6765 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 290: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 290/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4960 - acc: 0.7233 - val_loss: 0.5479 - val_acc: 0.6752 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 291: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 291/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4988 - acc: 0.7293 - val_loss: 0.5473 - val_acc: 0.6739 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 292: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 292/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5045 - acc: 0.7241 - val_loss: 0.5474 - val_acc: 0.6777 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 293: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 293/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4927 - acc: 0.7345 - val_loss: 0.5478 - val_acc: 0.6790 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 294: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 294/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4940 - acc: 0.7277 - val_loss: 0.5483 - val_acc: 0.6803 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 295: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 295/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5015 - acc: 0.7221 - val_loss: 0.5485 - val_acc: 0.6816 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 296: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 296/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5064 - acc: 0.7225 - val_loss: 0.5487 - val_acc: 0.6803 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 297: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 297/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5009 - acc: 0.7241 - val_loss: 0.5485 - val_acc: 0.6790 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 298: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 298/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5048 - acc: 0.7193 - val_loss: 0.5482 - val_acc: 0.6790 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 299: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 299/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5035 - acc: 0.7265 - val_loss: 0.5478 - val_acc: 0.6790 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 300: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 300/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5052 - acc: 0.7189 - val_loss: 0.5479 - val_acc: 0.6790 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 301: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 301/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5039 - acc: 0.7353 - val_loss: 0.5481 - val_acc: 0.6803 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 302: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 302/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5018 - acc: 0.7213 - val_loss: 0.5481 - val_acc: 0.6790 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 303: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 303/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4986 - acc: 0.7341 - val_loss: 0.5477 - val_acc: 0.6752 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 304: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 304/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4946 - acc: 0.7277 - val_loss: 0.5475 - val_acc: 0.6752 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 305: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 305/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4953 - acc: 0.7341 - val_loss: 0.5468 - val_acc: 0.6765 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 306: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 306/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4945 - acc: 0.7361 - val_loss: 0.5470 - val_acc: 0.6790 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 307: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 307/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5074 - acc: 0.7277 - val_loss: 0.5474 - val_acc: 0.6790 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 308: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 308/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4956 - acc: 0.7353 - val_loss: 0.5480 - val_acc: 0.6777 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 309: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 309/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5074 - acc: 0.7305 - val_loss: 0.5473 - val_acc: 0.6790 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 310: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 310/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4986 - acc: 0.7301 - val_loss: 0.5471 - val_acc: 0.6790 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 311: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 311/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.4959 - acc: 0.7309 - val_loss: 0.5468 - val_acc: 0.6816 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 312: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 312/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5008 - acc: 0.7305 - val_loss: 0.5469 - val_acc: 0.6790 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 313: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 313/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4943 - acc: 0.7301 - val_loss: 0.5472 - val_acc: 0.6803 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 314: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 314/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4944 - acc: 0.7305 - val_loss: 0.5474 - val_acc: 0.6816 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 315: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 315/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5036 - acc: 0.7237 - val_loss: 0.5473 - val_acc: 0.6803 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 316: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 316/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4986 - acc: 0.7273 - val_loss: 0.5469 - val_acc: 0.6803 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 317: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 317/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4938 - acc: 0.7333 - val_loss: 0.5466 - val_acc: 0.6790 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 318: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 318/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4965 - acc: 0.7253 - val_loss: 0.5466 - val_acc: 0.6777 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 319: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 319/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4980 - acc: 0.7213 - val_loss: 0.5469 - val_acc: 0.6803 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 320: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 320/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4953 - acc: 0.7225 - val_loss: 0.5469 - val_acc: 0.6790 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 321: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 321/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5026 - acc: 0.7249 - val_loss: 0.5465 - val_acc: 0.6765 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 322: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 322/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5046 - acc: 0.7189 - val_loss: 0.5466 - val_acc: 0.6752 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 323: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 323/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5020 - acc: 0.7305 - val_loss: 0.5464 - val_acc: 0.6739 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 324: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 324/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5048 - acc: 0.7257 - val_loss: 0.5467 - val_acc: 0.6752 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 325: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 325/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4942 - acc: 0.7225 - val_loss: 0.5468 - val_acc: 0.6752 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 326: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 326/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5040 - acc: 0.7201 - val_loss: 0.5469 - val_acc: 0.6765 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 327: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 327/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5009 - acc: 0.7217 - val_loss: 0.5468 - val_acc: 0.6752 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 328: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 328/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4938 - acc: 0.7365 - val_loss: 0.5470 - val_acc: 0.6777 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 329: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 329/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4997 - acc: 0.7237 - val_loss: 0.5469 - val_acc: 0.6765 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 330: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 330/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4960 - acc: 0.7417 - val_loss: 0.5472 - val_acc: 0.6765 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 331: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 331/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5008 - acc: 0.7205 - val_loss: 0.5478 - val_acc: 0.6765 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 332: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 332/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4955 - acc: 0.7305 - val_loss: 0.5481 - val_acc: 0.6752 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 333: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 333/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5105 - acc: 0.7241 - val_loss: 0.5484 - val_acc: 0.6752 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 334: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 334/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4837 - acc: 0.7389 - val_loss: 0.5481 - val_acc: 0.6777 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 335: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 335/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4815 - acc: 0.7341 - val_loss: 0.5479 - val_acc: 0.6777 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 336: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 336/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5003 - acc: 0.7317 - val_loss: 0.5480 - val_acc: 0.6777 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 337: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 337/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4943 - acc: 0.7285 - val_loss: 0.5482 - val_acc: 0.6790 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 338: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 338/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4881 - acc: 0.7321 - val_loss: 0.5483 - val_acc: 0.6816 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 339: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 339/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4976 - acc: 0.7377 - val_loss: 0.5486 - val_acc: 0.6816 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 340: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 340/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4926 - acc: 0.7297 - val_loss: 0.5490 - val_acc: 0.6829 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 341: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 341/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4987 - acc: 0.7221 - val_loss: 0.5492 - val_acc: 0.6829 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 342: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 342/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4995 - acc: 0.7297 - val_loss: 0.5495 - val_acc: 0.6829 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 343: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 343/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4967 - acc: 0.7285 - val_loss: 0.5497 - val_acc: 0.6829 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 344: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 344/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4909 - acc: 0.7253 - val_loss: 0.5491 - val_acc: 0.6816 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 345: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 345/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4914 - acc: 0.7389 - val_loss: 0.5483 - val_acc: 0.6790 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 346: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 346/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4894 - acc: 0.7441 - val_loss: 0.5479 - val_acc: 0.6790 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 347: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 347/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5054 - acc: 0.7149 - val_loss: 0.5477 - val_acc: 0.6777 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 348: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 348/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4983 - acc: 0.7281 - val_loss: 0.5476 - val_acc: 0.6765 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 349: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 349/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4964 - acc: 0.7221 - val_loss: 0.5478 - val_acc: 0.6777 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 350: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 350/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4834 - acc: 0.7397 - val_loss: 0.5475 - val_acc: 0.6777 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 351: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 351/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4923 - acc: 0.7253 - val_loss: 0.5470 - val_acc: 0.6790 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 352: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 352/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4873 - acc: 0.7397 - val_loss: 0.5470 - val_acc: 0.6777 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 353: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 353/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5018 - acc: 0.7345 - val_loss: 0.5464 - val_acc: 0.6790 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 354: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 354/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4929 - acc: 0.7389 - val_loss: 0.5464 - val_acc: 0.6790 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 355: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 355/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4997 - acc: 0.7313 - val_loss: 0.5461 - val_acc: 0.6790 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 356: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 356/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4872 - acc: 0.7301 - val_loss: 0.5456 - val_acc: 0.6765 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 357: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 357/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5051 - acc: 0.7361 - val_loss: 0.5451 - val_acc: 0.6752 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 358: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 358/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5015 - acc: 0.7241 - val_loss: 0.5454 - val_acc: 0.6752 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 359: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 359/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4875 - acc: 0.7289 - val_loss: 0.5457 - val_acc: 0.6777 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 360: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 360/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4953 - acc: 0.7213 - val_loss: 0.5451 - val_acc: 0.6765 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 361: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 361/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5075 - acc: 0.7249 - val_loss: 0.5448 - val_acc: 0.6777 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 362: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 362/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4967 - acc: 0.7273 - val_loss: 0.5447 - val_acc: 0.6816 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 363: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 363/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4919 - acc: 0.7473 - val_loss: 0.5444 - val_acc: 0.6816 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 364: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 364/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4977 - acc: 0.7349 - val_loss: 0.5444 - val_acc: 0.6841 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 365: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 365/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4906 - acc: 0.7269 - val_loss: 0.5445 - val_acc: 0.6803 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 366: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 366/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5014 - acc: 0.7277 - val_loss: 0.5447 - val_acc: 0.6803 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 367: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 367/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4950 - acc: 0.7349 - val_loss: 0.5448 - val_acc: 0.6790 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 368: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 368/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4896 - acc: 0.7453 - val_loss: 0.5451 - val_acc: 0.6777 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 369: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 369/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4919 - acc: 0.7309 - val_loss: 0.5451 - val_acc: 0.6777 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 370: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 370/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5019 - acc: 0.7257 - val_loss: 0.5452 - val_acc: 0.6777 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 371: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 371/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4981 - acc: 0.7297 - val_loss: 0.5451 - val_acc: 0.6777 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 372: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 372/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4943 - acc: 0.7413 - val_loss: 0.5452 - val_acc: 0.6816 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 373: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 373/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4928 - acc: 0.7305 - val_loss: 0.5451 - val_acc: 0.6803 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 374: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 374/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4934 - acc: 0.7257 - val_loss: 0.5450 - val_acc: 0.6790 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 375: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 375/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5019 - acc: 0.7269 - val_loss: 0.5448 - val_acc: 0.6765 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 376: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 376/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4990 - acc: 0.7201 - val_loss: 0.5450 - val_acc: 0.6777 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 377: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 377/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4925 - acc: 0.7361 - val_loss: 0.5450 - val_acc: 0.6777 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 378: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 378/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4985 - acc: 0.7257 - val_loss: 0.5448 - val_acc: 0.6777 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 379: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 379/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5019 - acc: 0.7285 - val_loss: 0.5446 - val_acc: 0.6829 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 380: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 380/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4964 - acc: 0.7349 - val_loss: 0.5442 - val_acc: 0.6803 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 381: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 381/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4918 - acc: 0.7361 - val_loss: 0.5441 - val_acc: 0.6803 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 382: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 382/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4988 - acc: 0.7281 - val_loss: 0.5442 - val_acc: 0.6790 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 383: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 383/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4983 - acc: 0.7257 - val_loss: 0.5441 - val_acc: 0.6803 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 384: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 384/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4970 - acc: 0.7309 - val_loss: 0.5440 - val_acc: 0.6816 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 385: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 385/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4878 - acc: 0.7417 - val_loss: 0.5439 - val_acc: 0.6816 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 386: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 386/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5012 - acc: 0.7301 - val_loss: 0.5437 - val_acc: 0.6803 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 387: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 387/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4882 - acc: 0.7377 - val_loss: 0.5439 - val_acc: 0.6803 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 388: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 388/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4984 - acc: 0.7301 - val_loss: 0.5440 - val_acc: 0.6816 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 389: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 389/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4845 - acc: 0.7417 - val_loss: 0.5438 - val_acc: 0.6803 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 390: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 390/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4861 - acc: 0.7333 - val_loss: 0.5437 - val_acc: 0.6777 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 391: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 391/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4873 - acc: 0.7461 - val_loss: 0.5436 - val_acc: 0.6777 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 392: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 392/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4995 - acc: 0.7265 - val_loss: 0.5434 - val_acc: 0.6739 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 393: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 393/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4894 - acc: 0.7273 - val_loss: 0.5434 - val_acc: 0.6739 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 394: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 394/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4980 - acc: 0.7397 - val_loss: 0.5433 - val_acc: 0.6765 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 395: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 395/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5017 - acc: 0.7381 - val_loss: 0.5433 - val_acc: 0.6777 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 396: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 396/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4944 - acc: 0.7349 - val_loss: 0.5433 - val_acc: 0.6765 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 397: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 397/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4922 - acc: 0.7345 - val_loss: 0.5434 - val_acc: 0.6777 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 398: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 398/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4885 - acc: 0.7325 - val_loss: 0.5438 - val_acc: 0.6790 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 399: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 399/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4947 - acc: 0.7297 - val_loss: 0.5438 - val_acc: 0.6790 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 400: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 400/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4981 - acc: 0.7237 - val_loss: 0.5439 - val_acc: 0.6790 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 401: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 401/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4945 - acc: 0.7209 - val_loss: 0.5440 - val_acc: 0.6816 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 402: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 402/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4890 - acc: 0.7349 - val_loss: 0.5437 - val_acc: 0.6790 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 403: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 403/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4805 - acc: 0.7361 - val_loss: 0.5434 - val_acc: 0.6816 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 404: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 404/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5018 - acc: 0.7273 - val_loss: 0.5428 - val_acc: 0.6803 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 405: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 405/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4793 - acc: 0.7361 - val_loss: 0.5424 - val_acc: 0.6816 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 406: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 406/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4937 - acc: 0.7269 - val_loss: 0.5423 - val_acc: 0.6790 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 407: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 407/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4960 - acc: 0.7325 - val_loss: 0.5422 - val_acc: 0.6816 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 408: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 408/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4879 - acc: 0.7305 - val_loss: 0.5423 - val_acc: 0.6816 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 409: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 409/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4869 - acc: 0.7329 - val_loss: 0.5432 - val_acc: 0.6841 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 410: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 410/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4927 - acc: 0.7373 - val_loss: 0.5437 - val_acc: 0.6816 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 411: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 411/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4804 - acc: 0.7373 - val_loss: 0.5434 - val_acc: 0.6829 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 412: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 412/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4987 - acc: 0.7313 - val_loss: 0.5438 - val_acc: 0.6816 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 413: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 413/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4865 - acc: 0.7281 - val_loss: 0.5437 - val_acc: 0.6829 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 414: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 414/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5004 - acc: 0.7285 - val_loss: 0.5438 - val_acc: 0.6854 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 415: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 415/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4807 - acc: 0.7377 - val_loss: 0.5433 - val_acc: 0.6841 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 416: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 416/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4799 - acc: 0.7381 - val_loss: 0.5429 - val_acc: 0.6803 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 417: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 417/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4907 - acc: 0.7305 - val_loss: 0.5426 - val_acc: 0.6765 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 418: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 418/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4998 - acc: 0.7229 - val_loss: 0.5423 - val_acc: 0.6829 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 419: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 419/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4883 - acc: 0.7453 - val_loss: 0.5423 - val_acc: 0.6816 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 420: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 420/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4946 - acc: 0.7361 - val_loss: 0.5432 - val_acc: 0.6816 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 421: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 421/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4806 - acc: 0.7325 - val_loss: 0.5440 - val_acc: 0.6816 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 422: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 422/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4936 - acc: 0.7341 - val_loss: 0.5448 - val_acc: 0.6841 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 423: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 423/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4944 - acc: 0.7317 - val_loss: 0.5445 - val_acc: 0.6803 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 424: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 424/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4900 - acc: 0.7401 - val_loss: 0.5438 - val_acc: 0.6803 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 425: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 425/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4836 - acc: 0.7353 - val_loss: 0.5437 - val_acc: 0.6816 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 426: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 426/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4883 - acc: 0.7317 - val_loss: 0.5438 - val_acc: 0.6829 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 427: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 427/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4829 - acc: 0.7401 - val_loss: 0.5435 - val_acc: 0.6841 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 428: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 428/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4856 - acc: 0.7381 - val_loss: 0.5432 - val_acc: 0.6816 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 429: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 429/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4824 - acc: 0.7425 - val_loss: 0.5434 - val_acc: 0.6816 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 430: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 430/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4924 - acc: 0.7253 - val_loss: 0.5435 - val_acc: 0.6829 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 431: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 431/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4867 - acc: 0.7405 - val_loss: 0.5441 - val_acc: 0.6841 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 432: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 432/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4807 - acc: 0.7353 - val_loss: 0.5438 - val_acc: 0.6841 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 433: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 433/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4791 - acc: 0.7257 - val_loss: 0.5433 - val_acc: 0.6829 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 434: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 434/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4804 - acc: 0.7349 - val_loss: 0.5434 - val_acc: 0.6829 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 435: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 435/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4827 - acc: 0.7449 - val_loss: 0.5426 - val_acc: 0.6854 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 436: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 436/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4875 - acc: 0.7365 - val_loss: 0.5427 - val_acc: 0.6880 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 437: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 437/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4847 - acc: 0.7409 - val_loss: 0.5424 - val_acc: 0.6880 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 438: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 438/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4760 - acc: 0.7437 - val_loss: 0.5425 - val_acc: 0.6829 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 439: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 439/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4907 - acc: 0.7373 - val_loss: 0.5430 - val_acc: 0.6867 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 440: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 440/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4885 - acc: 0.7349 - val_loss: 0.5438 - val_acc: 0.6841 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 441: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 441/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4912 - acc: 0.7233 - val_loss: 0.5433 - val_acc: 0.6854 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 442: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 442/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4956 - acc: 0.7341 - val_loss: 0.5424 - val_acc: 0.6816 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 443: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 443/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4857 - acc: 0.7401 - val_loss: 0.5420 - val_acc: 0.6829 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 444: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 444/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4863 - acc: 0.7325 - val_loss: 0.5421 - val_acc: 0.6829 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 445: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 445/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4972 - acc: 0.7217 - val_loss: 0.5435 - val_acc: 0.6841 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 446: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 446/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4930 - acc: 0.7281 - val_loss: 0.5442 - val_acc: 0.6816 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 447: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 447/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4910 - acc: 0.7337 - val_loss: 0.5442 - val_acc: 0.6816 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 448: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 448/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4932 - acc: 0.7277 - val_loss: 0.5429 - val_acc: 0.6841 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 449: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 449/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4892 - acc: 0.7297 - val_loss: 0.5419 - val_acc: 0.6790 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 450: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 450/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4871 - acc: 0.7457 - val_loss: 0.5411 - val_acc: 0.6790 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 451: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 451/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4918 - acc: 0.7321 - val_loss: 0.5413 - val_acc: 0.6829 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 452: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 452/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4810 - acc: 0.7369 - val_loss: 0.5415 - val_acc: 0.6790 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 453: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 453/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4826 - acc: 0.7325 - val_loss: 0.5413 - val_acc: 0.6803 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 454: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 454/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4887 - acc: 0.7397 - val_loss: 0.5409 - val_acc: 0.6854 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 455: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 455/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4789 - acc: 0.7461 - val_loss: 0.5407 - val_acc: 0.6829 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 456: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 456/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4809 - acc: 0.7281 - val_loss: 0.5404 - val_acc: 0.6816 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 457: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 457/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4783 - acc: 0.7449 - val_loss: 0.5408 - val_acc: 0.6867 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 458: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 458/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4866 - acc: 0.7321 - val_loss: 0.5410 - val_acc: 0.6867 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 459: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 459/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4957 - acc: 0.7357 - val_loss: 0.5409 - val_acc: 0.6841 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 460: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 460/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4912 - acc: 0.7369 - val_loss: 0.5405 - val_acc: 0.6841 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 461: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 461/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4912 - acc: 0.7317 - val_loss: 0.5404 - val_acc: 0.6854 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 462: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 462/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4827 - acc: 0.7309 - val_loss: 0.5401 - val_acc: 0.6867 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 463: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 463/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4934 - acc: 0.7277 - val_loss: 0.5405 - val_acc: 0.6893 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 464: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 464/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4935 - acc: 0.7417 - val_loss: 0.5401 - val_acc: 0.6880 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 465: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 465/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4817 - acc: 0.7257 - val_loss: 0.5401 - val_acc: 0.6854 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 466: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 466/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4854 - acc: 0.7317 - val_loss: 0.5393 - val_acc: 0.6854 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 467: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 467/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4892 - acc: 0.7377 - val_loss: 0.5393 - val_acc: 0.6841 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 468: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 468/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4903 - acc: 0.7221 - val_loss: 0.5390 - val_acc: 0.6880 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 469: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 469/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4879 - acc: 0.7357 - val_loss: 0.5390 - val_acc: 0.6841 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 470: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 470/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4810 - acc: 0.7393 - val_loss: 0.5388 - val_acc: 0.6854 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 471: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 471/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4899 - acc: 0.7305 - val_loss: 0.5386 - val_acc: 0.6880 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 472: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 472/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4917 - acc: 0.7241 - val_loss: 0.5387 - val_acc: 0.6880 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 473: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 473/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4821 - acc: 0.7353 - val_loss: 0.5385 - val_acc: 0.6867 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 474: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 474/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4831 - acc: 0.7373 - val_loss: 0.5384 - val_acc: 0.6880 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 475: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 475/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4896 - acc: 0.7265 - val_loss: 0.5388 - val_acc: 0.6880 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 476: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 476/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4874 - acc: 0.7341 - val_loss: 0.5391 - val_acc: 0.6854 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 477: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 477/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4799 - acc: 0.7401 - val_loss: 0.5395 - val_acc: 0.6918 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 478: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 478/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4828 - acc: 0.7405 - val_loss: 0.5398 - val_acc: 0.6880 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 479: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 479/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4860 - acc: 0.7457 - val_loss: 0.5395 - val_acc: 0.6905 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 480: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 480/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4822 - acc: 0.7353 - val_loss: 0.5388 - val_acc: 0.6905 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 481: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 481/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4814 - acc: 0.7345 - val_loss: 0.5385 - val_acc: 0.6905 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 482: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 482/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4811 - acc: 0.7461 - val_loss: 0.5386 - val_acc: 0.6931 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 483: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 483/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4791 - acc: 0.7393 - val_loss: 0.5384 - val_acc: 0.6957 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 484: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 484/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4780 - acc: 0.7485 - val_loss: 0.5383 - val_acc: 0.6944 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 485: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 485/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4818 - acc: 0.7309 - val_loss: 0.5382 - val_acc: 0.6918 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 486: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 486/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4809 - acc: 0.7441 - val_loss: 0.5381 - val_acc: 0.6944 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 487: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 487/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4842 - acc: 0.7329 - val_loss: 0.5380 - val_acc: 0.6931 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 488: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 488/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4706 - acc: 0.7421 - val_loss: 0.5380 - val_acc: 0.6944 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 489: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 489/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4882 - acc: 0.7385 - val_loss: 0.5380 - val_acc: 0.6931 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 490: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 490/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4805 - acc: 0.7381 - val_loss: 0.5383 - val_acc: 0.6905 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 491: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 491/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4799 - acc: 0.7345 - val_loss: 0.5391 - val_acc: 0.6905 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 492: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 492/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4765 - acc: 0.7457 - val_loss: 0.5400 - val_acc: 0.6905 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 493: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 493/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4918 - acc: 0.7389 - val_loss: 0.5406 - val_acc: 0.6893 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 494: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 494/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4816 - acc: 0.7453 - val_loss: 0.5401 - val_acc: 0.6944 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 495: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 495/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4806 - acc: 0.7433 - val_loss: 0.5395 - val_acc: 0.6918 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 496: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 496/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4817 - acc: 0.7521 - val_loss: 0.5393 - val_acc: 0.6931 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 497: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 497/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4849 - acc: 0.7417 - val_loss: 0.5396 - val_acc: 0.6905 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 498: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 498/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4817 - acc: 0.7377 - val_loss: 0.5398 - val_acc: 0.6893 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 499: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 499/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4747 - acc: 0.7445 - val_loss: 0.5398 - val_acc: 0.6905 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 500: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 500/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4848 - acc: 0.7417 - val_loss: 0.5397 - val_acc: 0.6931 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 501: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 501/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4847 - acc: 0.7453 - val_loss: 0.5393 - val_acc: 0.6918 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 502: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 502/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4854 - acc: 0.7377 - val_loss: 0.5397 - val_acc: 0.6931 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 503: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 503/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4788 - acc: 0.7429 - val_loss: 0.5403 - val_acc: 0.6944 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 504: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 504/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4841 - acc: 0.7401 - val_loss: 0.5403 - val_acc: 0.6931 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 505: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 505/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4789 - acc: 0.7409 - val_loss: 0.5403 - val_acc: 0.6893 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 506: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 506/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4654 - acc: 0.7569 - val_loss: 0.5403 - val_acc: 0.6918 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 507: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 507/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4835 - acc: 0.7377 - val_loss: 0.5401 - val_acc: 0.6893 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 508: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 508/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4802 - acc: 0.7365 - val_loss: 0.5394 - val_acc: 0.6880 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 509: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 509/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4719 - acc: 0.7445 - val_loss: 0.5391 - val_acc: 0.6854 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 510: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 510/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4733 - acc: 0.7489 - val_loss: 0.5389 - val_acc: 0.6867 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 511: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 511/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4743 - acc: 0.7437 - val_loss: 0.5390 - val_acc: 0.6867 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 512: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 512/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4803 - acc: 0.7353 - val_loss: 0.5391 - val_acc: 0.6880 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 513: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 513/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4875 - acc: 0.7309 - val_loss: 0.5384 - val_acc: 0.6816 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 514: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 514/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4696 - acc: 0.7437 - val_loss: 0.5382 - val_acc: 0.6829 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 515: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 515/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4726 - acc: 0.7469 - val_loss: 0.5379 - val_acc: 0.6841 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 516: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 516/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4776 - acc: 0.7421 - val_loss: 0.5377 - val_acc: 0.6829 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 517: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 517/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4792 - acc: 0.7385 - val_loss: 0.5381 - val_acc: 0.6803 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 518: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 518/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4818 - acc: 0.7341 - val_loss: 0.5391 - val_acc: 0.6841 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 519: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 519/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4807 - acc: 0.7509 - val_loss: 0.5408 - val_acc: 0.6841 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 520: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 520/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4723 - acc: 0.7361 - val_loss: 0.5405 - val_acc: 0.6880 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 521: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 521/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4831 - acc: 0.7481 - val_loss: 0.5401 - val_acc: 0.6867 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 522: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 522/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4808 - acc: 0.7345 - val_loss: 0.5393 - val_acc: 0.6867 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 523: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 523/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4724 - acc: 0.7429 - val_loss: 0.5388 - val_acc: 0.6854 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 524: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 524/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4785 - acc: 0.7405 - val_loss: 0.5384 - val_acc: 0.6867 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 525: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 525/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4730 - acc: 0.7481 - val_loss: 0.5386 - val_acc: 0.6880 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 526: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 526/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4795 - acc: 0.7501 - val_loss: 0.5387 - val_acc: 0.6905 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 527: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 527/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4752 - acc: 0.7445 - val_loss: 0.5385 - val_acc: 0.6918 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 528: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 528/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4845 - acc: 0.7433 - val_loss: 0.5383 - val_acc: 0.6905 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 529: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 529/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4794 - acc: 0.7457 - val_loss: 0.5379 - val_acc: 0.6905 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 530: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 530/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4759 - acc: 0.7401 - val_loss: 0.5374 - val_acc: 0.6931 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 531: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 531/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4832 - acc: 0.7385 - val_loss: 0.5373 - val_acc: 0.6957 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 532: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 532/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4798 - acc: 0.7405 - val_loss: 0.5376 - val_acc: 0.6931 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 533: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 533/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4761 - acc: 0.7353 - val_loss: 0.5378 - val_acc: 0.6918 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 534: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 534/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4725 - acc: 0.7465 - val_loss: 0.5378 - val_acc: 0.6931 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 535: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 535/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4705 - acc: 0.7357 - val_loss: 0.5372 - val_acc: 0.6893 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 536: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 536/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4765 - acc: 0.7397 - val_loss: 0.5366 - val_acc: 0.6918 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 537: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 537/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4790 - acc: 0.7397 - val_loss: 0.5368 - val_acc: 0.6905 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 538: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 538/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4691 - acc: 0.7469 - val_loss: 0.5370 - val_acc: 0.6893 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 539: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 539/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4799 - acc: 0.7341 - val_loss: 0.5372 - val_acc: 0.6905 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 540: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 540/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4832 - acc: 0.7397 - val_loss: 0.5376 - val_acc: 0.6880 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 541: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 541/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4668 - acc: 0.7525 - val_loss: 0.5383 - val_acc: 0.6867 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 542: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 542/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4739 - acc: 0.7497 - val_loss: 0.5388 - val_acc: 0.6867 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 543: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 543/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4808 - acc: 0.7493 - val_loss: 0.5388 - val_acc: 0.6841 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 544: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 544/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4774 - acc: 0.7349 - val_loss: 0.5384 - val_acc: 0.6854 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 545: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 545/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4683 - acc: 0.7457 - val_loss: 0.5382 - val_acc: 0.6841 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 546: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 546/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4825 - acc: 0.7473 - val_loss: 0.5384 - val_acc: 0.6854 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 547: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 547/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4717 - acc: 0.7457 - val_loss: 0.5388 - val_acc: 0.6893 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 548: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 548/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4626 - acc: 0.7517 - val_loss: 0.5391 - val_acc: 0.6893 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 549: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 549/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4651 - acc: 0.7517 - val_loss: 0.5388 - val_acc: 0.6905 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 550: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 550/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4822 - acc: 0.7485 - val_loss: 0.5384 - val_acc: 0.6905 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 551: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 551/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4803 - acc: 0.7301 - val_loss: 0.5372 - val_acc: 0.6918 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 552: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 552/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4705 - acc: 0.7449 - val_loss: 0.5372 - val_acc: 0.6905 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 553: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 553/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4773 - acc: 0.7361 - val_loss: 0.5374 - val_acc: 0.6880 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 554: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 554/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4756 - acc: 0.7449 - val_loss: 0.5371 - val_acc: 0.6854 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 555: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 555/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4760 - acc: 0.7521 - val_loss: 0.5366 - val_acc: 0.6918 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 556: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 556/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4716 - acc: 0.7581 - val_loss: 0.5362 - val_acc: 0.6969 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 557: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 557/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4774 - acc: 0.7429 - val_loss: 0.5358 - val_acc: 0.6982 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 558: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 558/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4617 - acc: 0.7561 - val_loss: 0.5355 - val_acc: 0.6982 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 559: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 559/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4771 - acc: 0.7385 - val_loss: 0.5359 - val_acc: 0.6957 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 560: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 560/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4772 - acc: 0.7433 - val_loss: 0.5352 - val_acc: 0.6969 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 561: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 561/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4761 - acc: 0.7457 - val_loss: 0.5347 - val_acc: 0.6957 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 562: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 562/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4681 - acc: 0.7505 - val_loss: 0.5344 - val_acc: 0.6944 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 563: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 563/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4688 - acc: 0.7505 - val_loss: 0.5345 - val_acc: 0.6944 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 564: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 564/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4644 - acc: 0.7489 - val_loss: 0.5347 - val_acc: 0.6957 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 565: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 565/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4649 - acc: 0.7553 - val_loss: 0.5348 - val_acc: 0.6969 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 566: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 566/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4728 - acc: 0.7433 - val_loss: 0.5348 - val_acc: 0.6969 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 567: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 567/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4661 - acc: 0.7505 - val_loss: 0.5352 - val_acc: 0.6969 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 568: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 568/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4682 - acc: 0.7445 - val_loss: 0.5357 - val_acc: 0.6969 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 569: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 569/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4708 - acc: 0.7473 - val_loss: 0.5360 - val_acc: 0.6982 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 570: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 570/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4730 - acc: 0.7521 - val_loss: 0.5359 - val_acc: 0.6957 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 571: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 571/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4690 - acc: 0.7489 - val_loss: 0.5361 - val_acc: 0.6957 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 572: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 572/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4720 - acc: 0.7377 - val_loss: 0.5366 - val_acc: 0.6969 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 573: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 573/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4706 - acc: 0.7441 - val_loss: 0.5375 - val_acc: 0.6918 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 574: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 574/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4865 - acc: 0.7349 - val_loss: 0.5377 - val_acc: 0.6918 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 575: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 575/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4752 - acc: 0.7413 - val_loss: 0.5374 - val_acc: 0.6944 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 576: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 576/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4609 - acc: 0.7637 - val_loss: 0.5376 - val_acc: 0.6944 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 577: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 577/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4615 - acc: 0.7469 - val_loss: 0.5385 - val_acc: 0.6931 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 578: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 578/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4714 - acc: 0.7485 - val_loss: 0.5383 - val_acc: 0.6905 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 579: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 579/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4645 - acc: 0.7513 - val_loss: 0.5374 - val_acc: 0.6957 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 580: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 580/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4678 - acc: 0.7585 - val_loss: 0.5357 - val_acc: 0.6944 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 581: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 581/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4735 - acc: 0.7449 - val_loss: 0.5349 - val_acc: 0.6969 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 582: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 582/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4622 - acc: 0.7485 - val_loss: 0.5344 - val_acc: 0.6969 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 583: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 583/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4635 - acc: 0.7565 - val_loss: 0.5343 - val_acc: 0.6969 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 584: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 584/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4710 - acc: 0.7505 - val_loss: 0.5343 - val_acc: 0.6969 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 585: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 585/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4648 - acc: 0.7577 - val_loss: 0.5344 - val_acc: 0.6957 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 586: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 586/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4712 - acc: 0.7449 - val_loss: 0.5343 - val_acc: 0.6918 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 587: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 587/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4734 - acc: 0.7417 - val_loss: 0.5340 - val_acc: 0.6969 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 588: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 588/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4626 - acc: 0.7549 - val_loss: 0.5337 - val_acc: 0.6982 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 589: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 589/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4571 - acc: 0.7465 - val_loss: 0.5336 - val_acc: 0.6969 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 590: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 590/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4795 - acc: 0.7529 - val_loss: 0.5335 - val_acc: 0.6969 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 591: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 591/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4516 - acc: 0.7609 - val_loss: 0.5333 - val_acc: 0.6957 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 592: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 592/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4598 - acc: 0.7533 - val_loss: 0.5330 - val_acc: 0.6918 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 593: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 593/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4785 - acc: 0.7365 - val_loss: 0.5330 - val_acc: 0.6918 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 594: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 594/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4668 - acc: 0.7497 - val_loss: 0.5330 - val_acc: 0.6918 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 595: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 595/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4605 - acc: 0.7373 - val_loss: 0.5331 - val_acc: 0.6880 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 596: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 596/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4629 - acc: 0.7549 - val_loss: 0.5334 - val_acc: 0.6944 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 597: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 597/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4728 - acc: 0.7377 - val_loss: 0.5335 - val_acc: 0.6982 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 598: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 598/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4647 - acc: 0.7529 - val_loss: 0.5337 - val_acc: 0.6957 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 599: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 599/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4584 - acc: 0.7541 - val_loss: 0.5337 - val_acc: 0.6944 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 600: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 600/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4676 - acc: 0.7505 - val_loss: 0.5336 - val_acc: 0.6931 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 601: LearningRateScheduler setting learning rate to 1.5e-05.\n",
            "Epoch 601/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4606 - acc: 0.7489 - val_loss: 0.5335 - val_acc: 0.6944 - lr: 1.5000e-05\n",
            "\n",
            "Epoch 602: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 602/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4710 - acc: 0.7453 - val_loss: 0.5335 - val_acc: 0.6957 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 603: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 603/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4683 - acc: 0.7533 - val_loss: 0.5334 - val_acc: 0.6969 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 604: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 604/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4637 - acc: 0.7593 - val_loss: 0.5334 - val_acc: 0.6918 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 605: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 605/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4668 - acc: 0.7509 - val_loss: 0.5334 - val_acc: 0.6931 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 606: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 606/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4659 - acc: 0.7545 - val_loss: 0.5334 - val_acc: 0.6944 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 607: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 607/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4599 - acc: 0.7621 - val_loss: 0.5335 - val_acc: 0.6957 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 608: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 608/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4811 - acc: 0.7449 - val_loss: 0.5335 - val_acc: 0.6995 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 609: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 609/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4615 - acc: 0.7481 - val_loss: 0.5336 - val_acc: 0.6969 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 610: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 610/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4755 - acc: 0.7365 - val_loss: 0.5336 - val_acc: 0.6969 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 611: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 611/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4721 - acc: 0.7469 - val_loss: 0.5336 - val_acc: 0.6957 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 612: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 612/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4651 - acc: 0.7437 - val_loss: 0.5336 - val_acc: 0.6957 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 613: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 613/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4715 - acc: 0.7477 - val_loss: 0.5337 - val_acc: 0.6957 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 614: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 614/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4671 - acc: 0.7601 - val_loss: 0.5337 - val_acc: 0.6957 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 615: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 615/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4618 - acc: 0.7573 - val_loss: 0.5337 - val_acc: 0.6957 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 616: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 616/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4639 - acc: 0.7649 - val_loss: 0.5337 - val_acc: 0.6969 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 617: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 617/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4641 - acc: 0.7557 - val_loss: 0.5337 - val_acc: 0.6969 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 618: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 618/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4664 - acc: 0.7537 - val_loss: 0.5338 - val_acc: 0.6944 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 619: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 619/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4637 - acc: 0.7541 - val_loss: 0.5338 - val_acc: 0.6944 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 620: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 620/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4672 - acc: 0.7581 - val_loss: 0.5338 - val_acc: 0.6944 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 621: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 621/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4813 - acc: 0.7397 - val_loss: 0.5339 - val_acc: 0.6957 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 622: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 622/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4752 - acc: 0.7425 - val_loss: 0.5339 - val_acc: 0.6957 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 623: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 623/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4641 - acc: 0.7453 - val_loss: 0.5340 - val_acc: 0.6957 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 624: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 624/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4745 - acc: 0.7437 - val_loss: 0.5340 - val_acc: 0.6944 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 625: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 625/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4625 - acc: 0.7485 - val_loss: 0.5340 - val_acc: 0.6944 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 626: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 626/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4583 - acc: 0.7605 - val_loss: 0.5340 - val_acc: 0.6944 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 627: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 627/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4753 - acc: 0.7433 - val_loss: 0.5341 - val_acc: 0.6944 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 628: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 628/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4597 - acc: 0.7553 - val_loss: 0.5341 - val_acc: 0.6944 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 629: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 629/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4646 - acc: 0.7497 - val_loss: 0.5342 - val_acc: 0.6944 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 630: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 630/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4701 - acc: 0.7497 - val_loss: 0.5341 - val_acc: 0.6944 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 631: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 631/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4673 - acc: 0.7445 - val_loss: 0.5341 - val_acc: 0.6944 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 632: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 632/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4609 - acc: 0.7609 - val_loss: 0.5341 - val_acc: 0.6944 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 633: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 633/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4669 - acc: 0.7525 - val_loss: 0.5341 - val_acc: 0.6957 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 634: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 634/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4726 - acc: 0.7493 - val_loss: 0.5340 - val_acc: 0.6969 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 635: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 635/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4701 - acc: 0.7465 - val_loss: 0.5341 - val_acc: 0.6969 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 636: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 636/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4667 - acc: 0.7473 - val_loss: 0.5341 - val_acc: 0.6969 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 637: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 637/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4598 - acc: 0.7589 - val_loss: 0.5341 - val_acc: 0.6969 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 638: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 638/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4628 - acc: 0.7625 - val_loss: 0.5342 - val_acc: 0.6969 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 639: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 639/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4689 - acc: 0.7457 - val_loss: 0.5341 - val_acc: 0.6969 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 640: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 640/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4621 - acc: 0.7501 - val_loss: 0.5341 - val_acc: 0.6969 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 641: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 641/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4631 - acc: 0.7541 - val_loss: 0.5341 - val_acc: 0.6969 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 642: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 642/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4698 - acc: 0.7537 - val_loss: 0.5341 - val_acc: 0.6957 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 643: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 643/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.4628 - acc: 0.7613 - val_loss: 0.5341 - val_acc: 0.6957 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 644: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 644/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4687 - acc: 0.7545 - val_loss: 0.5340 - val_acc: 0.6969 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 645: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 645/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4720 - acc: 0.7493 - val_loss: 0.5340 - val_acc: 0.6969 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 646: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 646/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4632 - acc: 0.7509 - val_loss: 0.5340 - val_acc: 0.6982 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 647: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 647/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4676 - acc: 0.7489 - val_loss: 0.5340 - val_acc: 0.6969 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 648: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 648/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4596 - acc: 0.7533 - val_loss: 0.5340 - val_acc: 0.6969 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 649: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 649/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4806 - acc: 0.7317 - val_loss: 0.5339 - val_acc: 0.6969 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 650: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 650/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4694 - acc: 0.7449 - val_loss: 0.5339 - val_acc: 0.6969 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 651: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 651/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4760 - acc: 0.7489 - val_loss: 0.5339 - val_acc: 0.6969 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 652: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 652/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4692 - acc: 0.7457 - val_loss: 0.5339 - val_acc: 0.6969 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 653: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 653/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4654 - acc: 0.7525 - val_loss: 0.5339 - val_acc: 0.6969 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 654: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 654/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4607 - acc: 0.7421 - val_loss: 0.5339 - val_acc: 0.6969 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 655: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 655/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4639 - acc: 0.7573 - val_loss: 0.5338 - val_acc: 0.6969 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 656: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 656/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4670 - acc: 0.7533 - val_loss: 0.5338 - val_acc: 0.6969 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 657: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 657/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4632 - acc: 0.7541 - val_loss: 0.5338 - val_acc: 0.6969 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 658: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 658/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4740 - acc: 0.7441 - val_loss: 0.5339 - val_acc: 0.6969 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 659: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 659/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4768 - acc: 0.7461 - val_loss: 0.5339 - val_acc: 0.6969 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 660: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 660/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4728 - acc: 0.7405 - val_loss: 0.5340 - val_acc: 0.6969 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 661: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 661/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4739 - acc: 0.7441 - val_loss: 0.5340 - val_acc: 0.6969 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 662: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 662/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4648 - acc: 0.7553 - val_loss: 0.5340 - val_acc: 0.6969 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 663: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 663/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4585 - acc: 0.7505 - val_loss: 0.5339 - val_acc: 0.6957 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 664: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 664/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4618 - acc: 0.7521 - val_loss: 0.5339 - val_acc: 0.6957 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 665: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 665/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4658 - acc: 0.7541 - val_loss: 0.5340 - val_acc: 0.6969 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 666: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 666/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4561 - acc: 0.7577 - val_loss: 0.5340 - val_acc: 0.6969 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 667: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 667/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4631 - acc: 0.7521 - val_loss: 0.5340 - val_acc: 0.6969 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 668: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 668/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4587 - acc: 0.7577 - val_loss: 0.5340 - val_acc: 0.6969 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 669: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 669/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4658 - acc: 0.7453 - val_loss: 0.5340 - val_acc: 0.6969 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 670: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 670/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4682 - acc: 0.7517 - val_loss: 0.5341 - val_acc: 0.6969 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 671: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 671/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4604 - acc: 0.7461 - val_loss: 0.5341 - val_acc: 0.6969 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 672: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 672/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4731 - acc: 0.7489 - val_loss: 0.5341 - val_acc: 0.6969 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 673: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 673/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4713 - acc: 0.7489 - val_loss: 0.5341 - val_acc: 0.6969 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 674: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 674/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4649 - acc: 0.7549 - val_loss: 0.5340 - val_acc: 0.6969 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 675: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 675/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4615 - acc: 0.7433 - val_loss: 0.5340 - val_acc: 0.6969 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 676: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 676/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4685 - acc: 0.7473 - val_loss: 0.5339 - val_acc: 0.6969 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 677: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 677/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4668 - acc: 0.7565 - val_loss: 0.5339 - val_acc: 0.6957 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 678: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 678/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4662 - acc: 0.7481 - val_loss: 0.5339 - val_acc: 0.6957 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 679: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 679/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4671 - acc: 0.7481 - val_loss: 0.5339 - val_acc: 0.6957 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 680: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 680/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4762 - acc: 0.7461 - val_loss: 0.5339 - val_acc: 0.6944 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 681: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 681/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4674 - acc: 0.7501 - val_loss: 0.5338 - val_acc: 0.6944 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 682: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 682/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4682 - acc: 0.7625 - val_loss: 0.5339 - val_acc: 0.6944 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 683: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 683/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4739 - acc: 0.7545 - val_loss: 0.5339 - val_acc: 0.6944 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 684: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 684/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4633 - acc: 0.7517 - val_loss: 0.5339 - val_acc: 0.6957 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 685: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 685/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4577 - acc: 0.7529 - val_loss: 0.5338 - val_acc: 0.6944 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 686: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 686/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4709 - acc: 0.7589 - val_loss: 0.5338 - val_acc: 0.6969 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 687: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 687/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4700 - acc: 0.7425 - val_loss: 0.5337 - val_acc: 0.6969 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 688: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 688/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4703 - acc: 0.7397 - val_loss: 0.5337 - val_acc: 0.6969 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 689: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 689/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4642 - acc: 0.7549 - val_loss: 0.5338 - val_acc: 0.6969 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 690: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 690/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4644 - acc: 0.7505 - val_loss: 0.5338 - val_acc: 0.6995 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 691: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 691/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4602 - acc: 0.7569 - val_loss: 0.5338 - val_acc: 0.6995 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 692: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 692/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4692 - acc: 0.7513 - val_loss: 0.5338 - val_acc: 0.6982 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 693: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 693/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4622 - acc: 0.7505 - val_loss: 0.5338 - val_acc: 0.6982 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 694: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 694/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4606 - acc: 0.7569 - val_loss: 0.5337 - val_acc: 0.6982 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 695: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 695/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4585 - acc: 0.7501 - val_loss: 0.5338 - val_acc: 0.6982 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 696: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 696/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4693 - acc: 0.7485 - val_loss: 0.5338 - val_acc: 0.6982 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 697: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 697/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4722 - acc: 0.7437 - val_loss: 0.5338 - val_acc: 0.6995 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 698: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 698/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4758 - acc: 0.7417 - val_loss: 0.5338 - val_acc: 0.6995 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 699: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 699/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4783 - acc: 0.7385 - val_loss: 0.5338 - val_acc: 0.6982 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 700: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 700/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4677 - acc: 0.7529 - val_loss: 0.5339 - val_acc: 0.6982 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 701: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 701/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4619 - acc: 0.7525 - val_loss: 0.5339 - val_acc: 0.6969 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 702: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 702/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4640 - acc: 0.7429 - val_loss: 0.5347 - val_acc: 0.6944 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 703: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 703/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4647 - acc: 0.7465 - val_loss: 0.5335 - val_acc: 0.6982 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 704: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 704/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4709 - acc: 0.7481 - val_loss: 0.5332 - val_acc: 0.7020 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 705: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 705/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4640 - acc: 0.7581 - val_loss: 0.5329 - val_acc: 0.7020 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 706: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 706/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4739 - acc: 0.7373 - val_loss: 0.5326 - val_acc: 0.7033 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 707: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 707/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4765 - acc: 0.7437 - val_loss: 0.5325 - val_acc: 0.7046 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 708: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 708/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4691 - acc: 0.7509 - val_loss: 0.5325 - val_acc: 0.7046 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 709: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 709/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4631 - acc: 0.7521 - val_loss: 0.5325 - val_acc: 0.7033 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 710: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 710/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4686 - acc: 0.7489 - val_loss: 0.5329 - val_acc: 0.7020 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 711: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 711/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4669 - acc: 0.7497 - val_loss: 0.5329 - val_acc: 0.7008 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 712: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 712/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4632 - acc: 0.7645 - val_loss: 0.5331 - val_acc: 0.6969 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 713: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 713/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4668 - acc: 0.7597 - val_loss: 0.5339 - val_acc: 0.6995 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 714: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 714/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4653 - acc: 0.7501 - val_loss: 0.5345 - val_acc: 0.7033 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 715: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 715/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4704 - acc: 0.7509 - val_loss: 0.5345 - val_acc: 0.7008 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 716: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 716/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4543 - acc: 0.7649 - val_loss: 0.5339 - val_acc: 0.6995 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 717: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 717/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4607 - acc: 0.7589 - val_loss: 0.5337 - val_acc: 0.6982 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 718: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 718/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4659 - acc: 0.7593 - val_loss: 0.5342 - val_acc: 0.6969 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 719: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 719/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4646 - acc: 0.7549 - val_loss: 0.5338 - val_acc: 0.6995 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 720: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 720/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4550 - acc: 0.7557 - val_loss: 0.5338 - val_acc: 0.6944 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 721: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 721/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4563 - acc: 0.7529 - val_loss: 0.5337 - val_acc: 0.6931 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 722: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 722/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4667 - acc: 0.7505 - val_loss: 0.5337 - val_acc: 0.6944 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 723: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 723/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4582 - acc: 0.7605 - val_loss: 0.5336 - val_acc: 0.6944 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 724: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 724/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4602 - acc: 0.7505 - val_loss: 0.5331 - val_acc: 0.6944 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 725: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 725/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4735 - acc: 0.7441 - val_loss: 0.5329 - val_acc: 0.6944 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 726: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 726/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4516 - acc: 0.7669 - val_loss: 0.5330 - val_acc: 0.7008 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 727: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 727/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4587 - acc: 0.7413 - val_loss: 0.5331 - val_acc: 0.7033 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 728: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 728/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4763 - acc: 0.7369 - val_loss: 0.5329 - val_acc: 0.7008 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 729: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 729/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4728 - acc: 0.7505 - val_loss: 0.5318 - val_acc: 0.6957 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 730: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 730/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4604 - acc: 0.7493 - val_loss: 0.5315 - val_acc: 0.6969 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 731: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 731/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4672 - acc: 0.7521 - val_loss: 0.5316 - val_acc: 0.6944 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 732: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 732/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4684 - acc: 0.7461 - val_loss: 0.5326 - val_acc: 0.7020 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 733: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 733/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4577 - acc: 0.7613 - val_loss: 0.5324 - val_acc: 0.6957 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 734: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 734/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4576 - acc: 0.7545 - val_loss: 0.5325 - val_acc: 0.6944 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 735: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 735/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4589 - acc: 0.7585 - val_loss: 0.5326 - val_acc: 0.6957 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 736: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 736/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4516 - acc: 0.7557 - val_loss: 0.5326 - val_acc: 0.6944 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 737: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 737/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4592 - acc: 0.7589 - val_loss: 0.5323 - val_acc: 0.6982 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 738: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 738/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4586 - acc: 0.7509 - val_loss: 0.5319 - val_acc: 0.7008 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 739: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 739/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4532 - acc: 0.7605 - val_loss: 0.5315 - val_acc: 0.6957 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 740: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 740/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4538 - acc: 0.7561 - val_loss: 0.5315 - val_acc: 0.6969 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 741: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 741/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4602 - acc: 0.7509 - val_loss: 0.5317 - val_acc: 0.7020 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 742: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 742/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4624 - acc: 0.7481 - val_loss: 0.5311 - val_acc: 0.7020 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 743: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 743/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4613 - acc: 0.7593 - val_loss: 0.5314 - val_acc: 0.7046 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 744: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 744/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4591 - acc: 0.7529 - val_loss: 0.5312 - val_acc: 0.7072 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 745: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 745/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4569 - acc: 0.7573 - val_loss: 0.5316 - val_acc: 0.7033 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 746: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 746/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4613 - acc: 0.7613 - val_loss: 0.5320 - val_acc: 0.7046 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 747: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 747/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4582 - acc: 0.7521 - val_loss: 0.5325 - val_acc: 0.7020 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 748: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 748/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4589 - acc: 0.7553 - val_loss: 0.5331 - val_acc: 0.7008 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 749: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 749/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4601 - acc: 0.7501 - val_loss: 0.5338 - val_acc: 0.6995 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 750: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 750/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4549 - acc: 0.7493 - val_loss: 0.5345 - val_acc: 0.6995 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 751: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 751/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4599 - acc: 0.7521 - val_loss: 0.5340 - val_acc: 0.7020 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 752: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 752/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4588 - acc: 0.7685 - val_loss: 0.5340 - val_acc: 0.7008 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 753: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 753/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4567 - acc: 0.7453 - val_loss: 0.5332 - val_acc: 0.6995 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 754: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 754/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4501 - acc: 0.7573 - val_loss: 0.5327 - val_acc: 0.6995 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 755: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 755/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4528 - acc: 0.7541 - val_loss: 0.5321 - val_acc: 0.6995 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 756: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 756/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4525 - acc: 0.7517 - val_loss: 0.5316 - val_acc: 0.6982 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 757: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 757/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4616 - acc: 0.7557 - val_loss: 0.5315 - val_acc: 0.7020 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 758: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 758/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4602 - acc: 0.7553 - val_loss: 0.5313 - val_acc: 0.7008 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 759: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 759/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4604 - acc: 0.7533 - val_loss: 0.5310 - val_acc: 0.6995 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 760: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 760/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4538 - acc: 0.7589 - val_loss: 0.5310 - val_acc: 0.6995 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 761: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 761/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4518 - acc: 0.7561 - val_loss: 0.5313 - val_acc: 0.7008 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 762: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 762/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4504 - acc: 0.7589 - val_loss: 0.5310 - val_acc: 0.6995 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 763: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 763/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4648 - acc: 0.7457 - val_loss: 0.5315 - val_acc: 0.6982 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 764: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 764/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4635 - acc: 0.7509 - val_loss: 0.5318 - val_acc: 0.6982 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 765: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 765/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4533 - acc: 0.7637 - val_loss: 0.5323 - val_acc: 0.7020 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 766: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 766/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4549 - acc: 0.7473 - val_loss: 0.5322 - val_acc: 0.7020 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 767: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 767/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4589 - acc: 0.7537 - val_loss: 0.5310 - val_acc: 0.7059 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 768: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 768/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4462 - acc: 0.7617 - val_loss: 0.5299 - val_acc: 0.7046 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 769: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 769/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4532 - acc: 0.7529 - val_loss: 0.5294 - val_acc: 0.7059 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 770: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 770/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4413 - acc: 0.7529 - val_loss: 0.5292 - val_acc: 0.7008 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 771: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 771/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4588 - acc: 0.7469 - val_loss: 0.5290 - val_acc: 0.6982 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 772: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 772/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4570 - acc: 0.7481 - val_loss: 0.5285 - val_acc: 0.7020 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 773: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 773/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4518 - acc: 0.7573 - val_loss: 0.5287 - val_acc: 0.7059 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 774: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 774/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4604 - acc: 0.7629 - val_loss: 0.5287 - val_acc: 0.7059 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 775: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 775/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4516 - acc: 0.7565 - val_loss: 0.5287 - val_acc: 0.7072 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 776: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 776/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4603 - acc: 0.7553 - val_loss: 0.5281 - val_acc: 0.7033 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 777: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 777/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4535 - acc: 0.7581 - val_loss: 0.5279 - val_acc: 0.7046 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 778: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 778/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4524 - acc: 0.7629 - val_loss: 0.5281 - val_acc: 0.7046 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 779: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 779/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4578 - acc: 0.7541 - val_loss: 0.5278 - val_acc: 0.7072 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 780: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 780/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4526 - acc: 0.7649 - val_loss: 0.5277 - val_acc: 0.7059 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 781: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 781/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4527 - acc: 0.7613 - val_loss: 0.5279 - val_acc: 0.7084 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 782: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 782/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4484 - acc: 0.7645 - val_loss: 0.5278 - val_acc: 0.7084 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 783: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 783/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4504 - acc: 0.7605 - val_loss: 0.5283 - val_acc: 0.7008 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 784: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 784/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4535 - acc: 0.7581 - val_loss: 0.5292 - val_acc: 0.6982 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 785: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 785/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4360 - acc: 0.7701 - val_loss: 0.5301 - val_acc: 0.6931 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 786: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 786/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4468 - acc: 0.7545 - val_loss: 0.5302 - val_acc: 0.6893 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 787: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 787/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4521 - acc: 0.7621 - val_loss: 0.5300 - val_acc: 0.6957 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 788: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 788/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4522 - acc: 0.7605 - val_loss: 0.5303 - val_acc: 0.7097 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 789: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 789/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4534 - acc: 0.7629 - val_loss: 0.5300 - val_acc: 0.7084 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 790: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 790/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4498 - acc: 0.7509 - val_loss: 0.5299 - val_acc: 0.7059 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 791: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 791/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4476 - acc: 0.7613 - val_loss: 0.5298 - val_acc: 0.7059 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 792: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 792/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4521 - acc: 0.7633 - val_loss: 0.5298 - val_acc: 0.7046 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 793: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 793/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4421 - acc: 0.7649 - val_loss: 0.5290 - val_acc: 0.7033 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 794: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 794/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4564 - acc: 0.7505 - val_loss: 0.5288 - val_acc: 0.7020 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 795: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 795/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4503 - acc: 0.7593 - val_loss: 0.5288 - val_acc: 0.6995 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 796: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 796/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4402 - acc: 0.7649 - val_loss: 0.5285 - val_acc: 0.7046 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 797: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 797/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4444 - acc: 0.7561 - val_loss: 0.5281 - val_acc: 0.7046 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 798: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 798/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4396 - acc: 0.7609 - val_loss: 0.5284 - val_acc: 0.7059 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 799: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 799/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4530 - acc: 0.7569 - val_loss: 0.5294 - val_acc: 0.7059 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 800: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 800/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4307 - acc: 0.7725 - val_loss: 0.5285 - val_acc: 0.7072 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 801: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 801/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4340 - acc: 0.7645 - val_loss: 0.5286 - val_acc: 0.7084 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 802: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 802/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4453 - acc: 0.7677 - val_loss: 0.5282 - val_acc: 0.7084 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 803: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 803/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4388 - acc: 0.7625 - val_loss: 0.5287 - val_acc: 0.7072 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 804: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 804/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4432 - acc: 0.7717 - val_loss: 0.5288 - val_acc: 0.7084 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 805: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 805/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4595 - acc: 0.7577 - val_loss: 0.5281 - val_acc: 0.7046 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 806: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 806/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4460 - acc: 0.7761 - val_loss: 0.5278 - val_acc: 0.7059 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 807: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 807/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4492 - acc: 0.7573 - val_loss: 0.5278 - val_acc: 0.7072 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 808: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 808/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4514 - acc: 0.7549 - val_loss: 0.5275 - val_acc: 0.7059 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 809: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 809/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4398 - acc: 0.7761 - val_loss: 0.5273 - val_acc: 0.7046 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 810: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 810/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4493 - acc: 0.7593 - val_loss: 0.5273 - val_acc: 0.7008 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 811: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 811/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4424 - acc: 0.7545 - val_loss: 0.5273 - val_acc: 0.6995 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 812: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 812/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4460 - acc: 0.7661 - val_loss: 0.5275 - val_acc: 0.7046 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 813: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 813/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4506 - acc: 0.7525 - val_loss: 0.5275 - val_acc: 0.7020 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 814: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 814/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4398 - acc: 0.7629 - val_loss: 0.5277 - val_acc: 0.7020 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 815: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 815/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4532 - acc: 0.7661 - val_loss: 0.5280 - val_acc: 0.7020 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 816: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 816/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4480 - acc: 0.7665 - val_loss: 0.5284 - val_acc: 0.7020 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 817: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 817/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4554 - acc: 0.7601 - val_loss: 0.5286 - val_acc: 0.7008 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 818: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 818/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4400 - acc: 0.7757 - val_loss: 0.5289 - val_acc: 0.6995 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 819: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 819/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4477 - acc: 0.7729 - val_loss: 0.5288 - val_acc: 0.6982 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 820: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 820/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4363 - acc: 0.7705 - val_loss: 0.5288 - val_acc: 0.6995 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 821: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 821/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4382 - acc: 0.7605 - val_loss: 0.5295 - val_acc: 0.6969 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 822: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 822/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4366 - acc: 0.7657 - val_loss: 0.5291 - val_acc: 0.7020 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 823: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 823/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4361 - acc: 0.7605 - val_loss: 0.5287 - val_acc: 0.7020 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 824: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 824/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4496 - acc: 0.7577 - val_loss: 0.5279 - val_acc: 0.7020 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 825: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 825/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4456 - acc: 0.7573 - val_loss: 0.5276 - val_acc: 0.6995 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 826: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 826/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4421 - acc: 0.7641 - val_loss: 0.5282 - val_acc: 0.6995 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 827: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 827/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4390 - acc: 0.7569 - val_loss: 0.5281 - val_acc: 0.6982 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 828: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 828/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4384 - acc: 0.7725 - val_loss: 0.5285 - val_acc: 0.6995 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 829: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 829/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4569 - acc: 0.7601 - val_loss: 0.5279 - val_acc: 0.6982 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 830: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 830/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4357 - acc: 0.7665 - val_loss: 0.5273 - val_acc: 0.6944 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 831: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 831/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4446 - acc: 0.7549 - val_loss: 0.5273 - val_acc: 0.7072 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 832: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 832/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4525 - acc: 0.7493 - val_loss: 0.5277 - val_acc: 0.7046 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 833: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 833/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4437 - acc: 0.7621 - val_loss: 0.5285 - val_acc: 0.7059 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 834: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 834/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4384 - acc: 0.7705 - val_loss: 0.5273 - val_acc: 0.7084 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 835: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 835/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4423 - acc: 0.7705 - val_loss: 0.5274 - val_acc: 0.7110 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 836: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 836/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4442 - acc: 0.7685 - val_loss: 0.5272 - val_acc: 0.7097 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 837: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 837/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4479 - acc: 0.7713 - val_loss: 0.5276 - val_acc: 0.6982 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 838: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 838/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4387 - acc: 0.7629 - val_loss: 0.5290 - val_acc: 0.6957 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 839: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 839/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4351 - acc: 0.7645 - val_loss: 0.5294 - val_acc: 0.6982 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 840: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 840/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4464 - acc: 0.7693 - val_loss: 0.5299 - val_acc: 0.7008 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 841: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 841/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4418 - acc: 0.7565 - val_loss: 0.5302 - val_acc: 0.7084 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 842: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 842/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4372 - acc: 0.7621 - val_loss: 0.5299 - val_acc: 0.7020 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 843: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 843/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4429 - acc: 0.7645 - val_loss: 0.5298 - val_acc: 0.7008 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 844: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 844/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4405 - acc: 0.7657 - val_loss: 0.5293 - val_acc: 0.6995 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 845: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 845/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4390 - acc: 0.7629 - val_loss: 0.5289 - val_acc: 0.6982 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 846: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 846/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4309 - acc: 0.7745 - val_loss: 0.5285 - val_acc: 0.6957 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 847: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 847/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4364 - acc: 0.7765 - val_loss: 0.5285 - val_acc: 0.7020 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 848: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 848/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4354 - acc: 0.7701 - val_loss: 0.5281 - val_acc: 0.7046 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 849: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 849/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4239 - acc: 0.7701 - val_loss: 0.5285 - val_acc: 0.7033 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 850: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 850/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4207 - acc: 0.7861 - val_loss: 0.5295 - val_acc: 0.7059 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 851: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 851/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4394 - acc: 0.7685 - val_loss: 0.5292 - val_acc: 0.7072 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 852: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 852/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4271 - acc: 0.7661 - val_loss: 0.5287 - val_acc: 0.7084 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 853: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 853/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4331 - acc: 0.7773 - val_loss: 0.5303 - val_acc: 0.7084 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 854: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 854/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4492 - acc: 0.7621 - val_loss: 0.5305 - val_acc: 0.7072 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 855: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 855/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4443 - acc: 0.7657 - val_loss: 0.5298 - val_acc: 0.7059 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 856: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 856/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4502 - acc: 0.7645 - val_loss: 0.5290 - val_acc: 0.7059 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 857: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 857/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4324 - acc: 0.7729 - val_loss: 0.5288 - val_acc: 0.7046 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 858: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 858/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4292 - acc: 0.7813 - val_loss: 0.5284 - val_acc: 0.7046 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 859: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 859/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.4416 - acc: 0.7561 - val_loss: 0.5294 - val_acc: 0.7008 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 860: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 860/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4345 - acc: 0.7633 - val_loss: 0.5285 - val_acc: 0.7033 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 861: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 861/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4385 - acc: 0.7601 - val_loss: 0.5271 - val_acc: 0.7046 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 862: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 862/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4349 - acc: 0.7777 - val_loss: 0.5281 - val_acc: 0.6995 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 863: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 863/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4401 - acc: 0.7537 - val_loss: 0.5297 - val_acc: 0.6982 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 864: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 864/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4368 - acc: 0.7585 - val_loss: 0.5289 - val_acc: 0.7033 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 865: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 865/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4241 - acc: 0.7741 - val_loss: 0.5297 - val_acc: 0.7033 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 866: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 866/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4326 - acc: 0.7733 - val_loss: 0.5281 - val_acc: 0.7059 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 867: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 867/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4373 - acc: 0.7721 - val_loss: 0.5293 - val_acc: 0.7033 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 868: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 868/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4410 - acc: 0.7645 - val_loss: 0.5333 - val_acc: 0.6957 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 869: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 869/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4389 - acc: 0.7685 - val_loss: 0.5305 - val_acc: 0.7008 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 870: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 870/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4416 - acc: 0.7721 - val_loss: 0.5284 - val_acc: 0.7084 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 871: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 871/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4364 - acc: 0.7669 - val_loss: 0.5283 - val_acc: 0.7072 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 872: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 872/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4329 - acc: 0.7737 - val_loss: 0.5281 - val_acc: 0.7059 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 873: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 873/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4293 - acc: 0.7657 - val_loss: 0.5285 - val_acc: 0.7072 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 874: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 874/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4297 - acc: 0.7677 - val_loss: 0.5286 - val_acc: 0.7033 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 875: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 875/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4313 - acc: 0.7793 - val_loss: 0.5288 - val_acc: 0.7046 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 876: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 876/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4315 - acc: 0.7661 - val_loss: 0.5285 - val_acc: 0.6982 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 877: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 877/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4329 - acc: 0.7673 - val_loss: 0.5286 - val_acc: 0.7033 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 878: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 878/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4357 - acc: 0.7609 - val_loss: 0.5290 - val_acc: 0.7046 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 879: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 879/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4251 - acc: 0.7745 - val_loss: 0.5287 - val_acc: 0.7123 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 880: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 880/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4296 - acc: 0.7681 - val_loss: 0.5266 - val_acc: 0.7110 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 881: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 881/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4292 - acc: 0.7669 - val_loss: 0.5258 - val_acc: 0.7097 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 882: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 882/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4242 - acc: 0.7789 - val_loss: 0.5257 - val_acc: 0.7097 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 883: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 883/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4255 - acc: 0.7685 - val_loss: 0.5264 - val_acc: 0.6957 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 884: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 884/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4390 - acc: 0.7653 - val_loss: 0.5250 - val_acc: 0.7072 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 885: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 885/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4220 - acc: 0.7757 - val_loss: 0.5248 - val_acc: 0.7059 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 886: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 886/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4269 - acc: 0.7709 - val_loss: 0.5253 - val_acc: 0.7072 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 887: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 887/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4328 - acc: 0.7757 - val_loss: 0.5253 - val_acc: 0.7046 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 888: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 888/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4152 - acc: 0.7861 - val_loss: 0.5254 - val_acc: 0.7123 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 889: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 889/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4247 - acc: 0.7713 - val_loss: 0.5254 - val_acc: 0.7123 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 890: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 890/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4222 - acc: 0.7873 - val_loss: 0.5255 - val_acc: 0.7110 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 891: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 891/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4243 - acc: 0.7873 - val_loss: 0.5264 - val_acc: 0.7136 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 892: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 892/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4340 - acc: 0.7757 - val_loss: 0.5271 - val_acc: 0.7161 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 893: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 893/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4189 - acc: 0.7789 - val_loss: 0.5293 - val_acc: 0.7059 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 894: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 894/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4126 - acc: 0.7829 - val_loss: 0.5307 - val_acc: 0.7059 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 895: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 895/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4377 - acc: 0.7657 - val_loss: 0.5299 - val_acc: 0.7084 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 896: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 896/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4304 - acc: 0.7801 - val_loss: 0.5285 - val_acc: 0.7110 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 897: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 897/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4093 - acc: 0.7893 - val_loss: 0.5298 - val_acc: 0.7123 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 898: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 898/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4160 - acc: 0.7813 - val_loss: 0.5299 - val_acc: 0.7084 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 899: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 899/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4323 - acc: 0.7769 - val_loss: 0.5297 - val_acc: 0.7072 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 900: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 900/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4051 - acc: 0.7917 - val_loss: 0.5296 - val_acc: 0.7110 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 901: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 901/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4224 - acc: 0.7749 - val_loss: 0.5284 - val_acc: 0.7148 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 902: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 902/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4291 - acc: 0.7793 - val_loss: 0.5281 - val_acc: 0.7174 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 903: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 903/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4170 - acc: 0.7817 - val_loss: 0.5285 - val_acc: 0.7161 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 904: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 904/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4152 - acc: 0.7897 - val_loss: 0.5286 - val_acc: 0.7148 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 905: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 905/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4203 - acc: 0.7761 - val_loss: 0.5285 - val_acc: 0.7136 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 906: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 906/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4204 - acc: 0.7801 - val_loss: 0.5288 - val_acc: 0.7123 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 907: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 907/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4238 - acc: 0.7733 - val_loss: 0.5338 - val_acc: 0.7020 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 908: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 908/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4151 - acc: 0.7781 - val_loss: 0.5331 - val_acc: 0.6982 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 909: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 909/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4270 - acc: 0.7817 - val_loss: 0.5310 - val_acc: 0.7020 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 910: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 910/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4298 - acc: 0.7725 - val_loss: 0.5272 - val_acc: 0.7084 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 911: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 911/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4212 - acc: 0.7845 - val_loss: 0.5255 - val_acc: 0.7136 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 912: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 912/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4262 - acc: 0.7785 - val_loss: 0.5245 - val_acc: 0.7084 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 913: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 913/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4157 - acc: 0.7817 - val_loss: 0.5243 - val_acc: 0.7148 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 914: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 914/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4167 - acc: 0.7769 - val_loss: 0.5245 - val_acc: 0.7123 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 915: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 915/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4291 - acc: 0.7677 - val_loss: 0.5276 - val_acc: 0.7123 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 916: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 916/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4246 - acc: 0.7729 - val_loss: 0.5295 - val_acc: 0.7072 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 917: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 917/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4103 - acc: 0.7865 - val_loss: 0.5303 - val_acc: 0.7072 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 918: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 918/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4016 - acc: 0.7925 - val_loss: 0.5269 - val_acc: 0.7097 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 919: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 919/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4191 - acc: 0.7733 - val_loss: 0.5257 - val_acc: 0.7097 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 920: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 920/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4125 - acc: 0.7849 - val_loss: 0.5285 - val_acc: 0.7046 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 921: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 921/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4189 - acc: 0.7869 - val_loss: 0.5293 - val_acc: 0.7072 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 922: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 922/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4044 - acc: 0.7861 - val_loss: 0.5311 - val_acc: 0.7097 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 923: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 923/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4170 - acc: 0.7917 - val_loss: 0.5290 - val_acc: 0.7046 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 924: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 924/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4060 - acc: 0.7861 - val_loss: 0.5272 - val_acc: 0.7059 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 925: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 925/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4124 - acc: 0.7785 - val_loss: 0.5266 - val_acc: 0.7046 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 926: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 926/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4104 - acc: 0.7841 - val_loss: 0.5272 - val_acc: 0.7110 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 927: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 927/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4201 - acc: 0.7829 - val_loss: 0.5262 - val_acc: 0.7097 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 928: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 928/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4146 - acc: 0.7821 - val_loss: 0.5262 - val_acc: 0.7136 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 929: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 929/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4125 - acc: 0.7753 - val_loss: 0.5263 - val_acc: 0.7136 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 930: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 930/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4249 - acc: 0.7749 - val_loss: 0.5269 - val_acc: 0.7059 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 931: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 931/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4220 - acc: 0.7761 - val_loss: 0.5278 - val_acc: 0.7097 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 932: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 932/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4167 - acc: 0.7837 - val_loss: 0.5304 - val_acc: 0.7072 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 933: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 933/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4130 - acc: 0.7773 - val_loss: 0.5320 - val_acc: 0.7046 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 934: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 934/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4186 - acc: 0.7725 - val_loss: 0.5320 - val_acc: 0.7033 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 935: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 935/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4135 - acc: 0.7777 - val_loss: 0.5300 - val_acc: 0.7033 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 936: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 936/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4258 - acc: 0.7793 - val_loss: 0.5297 - val_acc: 0.7008 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 937: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 937/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4208 - acc: 0.7785 - val_loss: 0.5297 - val_acc: 0.7059 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 938: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 938/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4072 - acc: 0.7889 - val_loss: 0.5334 - val_acc: 0.7072 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 939: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 939/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4154 - acc: 0.7793 - val_loss: 0.5322 - val_acc: 0.7097 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 940: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 940/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4194 - acc: 0.7793 - val_loss: 0.5310 - val_acc: 0.7110 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 941: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 941/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4169 - acc: 0.7789 - val_loss: 0.5287 - val_acc: 0.7059 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 942: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 942/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.4141 - acc: 0.7765 - val_loss: 0.5284 - val_acc: 0.7072 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 943: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 943/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4148 - acc: 0.7753 - val_loss: 0.5278 - val_acc: 0.7084 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 944: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 944/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.4144 - acc: 0.7817 - val_loss: 0.5280 - val_acc: 0.7097 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 945: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 945/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4099 - acc: 0.7837 - val_loss: 0.5298 - val_acc: 0.7084 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 946: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 946/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4008 - acc: 0.7857 - val_loss: 0.5287 - val_acc: 0.7148 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 947: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 947/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4117 - acc: 0.7873 - val_loss: 0.5279 - val_acc: 0.7123 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 948: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 948/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4153 - acc: 0.7865 - val_loss: 0.5326 - val_acc: 0.7097 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 949: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 949/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4083 - acc: 0.7881 - val_loss: 0.5358 - val_acc: 0.7097 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 950: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 950/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4108 - acc: 0.7833 - val_loss: 0.5327 - val_acc: 0.7136 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 951: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 951/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4038 - acc: 0.7901 - val_loss: 0.5273 - val_acc: 0.7161 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 952: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 952/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4161 - acc: 0.7809 - val_loss: 0.5266 - val_acc: 0.7161 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 953: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 953/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4059 - acc: 0.7877 - val_loss: 0.5258 - val_acc: 0.7174 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 954: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 954/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4063 - acc: 0.7877 - val_loss: 0.5250 - val_acc: 0.7110 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 955: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 955/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4142 - acc: 0.7897 - val_loss: 0.5270 - val_acc: 0.7174 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 956: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 956/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3979 - acc: 0.7913 - val_loss: 0.5381 - val_acc: 0.7020 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 957: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 957/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4085 - acc: 0.7849 - val_loss: 0.5379 - val_acc: 0.7020 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 958: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 958/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4104 - acc: 0.7929 - val_loss: 0.5321 - val_acc: 0.7059 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 959: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 959/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3866 - acc: 0.8005 - val_loss: 0.5282 - val_acc: 0.7033 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 960: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 960/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4004 - acc: 0.7893 - val_loss: 0.5266 - val_acc: 0.7059 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 961: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 961/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4144 - acc: 0.7757 - val_loss: 0.5272 - val_acc: 0.7097 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 962: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 962/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3954 - acc: 0.7841 - val_loss: 0.5283 - val_acc: 0.7072 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 963: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 963/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3957 - acc: 0.7961 - val_loss: 0.5289 - val_acc: 0.7072 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 964: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 964/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4158 - acc: 0.7781 - val_loss: 0.5294 - val_acc: 0.7072 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 965: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 965/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4003 - acc: 0.7929 - val_loss: 0.5292 - val_acc: 0.7072 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 966: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 966/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3974 - acc: 0.7965 - val_loss: 0.5299 - val_acc: 0.7110 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 967: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 967/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3951 - acc: 0.7897 - val_loss: 0.5320 - val_acc: 0.7110 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 968: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 968/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4072 - acc: 0.7841 - val_loss: 0.5334 - val_acc: 0.7136 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 969: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 969/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.3994 - acc: 0.7901 - val_loss: 0.5324 - val_acc: 0.7123 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 970: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 970/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4091 - acc: 0.7857 - val_loss: 0.5305 - val_acc: 0.7059 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 971: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 971/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4001 - acc: 0.7869 - val_loss: 0.5288 - val_acc: 0.7097 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 972: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 972/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3880 - acc: 0.7929 - val_loss: 0.5283 - val_acc: 0.7148 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 973: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 973/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3935 - acc: 0.7957 - val_loss: 0.5292 - val_acc: 0.7123 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 974: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 974/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4056 - acc: 0.7857 - val_loss: 0.5298 - val_acc: 0.7148 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 975: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 975/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.3943 - acc: 0.7849 - val_loss: 0.5299 - val_acc: 0.7148 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 976: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 976/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3989 - acc: 0.7949 - val_loss: 0.5298 - val_acc: 0.7174 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 977: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 977/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.3820 - acc: 0.8021 - val_loss: 0.5312 - val_acc: 0.7174 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 978: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 978/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4078 - acc: 0.7821 - val_loss: 0.5307 - val_acc: 0.7148 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 979: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 979/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3836 - acc: 0.7949 - val_loss: 0.5311 - val_acc: 0.7148 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 980: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 980/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4011 - acc: 0.7849 - val_loss: 0.5322 - val_acc: 0.7110 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 981: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 981/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3975 - acc: 0.7949 - val_loss: 0.5325 - val_acc: 0.7123 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 982: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 982/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3939 - acc: 0.7969 - val_loss: 0.5323 - val_acc: 0.7148 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 983: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 983/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3974 - acc: 0.7949 - val_loss: 0.5330 - val_acc: 0.7161 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 984: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 984/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3943 - acc: 0.7985 - val_loss: 0.5319 - val_acc: 0.7161 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 985: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 985/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3965 - acc: 0.7917 - val_loss: 0.5298 - val_acc: 0.7097 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 986: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 986/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4020 - acc: 0.7901 - val_loss: 0.5286 - val_acc: 0.7110 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 987: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 987/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3903 - acc: 0.7953 - val_loss: 0.5275 - val_acc: 0.7161 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 988: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 988/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3855 - acc: 0.8077 - val_loss: 0.5273 - val_acc: 0.7148 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 989: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 989/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3861 - acc: 0.8037 - val_loss: 0.5276 - val_acc: 0.7187 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 990: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 990/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4068 - acc: 0.7893 - val_loss: 0.5302 - val_acc: 0.7212 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 991: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 991/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3927 - acc: 0.7877 - val_loss: 0.5316 - val_acc: 0.7187 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 992: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 992/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3823 - acc: 0.7965 - val_loss: 0.5316 - val_acc: 0.7187 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 993: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 993/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3848 - acc: 0.8069 - val_loss: 0.5327 - val_acc: 0.7136 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 994: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 994/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3912 - acc: 0.7945 - val_loss: 0.5327 - val_acc: 0.7161 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 995: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 995/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3887 - acc: 0.7993 - val_loss: 0.5337 - val_acc: 0.7136 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 996: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 996/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3753 - acc: 0.8005 - val_loss: 0.5325 - val_acc: 0.7174 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 997: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 997/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3818 - acc: 0.7861 - val_loss: 0.5325 - val_acc: 0.7084 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 998: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 998/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3881 - acc: 0.7953 - val_loss: 0.5329 - val_acc: 0.7097 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 999: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 999/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3886 - acc: 0.8037 - val_loss: 0.5323 - val_acc: 0.7174 - lr: 4.0000e-05\n",
            "\n",
            "Epoch 1000: LearningRateScheduler setting learning rate to 4e-05.\n",
            "Epoch 1000/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3893 - acc: 0.7945 - val_loss: 0.5310 - val_acc: 0.7187 - lr: 4.0000e-05\n"
          ]
        }
      ],
      "source": [
        "history_simple = model_simple.fit(X_train,\n",
        "                                  y_train,\n",
        "                                  validation_data = (X_val, y_val),\n",
        "                                  callbacks = [callback],\n",
        "                                  epochs = 1000,\n",
        "                                  batch_size = 512)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# list all data in history_simple\n",
        "print(history_simple.history.keys())\n",
        "# summarize history_simple for accuracy\n",
        "plt.plot(history_simple.history['acc'])\n",
        "plt.plot(history_simple.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history_simple for loss\n",
        "plt.plot(history_simple.history['loss'])\n",
        "plt.plot(history_simple.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 945
        },
        "id": "sr4el_Y2P4AW",
        "outputId": "76c001fc-8dd1-4e14-ff92-32a62aac3523"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'acc', 'val_loss', 'val_acc', 'lr'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model because it has a balanced performance\n",
        "model_simple.save(\"/content/drive/MyDrive/models/base_model_noLST.keras\")\n",
        "\n",
        "# Save history of base model\n",
        "with open('/content/drive/MyDrive/models/base_model_history_noLST', 'wb') as file_pi:\n",
        "    pickle.dump(history_simple.history, file_pi)"
      ],
      "metadata": {
        "id": "SIKg72gU1KxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next I'll continue the training of the simple model but with a different learning schedule."
      ],
      "metadata": {
        "id": "7JP22Z7jpvzS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_simple_c = Sequential()\n",
        "\n",
        "# 1st Conv Layer\n",
        "model_simple_c.add(Conv2D(32, (2, 2), padding = \"same\", strides = (1, 1), input_shape = (20, 20, 13)))\n",
        "model_simple_c.add(BatchNormalization())\n",
        "model_simple_c.add(Activation(\"relu\"))\n",
        "model_simple_c.add(Dropout(0.2))\n",
        "\n",
        "# 2nd Conv layer\n",
        "model_simple_c.add(Conv2D(64, (4, 4), padding = \"same\", strides = (1, 1)))\n",
        "model_simple_c.add(BatchNormalization())\n",
        "model_simple_c.add(Activation(\"relu\"))\n",
        "model_simple_c.add(Dropout(0.5))\n",
        "\n",
        "# 3rd Conv layer\n",
        "model_simple_c.add(Conv2D(128, (2, 2), padding = \"same\", strides = (2, 2)))\n",
        "model_simple_c.add(BatchNormalization())\n",
        "model_simple_c.add(Activation(\"relu\"))\n",
        "model_simple_c.add(Dropout(0.5))\n",
        "model_simple_c.add(MaxPool2D(2, 2))\n",
        "\n",
        "# Dense layer\n",
        "model_simple_c.add(Flatten())\n",
        "model_simple_c.add(Dense(256))\n",
        "model_simple_c.add(Activation(\"relu\"))\n",
        "model_simple_c.add(Dropout(0.6))\n",
        "model_simple_c.add(Dense(512))\n",
        "model_simple_c.add(Activation(\"relu\"))\n",
        "model_simple_c.add(Dropout(0.3))\n",
        "model_simple_c.add(Dense(1))\n",
        "model_simple_c.add(Activation(\"sigmoid\"))\n",
        "\n",
        "model_simple_c.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ummjdK9d1_NS",
        "outputId": "232144b5-0936-45c4-c860-fc410619d193"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           (None, 20, 20, 32)        1696      \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 20, 20, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 20, 20, 32)        0         \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 20, 20, 32)        0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 20, 20, 64)        32832     \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 20, 20, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 20, 20, 64)        0         \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 20, 20, 64)        0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 10, 10, 128)       32896     \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 10, 10, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 10, 10, 128)       0         \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 10, 10, 128)       0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 5, 5, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 3200)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 256)               819456    \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 512)               131584    \n",
            "                                                                 \n",
            " activation_10 (Activation)  (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 513       \n",
            "                                                                 \n",
            " activation_11 (Activation)  (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,019,873\n",
            "Trainable params: 1,019,425\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load base model\n",
        "base_model = load_model(\"/content/drive/MyDrive/models/base_model_noLST.keras\")\n",
        "\n",
        "# Set weights from base model\n",
        "model_simple_c.set_weights(base_model.get_weights())"
      ],
      "metadata": {
        "id": "d3GbGSsD3IFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scheduler(epoch, lr):\n",
        "    l = 0.000001\n",
        "    if epoch > 200:\n",
        "        l = 0.00005\n",
        "\n",
        "    return l"
      ],
      "metadata": {
        "id": "8Hii6LMv2QtI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callback = LearningRateScheduler(scheduler, verbose = 1)"
      ],
      "metadata": {
        "id": "UThQBxeG2VgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optim_simple_c = optimizers.Adam()"
      ],
      "metadata": {
        "id": "dugN4__a2bfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_simple_c.compile(optimizer = optim_simple_c,\n",
        "                     loss = \"binary_crossentropy\",\n",
        "                     metrics = [\"acc\"])"
      ],
      "metadata": {
        "id": "Wy2F-T9C2gao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_simple_c = model_simple_c.fit(X_train,\n",
        "                                  y_train,\n",
        "                                  validation_data = (X_val, y_val),\n",
        "                                  callbacks = [callback],\n",
        "                                  epochs = 300,\n",
        "                                  batch_size = 256)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCLd3Gfc2hWz",
        "outputId": "30c63b05-9dd7-4079-d49b-f7b7d12ca61d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 1/300\n",
            "10/10 [==============================] - 4s 70ms/step - loss: 0.3897 - acc: 0.7965 - val_loss: 0.5306 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 2/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3877 - acc: 0.8053 - val_loss: 0.5303 - val_acc: 0.7174 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 3/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3841 - acc: 0.7989 - val_loss: 0.5300 - val_acc: 0.7187 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 4/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3944 - acc: 0.7917 - val_loss: 0.5297 - val_acc: 0.7187 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 5/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4020 - acc: 0.7909 - val_loss: 0.5295 - val_acc: 0.7187 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 6/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4001 - acc: 0.7977 - val_loss: 0.5292 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 7/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3893 - acc: 0.7901 - val_loss: 0.5290 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 8/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3860 - acc: 0.7957 - val_loss: 0.5288 - val_acc: 0.7174 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 9/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3995 - acc: 0.7821 - val_loss: 0.5287 - val_acc: 0.7174 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 10/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3993 - acc: 0.7981 - val_loss: 0.5286 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 11/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3962 - acc: 0.7925 - val_loss: 0.5285 - val_acc: 0.7212 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 12/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3886 - acc: 0.7897 - val_loss: 0.5284 - val_acc: 0.7187 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 13/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4015 - acc: 0.7997 - val_loss: 0.5284 - val_acc: 0.7187 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 14/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3790 - acc: 0.8037 - val_loss: 0.5284 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 15/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3988 - acc: 0.7949 - val_loss: 0.5284 - val_acc: 0.7212 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 16: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 16/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3952 - acc: 0.7957 - val_loss: 0.5285 - val_acc: 0.7187 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 17: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 17/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3873 - acc: 0.7949 - val_loss: 0.5285 - val_acc: 0.7225 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 18: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 18/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3860 - acc: 0.7957 - val_loss: 0.5285 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 19: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 19/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3949 - acc: 0.7921 - val_loss: 0.5285 - val_acc: 0.7187 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 20: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 20/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3971 - acc: 0.7897 - val_loss: 0.5285 - val_acc: 0.7212 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 21: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 21/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3850 - acc: 0.7921 - val_loss: 0.5285 - val_acc: 0.7212 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 22: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 22/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3847 - acc: 0.7973 - val_loss: 0.5285 - val_acc: 0.7212 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 23: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 23/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3872 - acc: 0.8069 - val_loss: 0.5285 - val_acc: 0.7212 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 24: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 24/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3884 - acc: 0.8025 - val_loss: 0.5285 - val_acc: 0.7225 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 25: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 25/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3858 - acc: 0.7969 - val_loss: 0.5286 - val_acc: 0.7225 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 26: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 26/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3922 - acc: 0.7977 - val_loss: 0.5286 - val_acc: 0.7212 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 27: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 27/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3861 - acc: 0.8085 - val_loss: 0.5286 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 28: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 28/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3927 - acc: 0.7873 - val_loss: 0.5286 - val_acc: 0.7212 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 29: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 29/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3977 - acc: 0.7921 - val_loss: 0.5286 - val_acc: 0.7225 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 30: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 30/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3869 - acc: 0.7961 - val_loss: 0.5286 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 31: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 31/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3943 - acc: 0.7917 - val_loss: 0.5286 - val_acc: 0.7212 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 32: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 32/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3907 - acc: 0.8029 - val_loss: 0.5286 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 33: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 33/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3883 - acc: 0.7997 - val_loss: 0.5287 - val_acc: 0.7212 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 34: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 34/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3831 - acc: 0.7973 - val_loss: 0.5287 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 35: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 35/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4035 - acc: 0.7949 - val_loss: 0.5287 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 36: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 36/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3883 - acc: 0.8005 - val_loss: 0.5287 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 37: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 37/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3888 - acc: 0.8029 - val_loss: 0.5286 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 38: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 38/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3875 - acc: 0.8001 - val_loss: 0.5286 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 39: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 39/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3894 - acc: 0.8005 - val_loss: 0.5285 - val_acc: 0.7212 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 40: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 40/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3861 - acc: 0.7977 - val_loss: 0.5285 - val_acc: 0.7212 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 41: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 41/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4026 - acc: 0.7837 - val_loss: 0.5285 - val_acc: 0.7212 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 42: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 42/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3827 - acc: 0.8109 - val_loss: 0.5285 - val_acc: 0.7225 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 43: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 43/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3915 - acc: 0.7929 - val_loss: 0.5286 - val_acc: 0.7212 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 44: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 44/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3864 - acc: 0.8049 - val_loss: 0.5286 - val_acc: 0.7212 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 45: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 45/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3973 - acc: 0.7977 - val_loss: 0.5286 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 46: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 46/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3872 - acc: 0.8041 - val_loss: 0.5287 - val_acc: 0.7212 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 47: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 47/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3972 - acc: 0.7873 - val_loss: 0.5288 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 48: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 48/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3930 - acc: 0.7925 - val_loss: 0.5288 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 49: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 49/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3994 - acc: 0.7917 - val_loss: 0.5288 - val_acc: 0.7187 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 50: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 50/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3910 - acc: 0.7981 - val_loss: 0.5287 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 51: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 51/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3963 - acc: 0.7969 - val_loss: 0.5288 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 52: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 52/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3909 - acc: 0.8053 - val_loss: 0.5287 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 53: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 53/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3905 - acc: 0.8021 - val_loss: 0.5287 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 54: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 54/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4048 - acc: 0.7957 - val_loss: 0.5286 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 55: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 55/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3841 - acc: 0.7953 - val_loss: 0.5286 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 56: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 56/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3985 - acc: 0.7925 - val_loss: 0.5286 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 57: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 57/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3913 - acc: 0.7957 - val_loss: 0.5285 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 58: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 58/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3906 - acc: 0.7933 - val_loss: 0.5284 - val_acc: 0.7225 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 59: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 59/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3964 - acc: 0.7929 - val_loss: 0.5284 - val_acc: 0.7225 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 60: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 60/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3938 - acc: 0.7989 - val_loss: 0.5284 - val_acc: 0.7225 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 61: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 61/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3966 - acc: 0.7929 - val_loss: 0.5284 - val_acc: 0.7225 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 62: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 62/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3988 - acc: 0.7945 - val_loss: 0.5284 - val_acc: 0.7225 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 63: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 63/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3945 - acc: 0.7953 - val_loss: 0.5284 - val_acc: 0.7225 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 64: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 64/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3920 - acc: 0.8009 - val_loss: 0.5284 - val_acc: 0.7225 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 65: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 65/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3924 - acc: 0.7853 - val_loss: 0.5285 - val_acc: 0.7225 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 66: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 66/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3975 - acc: 0.7905 - val_loss: 0.5285 - val_acc: 0.7225 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 67: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 67/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4040 - acc: 0.7929 - val_loss: 0.5285 - val_acc: 0.7225 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 68: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 68/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3836 - acc: 0.7941 - val_loss: 0.5285 - val_acc: 0.7212 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 69: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 69/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4008 - acc: 0.7989 - val_loss: 0.5285 - val_acc: 0.7212 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 70: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 70/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3866 - acc: 0.7949 - val_loss: 0.5285 - val_acc: 0.7212 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 71: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 71/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4000 - acc: 0.8021 - val_loss: 0.5285 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 72: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 72/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3983 - acc: 0.7977 - val_loss: 0.5285 - val_acc: 0.7212 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 73: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 73/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3951 - acc: 0.7981 - val_loss: 0.5286 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 74: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 74/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3950 - acc: 0.7933 - val_loss: 0.5286 - val_acc: 0.7187 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 75: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 75/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3940 - acc: 0.7925 - val_loss: 0.5286 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 76: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 76/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3998 - acc: 0.7857 - val_loss: 0.5285 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 77: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 77/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3894 - acc: 0.7917 - val_loss: 0.5285 - val_acc: 0.7187 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 78: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 78/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3924 - acc: 0.7909 - val_loss: 0.5285 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 79: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 79/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3946 - acc: 0.7845 - val_loss: 0.5285 - val_acc: 0.7212 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 80: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 80/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3864 - acc: 0.7973 - val_loss: 0.5286 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 81: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 81/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3970 - acc: 0.8005 - val_loss: 0.5286 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 82: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 82/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3814 - acc: 0.8173 - val_loss: 0.5286 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 83: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 83/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3978 - acc: 0.7925 - val_loss: 0.5286 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 84: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 84/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3737 - acc: 0.8069 - val_loss: 0.5285 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 85: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 85/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3952 - acc: 0.7953 - val_loss: 0.5286 - val_acc: 0.7187 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 86: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 86/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3989 - acc: 0.7913 - val_loss: 0.5285 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 87: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 87/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3777 - acc: 0.8037 - val_loss: 0.5285 - val_acc: 0.7187 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 88: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 88/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3743 - acc: 0.8093 - val_loss: 0.5286 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 89: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 89/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3853 - acc: 0.8009 - val_loss: 0.5285 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 90: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 90/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3946 - acc: 0.7953 - val_loss: 0.5285 - val_acc: 0.7212 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 91: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 91/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3812 - acc: 0.8013 - val_loss: 0.5284 - val_acc: 0.7212 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 92: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 92/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3976 - acc: 0.7889 - val_loss: 0.5283 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 93: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 93/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3982 - acc: 0.7901 - val_loss: 0.5283 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 94: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 94/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3889 - acc: 0.8009 - val_loss: 0.5282 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 95: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 95/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3878 - acc: 0.8005 - val_loss: 0.5283 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 96: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 96/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3880 - acc: 0.7893 - val_loss: 0.5283 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 97: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 97/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3912 - acc: 0.8029 - val_loss: 0.5284 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 98: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 98/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3821 - acc: 0.7937 - val_loss: 0.5285 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 99: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 99/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3836 - acc: 0.8009 - val_loss: 0.5285 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 100: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 100/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.4001 - acc: 0.7881 - val_loss: 0.5286 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 101: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 101/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4029 - acc: 0.7805 - val_loss: 0.5286 - val_acc: 0.7174 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 102: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 102/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3832 - acc: 0.8073 - val_loss: 0.5286 - val_acc: 0.7174 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 103: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 103/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3913 - acc: 0.7909 - val_loss: 0.5286 - val_acc: 0.7174 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 104: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 104/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3869 - acc: 0.8013 - val_loss: 0.5287 - val_acc: 0.7174 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 105: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 105/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3864 - acc: 0.8005 - val_loss: 0.5287 - val_acc: 0.7187 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 106: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 106/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3900 - acc: 0.7893 - val_loss: 0.5287 - val_acc: 0.7187 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 107: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 107/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.4017 - acc: 0.8025 - val_loss: 0.5287 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 108: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 108/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3960 - acc: 0.7973 - val_loss: 0.5287 - val_acc: 0.7187 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 109: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 109/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3977 - acc: 0.7933 - val_loss: 0.5286 - val_acc: 0.7212 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 110: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 110/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4110 - acc: 0.7921 - val_loss: 0.5286 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 111: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 111/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3831 - acc: 0.8033 - val_loss: 0.5284 - val_acc: 0.7187 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 112: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 112/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3823 - acc: 0.8025 - val_loss: 0.5285 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 113: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 113/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3962 - acc: 0.7929 - val_loss: 0.5284 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 114: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 114/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3817 - acc: 0.8085 - val_loss: 0.5284 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 115: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 115/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3915 - acc: 0.8013 - val_loss: 0.5284 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 116: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 116/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3977 - acc: 0.7949 - val_loss: 0.5284 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 117: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 117/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3838 - acc: 0.7913 - val_loss: 0.5283 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 118: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 118/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3909 - acc: 0.7869 - val_loss: 0.5283 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 119: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 119/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3870 - acc: 0.7945 - val_loss: 0.5283 - val_acc: 0.7212 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 120: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 120/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3843 - acc: 0.7921 - val_loss: 0.5284 - val_acc: 0.7212 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 121: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 121/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3928 - acc: 0.8041 - val_loss: 0.5285 - val_acc: 0.7212 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 122: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 122/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3905 - acc: 0.7889 - val_loss: 0.5286 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 123: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 123/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3889 - acc: 0.7981 - val_loss: 0.5285 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 124: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 124/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3917 - acc: 0.7997 - val_loss: 0.5285 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 125: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 125/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3878 - acc: 0.8069 - val_loss: 0.5284 - val_acc: 0.7212 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 126: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 126/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3863 - acc: 0.8049 - val_loss: 0.5286 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 127: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 127/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3894 - acc: 0.7921 - val_loss: 0.5285 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 128: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 128/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3819 - acc: 0.8113 - val_loss: 0.5286 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 129: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 129/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3939 - acc: 0.7917 - val_loss: 0.5286 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 130: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 130/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3965 - acc: 0.7845 - val_loss: 0.5286 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 131: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 131/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3761 - acc: 0.8053 - val_loss: 0.5286 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 132: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 132/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4118 - acc: 0.7829 - val_loss: 0.5286 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 133: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 133/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3869 - acc: 0.7965 - val_loss: 0.5286 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 134: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 134/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3878 - acc: 0.8049 - val_loss: 0.5286 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 135: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 135/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4029 - acc: 0.7961 - val_loss: 0.5285 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 136: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 136/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3857 - acc: 0.8005 - val_loss: 0.5286 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 137: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 137/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3877 - acc: 0.7973 - val_loss: 0.5286 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 138: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 138/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3962 - acc: 0.8057 - val_loss: 0.5286 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 139: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 139/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3882 - acc: 0.8009 - val_loss: 0.5286 - val_acc: 0.7174 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 140: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 140/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4022 - acc: 0.7853 - val_loss: 0.5286 - val_acc: 0.7187 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 141: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 141/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3819 - acc: 0.7969 - val_loss: 0.5287 - val_acc: 0.7174 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 142: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 142/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3955 - acc: 0.7917 - val_loss: 0.5287 - val_acc: 0.7174 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 143: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 143/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3874 - acc: 0.7961 - val_loss: 0.5288 - val_acc: 0.7174 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 144: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 144/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3909 - acc: 0.7941 - val_loss: 0.5288 - val_acc: 0.7174 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 145: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 145/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3811 - acc: 0.8005 - val_loss: 0.5289 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 146: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 146/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3883 - acc: 0.7957 - val_loss: 0.5289 - val_acc: 0.7212 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 147: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 147/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3986 - acc: 0.7885 - val_loss: 0.5289 - val_acc: 0.7212 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 148: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 148/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3825 - acc: 0.7965 - val_loss: 0.5289 - val_acc: 0.7212 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 149: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 149/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3894 - acc: 0.7961 - val_loss: 0.5288 - val_acc: 0.7212 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 150: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 150/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3925 - acc: 0.7969 - val_loss: 0.5288 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 151: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 151/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3808 - acc: 0.8029 - val_loss: 0.5287 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 152: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 152/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3911 - acc: 0.8001 - val_loss: 0.5287 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 153: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 153/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3914 - acc: 0.8009 - val_loss: 0.5287 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 154: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 154/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3961 - acc: 0.7921 - val_loss: 0.5286 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 155: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 155/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3821 - acc: 0.8041 - val_loss: 0.5287 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 156: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 156/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3926 - acc: 0.7813 - val_loss: 0.5286 - val_acc: 0.7187 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 157: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 157/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3982 - acc: 0.7957 - val_loss: 0.5285 - val_acc: 0.7187 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 158: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 158/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3906 - acc: 0.8017 - val_loss: 0.5286 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 159: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 159/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3954 - acc: 0.7937 - val_loss: 0.5286 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 160: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 160/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3958 - acc: 0.7889 - val_loss: 0.5286 - val_acc: 0.7187 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 161: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 161/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3766 - acc: 0.8109 - val_loss: 0.5287 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 162: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 162/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3871 - acc: 0.8009 - val_loss: 0.5286 - val_acc: 0.7187 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 163: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 163/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3914 - acc: 0.7941 - val_loss: 0.5286 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 164: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 164/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3908 - acc: 0.7957 - val_loss: 0.5284 - val_acc: 0.7187 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 165: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 165/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3927 - acc: 0.7929 - val_loss: 0.5284 - val_acc: 0.7187 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 166: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 166/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3964 - acc: 0.7973 - val_loss: 0.5284 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 167: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 167/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3870 - acc: 0.7949 - val_loss: 0.5284 - val_acc: 0.7187 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 168: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 168/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3890 - acc: 0.8017 - val_loss: 0.5285 - val_acc: 0.7187 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 169: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 169/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3796 - acc: 0.7989 - val_loss: 0.5284 - val_acc: 0.7187 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 170: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 170/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3833 - acc: 0.7965 - val_loss: 0.5285 - val_acc: 0.7187 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 171: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 171/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3907 - acc: 0.7973 - val_loss: 0.5285 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 172: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 172/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3891 - acc: 0.7957 - val_loss: 0.5285 - val_acc: 0.7199 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 173: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 173/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3949 - acc: 0.7937 - val_loss: 0.5286 - val_acc: 0.7212 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 174: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 174/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3996 - acc: 0.7853 - val_loss: 0.5286 - val_acc: 0.7212 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 175: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 175/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3769 - acc: 0.7997 - val_loss: 0.5286 - val_acc: 0.7212 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 176: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 176/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3976 - acc: 0.7925 - val_loss: 0.5286 - val_acc: 0.7212 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 177: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 177/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3899 - acc: 0.7949 - val_loss: 0.5286 - val_acc: 0.7212 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 178: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 178/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3836 - acc: 0.7973 - val_loss: 0.5287 - val_acc: 0.7212 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 179: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 179/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3923 - acc: 0.7901 - val_loss: 0.5287 - val_acc: 0.7212 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 180: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 180/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3807 - acc: 0.8129 - val_loss: 0.5287 - val_acc: 0.7212 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 181: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 181/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3868 - acc: 0.7977 - val_loss: 0.5286 - val_acc: 0.7212 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 182: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 182/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3913 - acc: 0.8033 - val_loss: 0.5287 - val_acc: 0.7225 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 183: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 183/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3782 - acc: 0.8061 - val_loss: 0.5287 - val_acc: 0.7212 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 184: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 184/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3864 - acc: 0.7937 - val_loss: 0.5288 - val_acc: 0.7225 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 185: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 185/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3867 - acc: 0.7981 - val_loss: 0.5287 - val_acc: 0.7225 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 186: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 186/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3786 - acc: 0.8061 - val_loss: 0.5288 - val_acc: 0.7225 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 187: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 187/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3982 - acc: 0.7945 - val_loss: 0.5288 - val_acc: 0.7225 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 188: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 188/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3912 - acc: 0.7985 - val_loss: 0.5287 - val_acc: 0.7225 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 189: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 189/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3968 - acc: 0.7881 - val_loss: 0.5287 - val_acc: 0.7225 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 190: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 190/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4035 - acc: 0.7921 - val_loss: 0.5286 - val_acc: 0.7225 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 191: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 191/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3909 - acc: 0.7957 - val_loss: 0.5286 - val_acc: 0.7225 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 192: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 192/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3977 - acc: 0.7965 - val_loss: 0.5286 - val_acc: 0.7212 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 193: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 193/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3817 - acc: 0.8013 - val_loss: 0.5286 - val_acc: 0.7225 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 194: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 194/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3747 - acc: 0.8133 - val_loss: 0.5286 - val_acc: 0.7225 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 195: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 195/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3816 - acc: 0.8065 - val_loss: 0.5286 - val_acc: 0.7225 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 196: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 196/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3817 - acc: 0.7985 - val_loss: 0.5286 - val_acc: 0.7225 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 197: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 197/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3823 - acc: 0.7945 - val_loss: 0.5286 - val_acc: 0.7225 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 198: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 198/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4013 - acc: 0.7961 - val_loss: 0.5285 - val_acc: 0.7225 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 199: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 199/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3806 - acc: 0.8061 - val_loss: 0.5286 - val_acc: 0.7225 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 200: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 200/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3818 - acc: 0.8029 - val_loss: 0.5286 - val_acc: 0.7225 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 201: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 201/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3899 - acc: 0.7973 - val_loss: 0.5285 - val_acc: 0.7212 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 202: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 202/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3979 - acc: 0.7825 - val_loss: 0.5262 - val_acc: 0.7212 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 203: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 203/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3851 - acc: 0.8077 - val_loss: 0.5291 - val_acc: 0.7174 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 204: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 204/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4041 - acc: 0.7985 - val_loss: 0.5266 - val_acc: 0.7148 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 205: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 205/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3885 - acc: 0.7989 - val_loss: 0.5263 - val_acc: 0.7110 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 206: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 206/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3901 - acc: 0.8001 - val_loss: 0.5266 - val_acc: 0.7161 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 207: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 207/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3986 - acc: 0.8049 - val_loss: 0.5306 - val_acc: 0.7110 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 208: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 208/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3914 - acc: 0.7921 - val_loss: 0.5315 - val_acc: 0.7136 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 209: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 209/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3984 - acc: 0.7993 - val_loss: 0.5284 - val_acc: 0.7110 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 210: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 210/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4017 - acc: 0.7949 - val_loss: 0.5323 - val_acc: 0.7110 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 211: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 211/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3872 - acc: 0.8013 - val_loss: 0.5314 - val_acc: 0.7110 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 212: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 212/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3808 - acc: 0.8001 - val_loss: 0.5334 - val_acc: 0.7161 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 213: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 213/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3836 - acc: 0.8053 - val_loss: 0.5358 - val_acc: 0.7123 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 214: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 214/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3862 - acc: 0.7969 - val_loss: 0.5348 - val_acc: 0.7123 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 215: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 215/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3902 - acc: 0.8017 - val_loss: 0.5341 - val_acc: 0.7136 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 216: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 216/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3910 - acc: 0.7969 - val_loss: 0.5313 - val_acc: 0.7187 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 217: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 217/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3946 - acc: 0.7981 - val_loss: 0.5400 - val_acc: 0.7238 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 218: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 218/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3907 - acc: 0.7949 - val_loss: 0.5323 - val_acc: 0.7212 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 219: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 219/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3867 - acc: 0.8085 - val_loss: 0.5308 - val_acc: 0.7199 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 220: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 220/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3862 - acc: 0.8037 - val_loss: 0.5319 - val_acc: 0.7187 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 221: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 221/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3759 - acc: 0.8189 - val_loss: 0.5411 - val_acc: 0.7251 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 222: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 222/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3898 - acc: 0.7993 - val_loss: 0.5408 - val_acc: 0.7187 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 223: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 223/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3683 - acc: 0.8181 - val_loss: 0.5313 - val_acc: 0.7072 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 224: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 224/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3897 - acc: 0.7977 - val_loss: 0.5309 - val_acc: 0.7097 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 225: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 225/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3823 - acc: 0.8001 - val_loss: 0.5402 - val_acc: 0.7174 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 226: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 226/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3790 - acc: 0.7965 - val_loss: 0.5406 - val_acc: 0.7148 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 227: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 227/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3780 - acc: 0.8025 - val_loss: 0.5395 - val_acc: 0.7123 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 228: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 228/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3816 - acc: 0.8057 - val_loss: 0.5408 - val_acc: 0.7136 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 229: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 229/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3798 - acc: 0.8137 - val_loss: 0.5376 - val_acc: 0.7161 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 230: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 230/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3737 - acc: 0.8097 - val_loss: 0.5363 - val_acc: 0.7110 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 231: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 231/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3743 - acc: 0.8073 - val_loss: 0.5356 - val_acc: 0.7161 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 232: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 232/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3695 - acc: 0.8081 - val_loss: 0.5381 - val_acc: 0.7072 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 233: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 233/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3735 - acc: 0.8065 - val_loss: 0.5396 - val_acc: 0.7084 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 234: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 234/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3763 - acc: 0.8077 - val_loss: 0.5327 - val_acc: 0.7161 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 235: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 235/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3854 - acc: 0.8077 - val_loss: 0.5389 - val_acc: 0.7110 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 236: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 236/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3749 - acc: 0.8077 - val_loss: 0.5441 - val_acc: 0.7059 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 237: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 237/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3769 - acc: 0.8049 - val_loss: 0.5377 - val_acc: 0.7059 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 238: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 238/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3772 - acc: 0.8081 - val_loss: 0.5363 - val_acc: 0.7046 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 239: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 239/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3785 - acc: 0.8017 - val_loss: 0.5383 - val_acc: 0.7199 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 240: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 240/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3711 - acc: 0.8109 - val_loss: 0.5353 - val_acc: 0.7110 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 241: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 241/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3847 - acc: 0.8041 - val_loss: 0.5307 - val_acc: 0.7059 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 242: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 242/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3828 - acc: 0.7993 - val_loss: 0.5287 - val_acc: 0.7110 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 243: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 243/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3745 - acc: 0.8105 - val_loss: 0.5314 - val_acc: 0.7097 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 244: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 244/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3818 - acc: 0.8049 - val_loss: 0.5324 - val_acc: 0.7059 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 245: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 245/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3710 - acc: 0.8145 - val_loss: 0.5336 - val_acc: 0.7110 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 246: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 246/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3799 - acc: 0.8153 - val_loss: 0.5354 - val_acc: 0.7097 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 247: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 247/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3643 - acc: 0.8069 - val_loss: 0.5365 - val_acc: 0.7161 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 248: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 248/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3677 - acc: 0.8173 - val_loss: 0.5410 - val_acc: 0.7110 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 249: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 249/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3665 - acc: 0.8197 - val_loss: 0.5374 - val_acc: 0.7072 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 250: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 250/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3714 - acc: 0.8149 - val_loss: 0.5358 - val_acc: 0.7072 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 251: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 251/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3597 - acc: 0.8173 - val_loss: 0.5342 - val_acc: 0.7097 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 252: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 252/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3749 - acc: 0.8053 - val_loss: 0.5364 - val_acc: 0.7110 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 253: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 253/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3657 - acc: 0.8085 - val_loss: 0.5370 - val_acc: 0.7161 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 254: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 254/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3690 - acc: 0.8057 - val_loss: 0.5368 - val_acc: 0.7136 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 255: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 255/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3663 - acc: 0.8197 - val_loss: 0.5389 - val_acc: 0.7123 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 256: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 256/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3640 - acc: 0.8137 - val_loss: 0.5356 - val_acc: 0.7084 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 257: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 257/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3631 - acc: 0.8189 - val_loss: 0.5377 - val_acc: 0.7161 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 258: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 258/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3681 - acc: 0.8137 - val_loss: 0.5474 - val_acc: 0.7046 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 259: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 259/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3638 - acc: 0.8149 - val_loss: 0.5443 - val_acc: 0.7020 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 260: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 260/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3700 - acc: 0.8117 - val_loss: 0.5376 - val_acc: 0.7148 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 261: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 261/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3671 - acc: 0.8201 - val_loss: 0.5355 - val_acc: 0.7084 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 262: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 262/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3740 - acc: 0.8069 - val_loss: 0.5317 - val_acc: 0.7097 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 263: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 263/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3560 - acc: 0.8133 - val_loss: 0.5347 - val_acc: 0.7187 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 264: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 264/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3752 - acc: 0.8137 - val_loss: 0.5361 - val_acc: 0.7110 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 265: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 265/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3795 - acc: 0.7981 - val_loss: 0.5327 - val_acc: 0.7084 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 266: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 266/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3708 - acc: 0.8093 - val_loss: 0.5334 - val_acc: 0.7084 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 267: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 267/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3663 - acc: 0.8089 - val_loss: 0.5380 - val_acc: 0.7097 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 268: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 268/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3761 - acc: 0.8109 - val_loss: 0.5371 - val_acc: 0.7225 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 269: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 269/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3706 - acc: 0.8021 - val_loss: 0.5401 - val_acc: 0.7136 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 270: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 270/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3644 - acc: 0.8097 - val_loss: 0.5365 - val_acc: 0.7033 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 271: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 271/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3636 - acc: 0.8109 - val_loss: 0.5331 - val_acc: 0.7212 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 272: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 272/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3570 - acc: 0.8165 - val_loss: 0.5371 - val_acc: 0.7161 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 273: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 273/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3689 - acc: 0.8145 - val_loss: 0.5420 - val_acc: 0.7059 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 274: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 274/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3571 - acc: 0.8129 - val_loss: 0.5535 - val_acc: 0.7033 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 275: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 275/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3569 - acc: 0.8241 - val_loss: 0.5447 - val_acc: 0.7148 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 276: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 276/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3466 - acc: 0.8289 - val_loss: 0.5460 - val_acc: 0.7059 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 277: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 277/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3556 - acc: 0.8217 - val_loss: 0.5570 - val_acc: 0.6969 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 278: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 278/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3603 - acc: 0.8261 - val_loss: 0.5434 - val_acc: 0.7008 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 279: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 279/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3558 - acc: 0.8177 - val_loss: 0.5341 - val_acc: 0.7123 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 280: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 280/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3537 - acc: 0.8205 - val_loss: 0.5374 - val_acc: 0.7123 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 281: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 281/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3570 - acc: 0.8205 - val_loss: 0.5396 - val_acc: 0.7136 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 282: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 282/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3636 - acc: 0.8125 - val_loss: 0.5399 - val_acc: 0.7161 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 283: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 283/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3512 - acc: 0.8241 - val_loss: 0.5410 - val_acc: 0.7046 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 284: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 284/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3488 - acc: 0.8265 - val_loss: 0.5431 - val_acc: 0.7136 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 285: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 285/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3485 - acc: 0.8241 - val_loss: 0.5457 - val_acc: 0.7148 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 286: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 286/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3500 - acc: 0.8145 - val_loss: 0.5502 - val_acc: 0.7097 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 287: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 287/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3625 - acc: 0.8201 - val_loss: 0.5573 - val_acc: 0.7059 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 288: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 288/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3548 - acc: 0.8209 - val_loss: 0.5567 - val_acc: 0.7008 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 289: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 289/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3345 - acc: 0.8213 - val_loss: 0.5482 - val_acc: 0.7033 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 290: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 290/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3669 - acc: 0.8017 - val_loss: 0.5433 - val_acc: 0.7110 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 291: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 291/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3480 - acc: 0.8205 - val_loss: 0.5440 - val_acc: 0.7136 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 292: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 292/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3498 - acc: 0.8289 - val_loss: 0.5487 - val_acc: 0.7136 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 293: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 293/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3355 - acc: 0.8317 - val_loss: 0.5569 - val_acc: 0.7033 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 294: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 294/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3466 - acc: 0.8217 - val_loss: 0.5610 - val_acc: 0.6982 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 295: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 295/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3501 - acc: 0.8145 - val_loss: 0.5565 - val_acc: 0.7008 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 296: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 296/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3318 - acc: 0.8333 - val_loss: 0.5558 - val_acc: 0.7072 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 297: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 297/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3541 - acc: 0.8233 - val_loss: 0.5568 - val_acc: 0.7072 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 298: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 298/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3407 - acc: 0.8249 - val_loss: 0.5621 - val_acc: 0.7033 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 299: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 299/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3540 - acc: 0.8137 - val_loss: 0.5530 - val_acc: 0.6957 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 300: LearningRateScheduler setting learning rate to 5e-05.\n",
            "Epoch 300/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3567 - acc: 0.8137 - val_loss: 0.5507 - val_acc: 0.6995 - lr: 5.0000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The red line in the following plots represents the performance of the model after implementing the new learning schedule."
      ],
      "metadata": {
        "id": "EsVOPTgQp-9O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load history from base model\n",
        "with open(\"/content/drive/MyDrive/models/base_model_history_noLST\", \"rb\") as file_pi:\n",
        "    base_model_history = pickle.load(file_pi)\n",
        "\n",
        "# Append data from fine tuning history\n",
        "for key in base_model_history.keys():\n",
        "    for i in range(0, len(history_simple_c.history[key])):\n",
        "        value = history_simple_c.history[key][i]\n",
        "        base_model_history[key].append(value)\n",
        "\n",
        "# list all data in history_simple_c\n",
        "print(base_model_history.keys())\n",
        "\n",
        "# summarize base_model for accuracy\n",
        "plt.plot(base_model_history['acc'])\n",
        "plt.plot(base_model_history['val_acc'])\n",
        "plt.axvline(x = 1000, color = \"r\")\n",
        "#plt.title('model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Entrenamiento', 'Validación'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize base_model for loss\n",
        "plt.plot(base_model_history['loss'])\n",
        "plt.plot(base_model_history['val_loss'])\n",
        "plt.axvline(x = 1000, color = \"r\")\n",
        "#plt.title('model loss')\n",
        "plt.ylabel('Pérdida (loss)')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Entrenamiento', 'Validación'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 903
        },
        "id": "7Q_UUA_L2mwA",
        "outputId": "c03e4e5f-f592-4eb0-df80-ede7ef97ac83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'acc', 'val_loss', 'val_acc', 'lr'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_simple_c.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJzbc3vYyYxe",
        "outputId": "724df6c8-1aca-48cc-c4e6-356fdbd10a57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4886 - acc: 0.7444\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4885512888431549, 0.7444089651107788]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# See predictions by class\n",
        "model_simple_c_pred = model_simple_c.predict(X_test, batch_size = 64)\n",
        "\n",
        "print(classification_report(y_test, np.where(model_simple_c_pred > 0.5, 1, 0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7gfmIRg0A2K",
        "outputId": "3fc0fbf2-6a33-4ca8-b690-1be1f57f3691"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 0s 9ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.72      0.75       323\n",
            "           1       0.72      0.77      0.74       303\n",
            "\n",
            "    accuracy                           0.74       626\n",
            "   macro avg       0.74      0.75      0.74       626\n",
            "weighted avg       0.75      0.74      0.74       626\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model with 74% accuracy\n",
        "model_simple_c.save(\"/content/drive/MyDrive/models/model_noLST_74acc.keras\")\n",
        "\n",
        "# Save history of model with 74% accuracy\n",
        "with open('/content/drive/MyDrive/models/model_noLST_74acc_history', 'wb') as file_pi:\n",
        "    pickle.dump(base_model_history, file_pi)"
      ],
      "metadata": {
        "id": "PudlFYrvnxpK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}